{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Label encoded original data\n",
    "\n",
    "### to check feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender  \\\n",
       "0           50                88                 30          80       1   \n",
       "1           32                82                 59          63       1   \n",
       "2           50                62                 13          33       1   \n",
       "3           60                80                 50          40       0   \n",
       "4           70                92                 50           7       0   \n",
       "\n",
       "   NationalITy  PlaceofBirth  StageID  GradeID  SectionID  Topic  Semester  \\\n",
       "0            4             4        1        4          0      8         0   \n",
       "1            3             3        2        0          1      0         1   \n",
       "2            3             3        2        0          1      4         1   \n",
       "3            4            11        0        8          0      9         0   \n",
       "4            4             4        2        0          1      7         0   \n",
       "\n",
       "   Relation  ParentAnsweringSurvey  ParentschoolSatisfaction  \\\n",
       "0         0                      1                         1   \n",
       "1         1                      1                         0   \n",
       "2         0                      0                         0   \n",
       "3         1                      0                         0   \n",
       "4         1                      1                         1   \n",
       "\n",
       "   StudentAbsenceDays Class  \n",
       "0                   1     H  \n",
       "1                   0     M  \n",
       "2                   0     L  \n",
       "3                   1     M  \n",
       "4                   1     H  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading original label encoded data\n",
    "df = pd.read_csv(\"Data/transformed/train_org_lb.csv\")\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert feature's string values into numbers to apply models\n",
    "label_to_key = {}\n",
    "key_to_label = {}\n",
    "for i,label in enumerate(sorted(df['Class'].unique())):\n",
    "    label_to_key[label] = i\n",
    "    key_to_label[i]= label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Class = df.Class.apply(lambda x :label_to_key[x]) # converting Class feature values from str to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 0, 'L': 1, 'M': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the conversion\n",
    "label_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting input features(X) and output (y)\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save trained model in pickle file\n",
    "\n",
    "def save_pkl_model(path,model):\n",
    "    pickle.dump(model, open(path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load trained model \n",
    "def load_pkl_model(path):\n",
    "    return pickle.load(open(path, 'rb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest**\n",
    "\n",
    "to check importance of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters for grid search \n",
    "\n",
    "\n",
    "# n_estimatorsint, default=100\n",
    "###The number of trees in the forest.\n",
    "\n",
    "#criterion{“gini”, “entropy”}, default=”gini”\n",
    "###The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n",
    "\n",
    "#bootstrapbool, default=True\n",
    "###Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html \n",
    "grid_param = {\n",
    "    'n_estimators': [int(x) for x in range(200,2000,200)],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  grid search cross fold validation\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=f1,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400,\n",
       "                                          1600, 1800]},\n",
       "             scoring=make_scorer(f1_score, average=micro))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying random forest with different combinations of hyperparameters \n",
    "gd_sr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting model with best hyperparameters \n",
    "best_random = gd_sr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8186088527551941 RandomForestClassifier(criterion='entropy', n_estimators=1000) [0.14102608 0.18770605 0.12323161 0.0863615  0.02310939 0.03406358\n",
      " 0.03131846 0.01404104 0.03284837 0.0167915  0.04704994 0.01124462\n",
      " 0.03197633 0.03793062 0.02426588 0.15703504]\n"
     ]
    }
   ],
   "source": [
    "#pritning best score, estimator and feature importance,  \n",
    "print (gd_sr.best_score_,best_random,best_random.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model \n",
    "save_pkl_model(\"models/rf.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "best_random = load_pkl_model(\"models/rf.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Stats        FI\n",
      "1           VisITedResources  0.187706\n",
      "15        StudentAbsenceDays  0.157035\n",
      "0                raisedhands  0.141026\n",
      "2          AnnouncementsView  0.123232\n",
      "3                 Discussion  0.086362\n",
      "10                     Topic  0.047050\n",
      "13     ParentAnsweringSurvey  0.037931\n",
      "5                NationalITy  0.034064\n",
      "8                    GradeID  0.032848\n",
      "12                  Relation  0.031976\n",
      "6               PlaceofBirth  0.031318\n",
      "14  ParentschoolSatisfaction  0.024266\n",
      "4                     gender  0.023109\n",
      "9                  SectionID  0.016792\n",
      "7                    StageID  0.014041\n",
      "11                  Semester  0.011245\n"
     ]
    }
   ],
   "source": [
    "# combining feature importance with column names in descending order to see \n",
    "\n",
    "d = {'Stats':X.columns,'FI':best_random.feature_importances_}\n",
    "df1 = pd.DataFrame(d)\n",
    "\n",
    "print(df1.sort_values(by=['FI'], ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing column names whose feature importance is less than 0.02 to drop \n",
    "drop_col = df1.Stats[df1.FI < 0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to drop columns by matching names of columns\n",
    "def func_dropCol(df,drop_col):\n",
    "    for i in drop_col:\n",
    "        df = df[df.columns.drop(list(df.filter(regex=i)))]\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive Bays\n",
    "**using one hot encoded ,bxtransformed data** \n",
    "**and important features from above model** \n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "The biggest and only assumption is the assumption of conditional independence.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Gives high performance when the conditional independence assumption is satisfied.\n",
    "2. Easy to implement because only probabilities need to be calculated.\n",
    "3. Works well with high-dimensional data, such as text.\n",
    "4. Fast for real-time predictions.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. If conditional independence does not hold, then is performs poorly.\n",
    "2. Has the problem of Numerical Stability or Numerical Underflow because of the multiplication of several small digits.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading classifier \n",
    "classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading one hot encoded box transformed data \n",
    "df = pd.read_csv(\"Data/transformed/train_bx_ohe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Semester_S</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...         1.0          0.0            0.0   \n",
       "1                0.0  ...         0.0          0.0            0.0   \n",
       "2                0.0  ...         0.0          0.0            0.0   \n",
       "3                0.0  ...         0.0          1.0            0.0   \n",
       "4                0.0  ...         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Semester_S  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0         0.0           0.0                        1.0   \n",
       "1            0.0         1.0           1.0                        1.0   \n",
       "2            0.0         1.0           0.0                        0.0   \n",
       "3            0.0         0.0           1.0                        0.0   \n",
       "4            0.0         0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      H  \n",
       "1                            0.0                         0.0      M  \n",
       "2                            0.0                         0.0      L  \n",
       "3                            0.0                         1.0      M  \n",
       "4                            1.0                         1.0      H  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 61)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows(r) and columns(c)  (r,c)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_IT</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_IT  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...       0.0         1.0          0.0            0.0   \n",
       "1                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "2                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "3                0.0  ...       0.0         0.0          1.0            0.0   \n",
       "4                0.0  ...       1.0         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0           0.0                        1.0   \n",
       "1            0.0           1.0                        1.0   \n",
       "2            0.0           0.0                        0.0   \n",
       "3            0.0           1.0                        0.0   \n",
       "4            0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      H  \n",
       "1                            0.0                         0.0      M  \n",
       "2                            0.0                         0.0      L  \n",
       "3                            0.0                         1.0      M  \n",
       "4                            1.0                         1.0      H  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns with less importance\n",
    "df = func_dropCol(df,drop_col)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 56)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows(r) and columns(c) in (r,c) format\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_IT</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_IT  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...       0.0         1.0          0.0            0.0   \n",
       "1                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "2                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "3                0.0  ...       0.0         0.0          1.0            0.0   \n",
       "4                0.0  ...       1.0         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0           0.0                        1.0   \n",
       "1            0.0           1.0                        1.0   \n",
       "2            0.0           0.0                        0.0   \n",
       "3            0.0           1.0                        0.0   \n",
       "4            0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      0  \n",
       "1                            0.0                         0.0      2  \n",
       "2                            0.0                         0.0      1  \n",
       "3                            0.0                         1.0      2  \n",
       "4                            1.0                         1.0      0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting Class feature values from str to number\n",
    "df.Class = df.Class.apply(lambda x :label_to_key[x]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting input and target features\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting range of hyperparameters for grid search\n",
    "\n",
    "#var_smoothingfloat, default=1e-9\n",
    "##Portion of the largest variance of all features that is added to variances for calculation stability.\n",
    "grid_param = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cross validation\n",
    "gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=f1,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=-1,\n",
       "             param_grid={'var_smoothing': array([1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,\n",
       "       1.e-08, 1.e-09])},\n",
       "             scoring=make_scorer(f1_score, average=micro))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying random forest with different combinations of hyperparameters \n",
    "gd_sr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6789220114423367 {'var_smoothing': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print (gd_sr.best_score_, gd_sr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/naive_bayes.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. algorithms with Normalized and one hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  (408, 61)\n",
      "shape after removing columns  (408, 56)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/transformed/train_mms_ohe.csv\")\n",
    "print(\"shape \" , df.shape)\n",
    "df = func_dropCol(df,drop_col)\n",
    "\n",
    "print(\"shape after removing columns \", df.shape)\n",
    "df.Class = df.Class.apply(lambda x :label_to_key[x]) # mapping \n",
    "df.head()\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Decision Trees \n",
    "**Assumptions of algorithm** :\n",
    "\n",
    "1. Initially, whole training data is considered as root.\n",
    "2. Records are distributed recursively on the basis of the attribute value.\n",
    "\n",
    "**Pros** :\n",
    "\n",
    "1. Compared to other algorithms, data preparation requires less time.\n",
    "2. Doesn’t require data to be normalized.\n",
    "3. Missing values, to an extent, don’t affect its performance much.\n",
    "4. Is very intuitive as can be explained as if-else conditions.\n",
    "\n",
    "**Cons**:\n",
    "\n",
    "1. Needs a lot of time to train the model.\n",
    "2. A small change in data can cause a considerably large change in the Decision Tree structure.\n",
    "3. Comparatively expensive to train.\n",
    "4. Not good for regression tasks.\n",
    "\n",
    "https://www.kdnuggets.com/2021/02/machine-learning-assumptions.html \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??\n",
    "f1 = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cross validation\n",
    "gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=params,\n",
    "                     scoring=f1,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 5, 10, 20],\n",
       "                         'min_samples_leaf': [5, 10, 20, 50, 100]},\n",
       "             scoring=make_scorer(f1_score, average=micro))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model with different combinations of hyperparameters \n",
    "gd_sr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = gd_sr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/decision_tree.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7476663655525445 {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 5}\n"
     ]
    }
   ],
   "source": [
    "print (gd_sr.best_score_, gd_sr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimatorsint, default=100\n",
    "###The number of trees in the forest.\n",
    "\n",
    "#criterion{“gini”, “entropy”}, default=”gini”\n",
    "###The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n",
    "\n",
    "#bootstrapbool, default=True\n",
    "###Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html \n",
    "grid_param = {\n",
    "    'n_estimators': [int(x) for x in range(200,2000,200)],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=f1,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400,\n",
       "                                          1600, 1800]},\n",
       "             scoring=make_scorer(f1_score, average=micro))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model with different combinations of hyperparameters \n",
    "gd_sr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8234869015356822 {'bootstrap': False, 'criterion': 'entropy', 'n_estimators': 1600} [1.38814581e-01 1.62327643e-01 1.19231846e-01 8.94267276e-02\n",
      " 2.65062464e-02 1.65214327e-03 4.76781657e-03 1.27808833e-02\n",
      " 1.24019184e-02 1.39803966e-03 1.15099585e-03 5.66400406e-03\n",
      " 4.69628115e-03 1.83480127e-03 2.62303909e-03 7.40261164e-04\n",
      " 2.21874359e-03 1.24814397e-04 1.61590258e-03 4.60765195e-03\n",
      " 1.24034781e-02 1.30227664e-02 1.23037441e-03 1.10377801e-03\n",
      " 2.98157146e-03 4.45442087e-03 1.32362625e-03 1.63571643e-03\n",
      " 2.13636569e-03 2.90317302e-03 1.01104673e-04 1.02807971e-02\n",
      " 5.96631302e-05 6.55931264e-03 1.11030524e-02 1.18431257e-02\n",
      " 8.67728115e-04 1.23461161e-03 2.68345839e-03 1.69186308e-03\n",
      " 5.02067177e-03 7.34546212e-03 7.47541098e-03 8.43233278e-03\n",
      " 7.10595737e-03 5.83591711e-03 1.06603019e-02 6.00998079e-03\n",
      " 3.83395615e-03 7.76446720e-03 4.42674257e-03 3.62736879e-02\n",
      " 4.10103433e-02 2.93981538e-02 1.35202287e-01]\n"
     ]
    }
   ],
   "source": [
    "print (gd_sr.best_score_, gd_sr.best_params_,gd_sr.best_estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/random_forest.pkl\",gd_sr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Stats':X.columns,'FI':gd_sr.best_estimator_.feature_importances_}\n",
    "df1 = pd.DataFrame(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stats</th>\n",
       "      <th>FI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raisedhands</td>\n",
       "      <td>0.138815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VisITedResources</td>\n",
       "      <td>0.162328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnouncementsView</td>\n",
       "      <td>0.119232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Discussion</td>\n",
       "      <td>0.089427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender_M</td>\n",
       "      <td>0.026506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NationalITy_Iran</td>\n",
       "      <td>0.001652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NationalITy_Iraq</td>\n",
       "      <td>0.004768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NationalITy_Jordan</td>\n",
       "      <td>0.012781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NationalITy_KW</td>\n",
       "      <td>0.012402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NationalITy_Lybia</td>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NationalITy_Morocco</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NationalITy_Palestine</td>\n",
       "      <td>0.005664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NationalITy_SaudiArabia</td>\n",
       "      <td>0.004696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NationalITy_Syria</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NationalITy_Tunis</td>\n",
       "      <td>0.002623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NationalITy_USA</td>\n",
       "      <td>0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NationalITy_lebanon</td>\n",
       "      <td>0.002219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NationalITy_venzuela</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PlaceofBirth_Iran</td>\n",
       "      <td>0.001616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PlaceofBirth_Iraq</td>\n",
       "      <td>0.004608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PlaceofBirth_Jordan</td>\n",
       "      <td>0.012403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PlaceofBirth_KuwaIT</td>\n",
       "      <td>0.013023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PlaceofBirth_Lybia</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PlaceofBirth_Morocco</td>\n",
       "      <td>0.001104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PlaceofBirth_Palestine</td>\n",
       "      <td>0.002982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PlaceofBirth_SaudiArabia</td>\n",
       "      <td>0.004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PlaceofBirth_Syria</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PlaceofBirth_Tunis</td>\n",
       "      <td>0.001636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PlaceofBirth_USA</td>\n",
       "      <td>0.002136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PlaceofBirth_lebanon</td>\n",
       "      <td>0.002903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PlaceofBirth_venzuela</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GradeID_G-04</td>\n",
       "      <td>0.010281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradeID_G-05</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GradeID_G-06</td>\n",
       "      <td>0.006559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GradeID_G-07</td>\n",
       "      <td>0.011103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GradeID_G-08</td>\n",
       "      <td>0.011843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GradeID_G-09</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GradeID_G-10</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>GradeID_G-11</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>GradeID_G-12</td>\n",
       "      <td>0.001692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Topic_Biology</td>\n",
       "      <td>0.005021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Topic_Chemistry</td>\n",
       "      <td>0.007345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Topic_English</td>\n",
       "      <td>0.007475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Topic_French</td>\n",
       "      <td>0.008432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Topic_Geology</td>\n",
       "      <td>0.007106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Topic_History</td>\n",
       "      <td>0.005836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Topic_IT</td>\n",
       "      <td>0.010660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Topic_Math</td>\n",
       "      <td>0.006010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Topic_Quran</td>\n",
       "      <td>0.003834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Topic_Science</td>\n",
       "      <td>0.007764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Topic_Spanish</td>\n",
       "      <td>0.004427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Relation_Mum</td>\n",
       "      <td>0.036274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ParentAnsweringSurvey_Yes</td>\n",
       "      <td>0.041010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ParentschoolSatisfaction_Good</td>\n",
       "      <td>0.029398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>StudentAbsenceDays_Under-7</td>\n",
       "      <td>0.135202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Stats        FI\n",
       "0                     raisedhands  0.138815\n",
       "1                VisITedResources  0.162328\n",
       "2               AnnouncementsView  0.119232\n",
       "3                      Discussion  0.089427\n",
       "4                        gender_M  0.026506\n",
       "5                NationalITy_Iran  0.001652\n",
       "6                NationalITy_Iraq  0.004768\n",
       "7              NationalITy_Jordan  0.012781\n",
       "8                  NationalITy_KW  0.012402\n",
       "9               NationalITy_Lybia  0.001398\n",
       "10            NationalITy_Morocco  0.001151\n",
       "11          NationalITy_Palestine  0.005664\n",
       "12        NationalITy_SaudiArabia  0.004696\n",
       "13              NationalITy_Syria  0.001835\n",
       "14              NationalITy_Tunis  0.002623\n",
       "15                NationalITy_USA  0.000740\n",
       "16            NationalITy_lebanon  0.002219\n",
       "17           NationalITy_venzuela  0.000125\n",
       "18              PlaceofBirth_Iran  0.001616\n",
       "19              PlaceofBirth_Iraq  0.004608\n",
       "20            PlaceofBirth_Jordan  0.012403\n",
       "21            PlaceofBirth_KuwaIT  0.013023\n",
       "22             PlaceofBirth_Lybia  0.001230\n",
       "23           PlaceofBirth_Morocco  0.001104\n",
       "24         PlaceofBirth_Palestine  0.002982\n",
       "25       PlaceofBirth_SaudiArabia  0.004454\n",
       "26             PlaceofBirth_Syria  0.001324\n",
       "27             PlaceofBirth_Tunis  0.001636\n",
       "28               PlaceofBirth_USA  0.002136\n",
       "29           PlaceofBirth_lebanon  0.002903\n",
       "30          PlaceofBirth_venzuela  0.000101\n",
       "31                   GradeID_G-04  0.010281\n",
       "32                   GradeID_G-05  0.000060\n",
       "33                   GradeID_G-06  0.006559\n",
       "34                   GradeID_G-07  0.011103\n",
       "35                   GradeID_G-08  0.011843\n",
       "36                   GradeID_G-09  0.000868\n",
       "37                   GradeID_G-10  0.001235\n",
       "38                   GradeID_G-11  0.002683\n",
       "39                   GradeID_G-12  0.001692\n",
       "40                  Topic_Biology  0.005021\n",
       "41                Topic_Chemistry  0.007345\n",
       "42                  Topic_English  0.007475\n",
       "43                   Topic_French  0.008432\n",
       "44                  Topic_Geology  0.007106\n",
       "45                  Topic_History  0.005836\n",
       "46                       Topic_IT  0.010660\n",
       "47                     Topic_Math  0.006010\n",
       "48                    Topic_Quran  0.003834\n",
       "49                  Topic_Science  0.007764\n",
       "50                  Topic_Spanish  0.004427\n",
       "51                   Relation_Mum  0.036274\n",
       "52      ParentAnsweringSurvey_Yes  0.041010\n",
       "53  ParentschoolSatisfaction_Good  0.029398\n",
       "54     StudentAbsenceDays_Under-7  0.135202"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param =  {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 3),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cross validation\n",
    "gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=f1,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "270 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.2965673         nan 0.43875339 0.43875339\n",
      " 0.43875339 0.43875339 0.43875339 0.43875339        nan        nan\n",
      "        nan        nan        nan 0.732972   0.73775971        nan\n",
      " 0.74272809 0.75739235        nan        nan 0.2965673         nan\n",
      " 0.43875339 0.43875339 0.43875339 0.43875339 0.43875339 0.43875339\n",
      "        nan        nan        nan        nan        nan 0.73288166\n",
      " 0.73775971        nan 0.74513701 0.74757603        nan        nan\n",
      " 0.73273111        nan 0.75498344 0.7622704  0.7622704  0.71562782\n",
      " 0.7622704  0.7622704         nan        nan        nan        nan\n",
      "        nan 0.732972   0.73775971        nan 0.74025896 0.75739235\n",
      "        nan        nan 0.73273111        nan 0.75498344 0.7622704\n",
      " 0.7622704  0.71562782 0.7622704  0.7622704         nan        nan\n",
      "        nan        nan        nan 0.73288166 0.73775971        nan\n",
      " 0.74757603 0.74757603        nan        nan 0.69611563        nan\n",
      " 0.75495333 0.73050286 0.74022885 0.69611563 0.73778982 0.75739235\n",
      "        nan        nan        nan        nan        nan 0.732972\n",
      " 0.73775971        nan 0.74757603 0.75495333        nan        nan\n",
      " 0.69611563        nan 0.74757603 0.74022885 0.74022885 0.69611563\n",
      " 0.74513701 0.74757603        nan        nan        nan        nan\n",
      "        nan 0.73288166 0.73775971        nan 0.74513701 0.74757603]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-04, 1.e+00, 1.e+04]),\n",
       "                         'max_iter': [100, 1000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring=make_scorer(f1_score, average=micro))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model with different combinations of hyperparameters \n",
    "gd_sr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7622704004817826 {'C': 1.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'} LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "print (gd_sr.best_score_, gd_sr.best_params_,gd_sr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/logistic_regression.pkl\",gd_sr.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 SVM\n",
    "**Assumptions:**\n",
    "\n",
    "It assumes data is independent and identically distributed.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Works really well on high dimensional data.\n",
    "2. Memory efficient.\n",
    "3. Effective in cases where the number of dimensions is greater than the number of samples.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. Not suitable for large datasets.\n",
    "2. Doesn’t work well when the dataset has noise, i.e., the target classes are overlapping.\n",
    "3. Slow to train.\n",
    "4. No probabilistic explanation for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = { 'C':[0.1,1,100,1000],\n",
    "'kernel':['rbf','poly','sigmoid','linear'],\n",
    "'degree':[1,5,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cross validation\n",
    "gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=f1,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 100, 1000], 'degree': [1, 5, 6],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid', 'linear']},\n",
       "             scoring=make_scorer(f1_score, average=micro))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model with different combinations of hyperparameters \n",
    "gd_sr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7917193616380608 {'C': 1, 'degree': 1, 'kernel': 'rbf'} SVC(C=1, degree=1)\n"
     ]
    }
   ],
   "source": [
    "print (gd_sr.best_score_, gd_sr.best_params_,gd_sr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/svm.pkl\",gd_sr.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 XGBOOST\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "It may have an assumption that encoded integer value for each variable has ordinal relation.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Can work in parallell.\n",
    "2. Can handle missing values.\n",
    "3. No need for scaling or normalizing data.\n",
    "4. Fast to interpret.\n",
    "5. Great execution speed.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. Can easily overfit if parameters are not tuned properly.\n",
    "2. Hard to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cross validation\n",
    "grid_param  = {\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [1,2],\n",
    "    'min_samples_leaf': [1,2],\n",
    "    'max_leaf_nodes': [4,50,None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=f1,\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_leaf_nodes\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_ca...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_leaf_nodes': [4, 50, None],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [1, 2], 'n_estimators': [100]},\n",
       "             scoring=make_scorer(f1_score, average=micro))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model with different combinations of hyperparameters \n",
    "gd_sr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7769948810599218 {'criterion': 'gini', 'max_leaf_nodes': 4, 'min_samples_leaf': 1, 'min_samples_split': 1, 'n_estimators': 100} XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              criterion='gini', early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=6,\n",
      "              max_leaf_nodes=4, max_leaves=0, min_child_weight=1,\n",
      "              min_samples_leaf=1, min_samples_split=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "              num_parallel_tree=1, ...)\n"
     ]
    }
   ],
   "source": [
    "print (gd_sr.best_score_, gd_sr.best_params_,gd_sr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/xgboost.pkl\",gd_sr.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
