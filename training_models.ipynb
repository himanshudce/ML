{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# import sklearn libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# import torch deep learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "# for reproducability ML\n",
    "np.random.seed(1)\n",
    "RandomState=1\n",
    "\n",
    "# for reproducability of DL\n",
    "manualSeed = 1\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convert feature's string values into numbers to apply models\n",
    "# label_to_key = {}\n",
    "# key_to_label = {}\n",
    "# for i,label in enumerate(sorted(df['Class'].unique())):\n",
    "#     label_to_key[label] = i\n",
    "#     key_to_label[i]= label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0': 'H', '1': 'L', '2': 'M'}, {'H': 0, 'L': 1, 'M': 2})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the json to convert from num to lable\n",
    "with open('Data/processing_models/num_to_label.json') as json_file:\n",
    "    num_to_label = json.load(json_file)\n",
    "\n",
    "with open('Data/processing_models/label_to_num.json') as json_file:\n",
    "    label_to_num = json.load(json_file)\n",
    "\n",
    "num_to_label,label_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save trained model in pickle file\n",
    "def save_pkl_model(path,model):\n",
    "    pickle.dump(model, open(path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load trained model \n",
    "def load_pkl_model(path):\n",
    "    return pickle.load(open(path, 'rb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "Since we have less training data instances, so it may be useful to try LOOCV but as we are performing hyper parameter tunning and with some algorithams like Random Forest it will be computaionally very tedious to use LOOCV, so we used k-fold splits as 10 (not 5) in order to get a good balance of low computational cost and low bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function using gridsearch cv and StratifiedKFold for the training estimation\n",
    "# f1 score rather then accuracy\n",
    "f1 = make_scorer(f1_score, average='micro')\n",
    "# stratified split\n",
    "split_count = 10\n",
    "kf = StratifiedKFold(n_splits=split_count,random_state=RandomState,shuffle=True)\n",
    "# grid search cv\n",
    "def get_best_estimator(classifier,grid_param,X,y):\n",
    "    gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=f1,\n",
    "                     cv=kf,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "    gd_sr.fit(X, y)\n",
    "    return gd_sr.best_score_,gd_sr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to drop columns by matching names of columns\n",
    "def func_dropCol(df,drop_col =['SectionID','StageID','Semester']):\n",
    "    for i in drop_col:\n",
    "        df = df[df.columns.drop(list(df.filter(regex=i)))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_converter(train):\n",
    "    ohe = OneHotEncoder(handle_unknown = 'ignore') \n",
    "    encoded_vec = ohe.fit(train)\n",
    "    ohe_transformed = encoded_vec.transform(train).toarray()\n",
    "    return ohe_transformed,ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state for every model for future use\n",
    "random_state = RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv accuracy for each model\n",
    "acc_wCol = {}\n",
    "accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Naive Bays\n",
    "* **Dataset Passed - Onehot encoded and bxtransformed (Normality)** \n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "The biggest and only assumption is the assumption of conditional independence.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Gives high performance when the conditional independence assumption is satisfied.\n",
    "2. Easy to implement because only probabilities need to be calculated.\n",
    "3. Works well with high-dimensional data, such as text.\n",
    "4. Fast for real-time predictions.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. If conditional independence does not hold, then is performs poorly.\n",
    "2. Has the problem of Numerical Stability or Numerical Underflow because of the multiplication of several small digits.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading classifier \n",
    "classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading one hot encoded box transformed data \n",
    "df = pd.read_csv(\"Data/transformed/train_bx_ohe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Semester_S</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...         1.0          0.0            0.0   \n",
       "1                0.0  ...         0.0          0.0            0.0   \n",
       "2                0.0  ...         0.0          0.0            0.0   \n",
       "3                0.0  ...         0.0          1.0            0.0   \n",
       "4                0.0  ...         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Semester_S  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0         0.0           0.0                        1.0   \n",
       "1            0.0         1.0           1.0                        1.0   \n",
       "2            0.0         1.0           0.0                        0.0   \n",
       "3            0.0         0.0           1.0                        0.0   \n",
       "4            0.0         0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      H  \n",
       "1                            0.0                         0.0      M  \n",
       "2                            0.0                         0.0      L  \n",
       "3                            0.0                         1.0      M  \n",
       "4                            1.0                         1.0      H  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 61)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows(r) and columns(c)  (r,c)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_IT</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_IT  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...       0.0         1.0          0.0            0.0   \n",
       "1                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "2                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "3                0.0  ...       0.0         0.0          1.0            0.0   \n",
       "4                0.0  ...       1.0         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0           0.0                        1.0   \n",
       "1            0.0           1.0                        1.0   \n",
       "2            0.0           0.0                        0.0   \n",
       "3            0.0           1.0                        0.0   \n",
       "4            0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      H  \n",
       "1                            0.0                         0.0      M  \n",
       "2                            0.0                         0.0      L  \n",
       "3                            0.0                         1.0      M  \n",
       "4                            1.0                         1.0      H  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns with less importance\n",
    "df = func_dropCol(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 56)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows(r) and columns(c) in (r,c) format\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_IT</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_IT  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...       0.0         1.0          0.0            0.0   \n",
       "1                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "2                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "3                0.0  ...       0.0         0.0          1.0            0.0   \n",
       "4                0.0  ...       1.0         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0           0.0                        1.0   \n",
       "1            0.0           1.0                        1.0   \n",
       "2            0.0           0.0                        0.0   \n",
       "3            0.0           1.0                        0.0   \n",
       "4            0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      0  \n",
       "1                            0.0                         0.0      2  \n",
       "2                            0.0                         0.0      1  \n",
       "3                            0.0                         1.0      2  \n",
       "4                            1.0                         1.0      0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting Class feature values from str to number\n",
    "df.Class = df.Class.apply(lambda x :label_to_num[x]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting input and target features\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting range of hyperparameters for grid search\n",
    "\n",
    "#var_smoothingfloat, default=1e-9\n",
    "##Portion of the largest variance of all features that is added to variances for calculation stability.\n",
    "grid_param = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6814024390243902 GaussianNB(var_smoothing=0.1)\n"
     ]
    }
   ],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param,X,y)\n",
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_wCol['naive_bayes'] = best_score\n",
    "accuracy['naive_bayes'] = best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/naive_bayes.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Trees \n",
    "\n",
    "* **Data Passed - Min-Max Normalized and one hot encoded data**\n",
    "\n",
    "**Assumptions of algorithm** :\n",
    "\n",
    "1. Initially, whole training data is considered as root.\n",
    "2. Records are distributed recursively on the basis of the attribute value.\n",
    "\n",
    "**Pros** :\n",
    "\n",
    "1. Compared to other algorithms, data preparation requires less time.\n",
    "2. Doesn’t require data to be normalized.\n",
    "3. Missing values, to an extent, don’t affect its performance much.\n",
    "4. Is very intuitive as can be explained as if-else conditions.\n",
    "\n",
    "**Cons**:\n",
    "\n",
    "1. Needs a lot of time to train the model.\n",
    "2. A small change in data can cause a considerably large change in the Decision Tree structure.\n",
    "3. Comparatively expensive to train.\n",
    "4. Not good for regression tasks.\n",
    "\n",
    "https://www.kdnuggets.com/2021/02/machine-learning-assumptions.html \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  (408, 61)\n",
      "shape after removing columns  (408, 56)\n"
     ]
    }
   ],
   "source": [
    "# Data to be used by Decision Tree and Further Algorithams\n",
    "df = pd.read_csv(\"Data/transformed/train_mms_ohe.csv\")\n",
    "print(\"shape \" , df.shape)\n",
    "df = func_dropCol(df)\n",
    "\n",
    "print(\"shape after removing columns \", df.shape)\n",
    "df.Class = df.Class.apply(lambda x :label_to_num[x]) # mapping \n",
    "df.head()\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"],\n",
    "    'max_features':[2,5,10,20,50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.720609756097561 DecisionTreeClassifier(criterion='entropy', max_depth=10, max_features=50,\n",
      "                       min_samples_leaf=10, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param,X,y)\n",
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_wCol['Decision_Tree'] = best_score\n",
    "accuracy['Decision_Tree'] = best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/decision_tree.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random forest\n",
    "* **Data Passed - Min-Max Normalized and one hot encoded data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max features is to consider optimal no. of features in order to manage high variance \n",
    "grid_param = {\n",
    "    'n_estimators': [10,100,500,1000,1500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features':[2,5,10,20,50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112195121951219 RandomForestClassifier(max_features=5, n_estimators=500, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_wCol['Random_forest'] = best_score\n",
    "accuracy['Random_forest'] = best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/random_forest.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression \n",
    "* **Data Passed - Min-Max Normalized and one hot encoded data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 penalty is lasso regression (l1 norm regularization)\n",
    "# l2 penalty is rigid regression (l2 norm regularization)\n",
    "grid_param =  {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 10),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620731707317073 LogisticRegression(C=0.3593813663804626, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_wCol['Logistic_regression'] = best_score\n",
    "accuracy['Logistic_regression'] = best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/logistic_regression.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SVM\n",
    "* **Data Passed - Min-Max Normalized and one hot encoded data**\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "It assumes data is independent and identically distributed.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Works really well on high dimensional data.\n",
    "2. Memory efficient.\n",
    "3. Effective in cases where the number of dimensions is greater than the number of samples.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. Not suitable for large datasets.\n",
    "2. Doesn’t work well when the dataset has noise, i.e., the target classes are overlapping.\n",
    "3. Slow to train.\n",
    "4. No probabilistic explanation for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = { 'C':[0.1,1,100,1000],\n",
    "'kernel':['rbf','poly','sigmoid','linear'],\n",
    "'degree':[1,5,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7967073170731708 SVC(C=100, degree=1, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_wCol['svm'] = best_score\n",
    "accuracy['svm'] = best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/svm.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. XGBOOST\n",
    "* **Data Passed - Min-Max Normalized and one hot encoded data**\n",
    "**Assumptions:**\n",
    "\n",
    "It may have an assumption that encoded integer value for each variable has ordinal relation.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Can work in parallell.\n",
    "2. Can handle missing values.\n",
    "3. No need for scaling or normalizing data.\n",
    "4. Fast to interpret.\n",
    "5. Great execution speed.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. Can easily overfit if parameters are not tuned properly.\n",
    "2. Hard to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cross validation\n",
    "grid_param  = {\n",
    "    'n_estimators': [100,500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2,5],\n",
    "    'min_samples_leaf': [2,5,10],\n",
    "    'max_features':[2,5,20,50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:02:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:03:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:04:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7398170731707318 XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              criterion='gini', early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=6,\n",
      "              max_features=2, max_leaves=0, min_child_weight=1,\n",
      "              min_samples_leaf=2, min_samples_split=2, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "              num_parallel_tree=1, ...)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_wCol['Xgboost'] = best_score\n",
    "accuracy['Xgboost'] = best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/xgboost.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Neural Network\n",
    "* **Data Passed - Min-Max Normalized and one hot encoded data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not applying K fold cross validation here as the deep learning models take high time and memory to train \n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y,test_size=0.15,stratify=y, random_state=RandomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test arrays after converting y to one hot encodding (3 classes)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_train,ohe_train = ohe_converter(y_train)\n",
    "y_test = y_test.values.reshape(-1,1)\n",
    "y_test = ohe_train.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([346, 55]) torch.Size([346, 3])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(X_train,y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 5, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = 5, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([5, 55])\n",
      "Labels batch shape: torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features.view(1,5,60).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ANN Model\n",
    "# we create a new class ANNModel which inherits from nn.Module \n",
    "# define variables in a class and a forward function which uses those variables and perform forward pass \n",
    "class ANNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "        \n",
    "        # Linear function 1: 60 --> 32\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        # self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Linear function 2: 32 --> 32\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        # self.tanh2 = nn.Tanh()\n",
    "        \n",
    "        # Linear function 3: 32 --> 32\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 3\n",
    "        # self.elu3 = nn.ELU()\n",
    "        \n",
    "        # Linear function 4 (readout): 32 --> 1\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = F.relu(self.fc1(x))\n",
    "        # Non-linearity 1\n",
    "        # out = self.relu1(out)\n",
    "        \n",
    "        # Linear function 2\n",
    "        out = F.relu(self.fc2(out)) \n",
    "        # Non-linearity 2\n",
    "        # out = self.relu1(out)\n",
    "        \n",
    "        # Linear function 2\n",
    "        out = F.relu(self.fc3(out))\n",
    "        # Non-linearity 2\n",
    "        # out = self.relu1(out)\n",
    "        \n",
    "        # Linear function 4 (readout)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "        # return F.softmax(out,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate ANN\n",
    "input_dim = train_features.size()[1]\n",
    "hidden_dim = 32 #hidden layer dim is one of the hyper parameter and it should be chosen and tuned. For now I only say 150 there is no reason.\n",
    "output_dim = 3\n",
    "\n",
    "# Create ANN\n",
    "model = ANNModel(input_dim, hidden_dim, output_dim)\n",
    "# to check all working fine, we can simply call model, no need to call specificly forward\n",
    "# model(train_features)\n",
    "# model.forward(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy Loss as multiClass classification\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "# model parameters are those variables for which gradient calculation is true, which can be updated\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ANNModel(\n",
       "  (fc1): Linear(in_features=55, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=3, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0673, grad_fn=<DivBackward1>)\n",
      "tensor(0.9903, grad_fn=<DivBackward1>)\n",
      "tensor(1.0010, grad_fn=<DivBackward1>)\n",
      "tensor(1.0647, grad_fn=<DivBackward1>)\n",
      "tensor(1.1495, grad_fn=<DivBackward1>)\n",
      "tensor(0.9897, grad_fn=<DivBackward1>)\n",
      "tensor(1.1436, grad_fn=<DivBackward1>)\n",
      "tensor(1.2233, grad_fn=<DivBackward1>)\n",
      "tensor(1.0624, grad_fn=<DivBackward1>)\n",
      "tensor(1.0693, grad_fn=<DivBackward1>)\n",
      "tensor(0.9837, grad_fn=<DivBackward1>)\n",
      "tensor(1.1346, grad_fn=<DivBackward1>)\n",
      "tensor(1.1251, grad_fn=<DivBackward1>)\n",
      "tensor(1.1349, grad_fn=<DivBackward1>)\n",
      "tensor(1.0591, grad_fn=<DivBackward1>)\n",
      "tensor(1.0609, grad_fn=<DivBackward1>)\n",
      "tensor(1.1417, grad_fn=<DivBackward1>)\n",
      "tensor(1.0538, grad_fn=<DivBackward1>)\n",
      "tensor(1.1447, grad_fn=<DivBackward1>)\n",
      "tensor(1.0013, grad_fn=<DivBackward1>)\n",
      "tensor(0.9706, grad_fn=<DivBackward1>)\n",
      "tensor(1.1278, grad_fn=<DivBackward1>)\n",
      "tensor(1.1522, grad_fn=<DivBackward1>)\n",
      "tensor(1.1460, grad_fn=<DivBackward1>)\n",
      "tensor(1.0772, grad_fn=<DivBackward1>)\n",
      "tensor(1.0733, grad_fn=<DivBackward1>)\n",
      "tensor(0.9691, grad_fn=<DivBackward1>)\n",
      "tensor(1.1955, grad_fn=<DivBackward1>)\n",
      "tensor(1.0687, grad_fn=<DivBackward1>)\n",
      "tensor(1.1325, grad_fn=<DivBackward1>)\n",
      "tensor(1.0998, grad_fn=<DivBackward1>)\n",
      "tensor(0.9849, grad_fn=<DivBackward1>)\n",
      "tensor(1.0081, grad_fn=<DivBackward1>)\n",
      "tensor(1.1951, grad_fn=<DivBackward1>)\n",
      "tensor(1.0733, grad_fn=<DivBackward1>)\n",
      "tensor(1.1472, grad_fn=<DivBackward1>)\n",
      "tensor(1.1486, grad_fn=<DivBackward1>)\n",
      "tensor(1.0363, grad_fn=<DivBackward1>)\n",
      "tensor(1.1778, grad_fn=<DivBackward1>)\n",
      "tensor(0.9899, grad_fn=<DivBackward1>)\n",
      "tensor(1.1153, grad_fn=<DivBackward1>)\n",
      "tensor(1.1245, grad_fn=<DivBackward1>)\n",
      "tensor(1.0383, grad_fn=<DivBackward1>)\n",
      "tensor(1.0634, grad_fn=<DivBackward1>)\n",
      "tensor(0.9596, grad_fn=<DivBackward1>)\n",
      "tensor(1.1225, grad_fn=<DivBackward1>)\n",
      "tensor(1.1230, grad_fn=<DivBackward1>)\n",
      "tensor(0.9499, grad_fn=<DivBackward1>)\n",
      "tensor(1.1252, grad_fn=<DivBackward1>)\n",
      "tensor(1.0683, grad_fn=<DivBackward1>)\n",
      "tensor(1.1179, grad_fn=<DivBackward1>)\n",
      "tensor(1.1501, grad_fn=<DivBackward1>)\n",
      "tensor(1.1159, grad_fn=<DivBackward1>)\n",
      "tensor(1.0308, grad_fn=<DivBackward1>)\n",
      "tensor(1.1504, grad_fn=<DivBackward1>)\n",
      "tensor(0.9864, grad_fn=<DivBackward1>)\n",
      "tensor(0.9945, grad_fn=<DivBackward1>)\n",
      "tensor(1.0241, grad_fn=<DivBackward1>)\n",
      "tensor(1.1919, grad_fn=<DivBackward1>)\n",
      "tensor(1.0153, grad_fn=<DivBackward1>)\n",
      "tensor(1.0298, grad_fn=<DivBackward1>)\n",
      "tensor(1.2043, grad_fn=<DivBackward1>)\n",
      "tensor(1.0852, grad_fn=<DivBackward1>)\n",
      "tensor(0.9463, grad_fn=<DivBackward1>)\n",
      "tensor(1.1105, grad_fn=<DivBackward1>)\n",
      "tensor(1.1171, grad_fn=<DivBackward1>)\n",
      "tensor(1.2443, grad_fn=<DivBackward1>)\n",
      "tensor(1.0259, grad_fn=<DivBackward1>)\n",
      "tensor(0.9868, grad_fn=<DivBackward1>)\n",
      "tensor(1.1086, grad_fn=<DivBackward1>)\n",
      "tensor(0.9932, grad_fn=<DivBackward1>)\n",
      "tensor(0.9766, grad_fn=<DivBackward1>)\n",
      "tensor(1.0575, grad_fn=<DivBackward1>)\n",
      "tensor(1.0997, grad_fn=<DivBackward1>)\n",
      "tensor(1.0856, grad_fn=<DivBackward1>)\n",
      "tensor(1.0103, grad_fn=<DivBackward1>)\n",
      "tensor(1.1511, grad_fn=<DivBackward1>)\n",
      "tensor(1.2099, grad_fn=<DivBackward1>)\n",
      "tensor(1.0288, grad_fn=<DivBackward1>)\n",
      "tensor(1.0956, grad_fn=<DivBackward1>)\n",
      "tensor(0.9725, grad_fn=<DivBackward1>)\n",
      "tensor(1.1133, grad_fn=<DivBackward1>)\n",
      "tensor(1.0786, grad_fn=<DivBackward1>)\n",
      "tensor(1.1142, grad_fn=<DivBackward1>)\n",
      "tensor(1.0270, grad_fn=<DivBackward1>)\n",
      "tensor(1.0627, grad_fn=<DivBackward1>)\n",
      "tensor(1.1178, grad_fn=<DivBackward1>)\n",
      "tensor(1.0256, grad_fn=<DivBackward1>)\n",
      "tensor(1.1189, grad_fn=<DivBackward1>)\n",
      "tensor(1.0186, grad_fn=<DivBackward1>)\n",
      "tensor(0.9317, grad_fn=<DivBackward1>)\n",
      "tensor(1.1095, grad_fn=<DivBackward1>)\n",
      "tensor(1.1606, grad_fn=<DivBackward1>)\n",
      "tensor(1.1530, grad_fn=<DivBackward1>)\n",
      "tensor(1.1031, grad_fn=<DivBackward1>)\n",
      "tensor(1.0641, grad_fn=<DivBackward1>)\n",
      "tensor(0.9366, grad_fn=<DivBackward1>)\n",
      "tensor(1.1640, grad_fn=<DivBackward1>)\n",
      "tensor(1.0643, grad_fn=<DivBackward1>)\n",
      "tensor(1.1139, grad_fn=<DivBackward1>)\n",
      "tensor(1.0635, grad_fn=<DivBackward1>)\n",
      "tensor(0.9768, grad_fn=<DivBackward1>)\n",
      "tensor(1.0231, grad_fn=<DivBackward1>)\n",
      "tensor(1.1567, grad_fn=<DivBackward1>)\n",
      "tensor(1.0687, grad_fn=<DivBackward1>)\n",
      "tensor(1.1505, grad_fn=<DivBackward1>)\n",
      "tensor(1.1535, grad_fn=<DivBackward1>)\n",
      "tensor(1.0133, grad_fn=<DivBackward1>)\n",
      "tensor(1.1439, grad_fn=<DivBackward1>)\n",
      "tensor(0.9831, grad_fn=<DivBackward1>)\n",
      "tensor(1.1604, grad_fn=<DivBackward1>)\n",
      "tensor(1.1050, grad_fn=<DivBackward1>)\n",
      "tensor(1.0164, grad_fn=<DivBackward1>)\n",
      "tensor(1.0659, grad_fn=<DivBackward1>)\n",
      "tensor(0.9334, grad_fn=<DivBackward1>)\n",
      "tensor(1.1040, grad_fn=<DivBackward1>)\n",
      "tensor(1.1065, grad_fn=<DivBackward1>)\n",
      "tensor(0.9236, grad_fn=<DivBackward1>)\n",
      "tensor(1.1069, grad_fn=<DivBackward1>)\n",
      "tensor(1.0670, grad_fn=<DivBackward1>)\n",
      "tensor(1.1051, grad_fn=<DivBackward1>)\n",
      "tensor(1.1554, grad_fn=<DivBackward1>)\n",
      "tensor(1.0963, grad_fn=<DivBackward1>)\n",
      "tensor(1.0112, grad_fn=<DivBackward1>)\n",
      "tensor(1.1555, grad_fn=<DivBackward1>)\n",
      "tensor(0.9785, grad_fn=<DivBackward1>)\n",
      "tensor(0.9555, grad_fn=<DivBackward1>)\n",
      "tensor(1.0014, grad_fn=<DivBackward1>)\n",
      "tensor(1.2192, grad_fn=<DivBackward1>)\n",
      "tensor(1.0267, grad_fn=<DivBackward1>)\n",
      "tensor(1.0114, grad_fn=<DivBackward1>)\n",
      "tensor(1.1920, grad_fn=<DivBackward1>)\n",
      "tensor(1.0578, grad_fn=<DivBackward1>)\n",
      "tensor(0.9231, grad_fn=<DivBackward1>)\n",
      "tensor(1.1283, grad_fn=<DivBackward1>)\n",
      "tensor(1.1013, grad_fn=<DivBackward1>)\n",
      "tensor(1.2194, grad_fn=<DivBackward1>)\n",
      "tensor(1.0100, grad_fn=<DivBackward1>)\n",
      "tensor(0.9810, grad_fn=<DivBackward1>)\n",
      "tensor(1.1528, grad_fn=<DivBackward1>)\n",
      "tensor(0.9569, grad_fn=<DivBackward1>)\n",
      "tensor(0.9707, grad_fn=<DivBackward1>)\n",
      "tensor(1.0852, grad_fn=<DivBackward1>)\n",
      "tensor(1.1165, grad_fn=<DivBackward1>)\n",
      "tensor(1.0518, grad_fn=<DivBackward1>)\n",
      "tensor(1.0205, grad_fn=<DivBackward1>)\n",
      "tensor(1.1527, grad_fn=<DivBackward1>)\n",
      "tensor(1.1997, grad_fn=<DivBackward1>)\n",
      "tensor(1.0105, grad_fn=<DivBackward1>)\n",
      "tensor(1.1045, grad_fn=<DivBackward1>)\n",
      "tensor(0.9680, grad_fn=<DivBackward1>)\n",
      "tensor(1.1002, grad_fn=<DivBackward1>)\n",
      "tensor(1.0554, grad_fn=<DivBackward1>)\n",
      "tensor(1.1001, grad_fn=<DivBackward1>)\n",
      "tensor(1.0101, grad_fn=<DivBackward1>)\n",
      "tensor(1.0626, grad_fn=<DivBackward1>)\n",
      "tensor(1.1002, grad_fn=<DivBackward1>)\n",
      "tensor(1.0114, grad_fn=<DivBackward1>)\n",
      "tensor(1.1006, grad_fn=<DivBackward1>)\n",
      "tensor(1.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.9132, grad_fn=<DivBackward1>)\n",
      "tensor(1.0983, grad_fn=<DivBackward1>)\n",
      "tensor(1.1603, grad_fn=<DivBackward1>)\n",
      "tensor(1.1497, grad_fn=<DivBackward1>)\n",
      "tensor(1.1114, grad_fn=<DivBackward1>)\n",
      "tensor(1.0527, grad_fn=<DivBackward1>)\n",
      "tensor(0.9226, grad_fn=<DivBackward1>)\n",
      "tensor(1.1468, grad_fn=<DivBackward1>)\n",
      "tensor(1.0568, grad_fn=<DivBackward1>)\n",
      "tensor(1.1010, grad_fn=<DivBackward1>)\n",
      "tensor(1.0458, grad_fn=<DivBackward1>)\n",
      "tensor(0.9717, grad_fn=<DivBackward1>)\n",
      "tensor(1.0282, grad_fn=<DivBackward1>)\n",
      "tensor(1.1266, grad_fn=<DivBackward1>)\n",
      "tensor(1.0617, grad_fn=<DivBackward1>)\n",
      "tensor(1.1433, grad_fn=<DivBackward1>)\n",
      "tensor(1.1478, grad_fn=<DivBackward1>)\n",
      "tensor(0.9980, grad_fn=<DivBackward1>)\n",
      "tensor(1.1180, grad_fn=<DivBackward1>)\n",
      "tensor(0.9794, grad_fn=<DivBackward1>)\n",
      "tensor(1.1780, grad_fn=<DivBackward1>)\n",
      "tensor(1.0877, grad_fn=<DivBackward1>)\n",
      "tensor(1.0022, grad_fn=<DivBackward1>)\n",
      "tensor(1.0650, grad_fn=<DivBackward1>)\n",
      "tensor(0.9240, grad_fn=<DivBackward1>)\n",
      "tensor(1.0851, grad_fn=<DivBackward1>)\n",
      "tensor(1.0910, grad_fn=<DivBackward1>)\n",
      "tensor(0.9112, grad_fn=<DivBackward1>)\n",
      "tensor(1.0882, grad_fn=<DivBackward1>)\n",
      "tensor(1.0613, grad_fn=<DivBackward1>)\n",
      "tensor(1.0932, grad_fn=<DivBackward1>)\n",
      "tensor(1.1498, grad_fn=<DivBackward1>)\n",
      "tensor(1.0742, grad_fn=<DivBackward1>)\n",
      "tensor(0.9982, grad_fn=<DivBackward1>)\n",
      "tensor(1.1495, grad_fn=<DivBackward1>)\n",
      "tensor(0.9725, grad_fn=<DivBackward1>)\n",
      "tensor(0.9326, grad_fn=<DivBackward1>)\n",
      "tensor(0.9827, grad_fn=<DivBackward1>)\n",
      "tensor(1.2261, grad_fn=<DivBackward1>)\n",
      "tensor(1.0285, grad_fn=<DivBackward1>)\n",
      "tensor(0.9975, grad_fn=<DivBackward1>)\n",
      "tensor(1.1744, grad_fn=<DivBackward1>)\n",
      "tensor(1.0420, grad_fn=<DivBackward1>)\n",
      "tensor(0.9105, grad_fn=<DivBackward1>)\n",
      "tensor(1.1332, grad_fn=<DivBackward1>)\n",
      "tensor(1.0823, grad_fn=<DivBackward1>)\n",
      "tensor(1.1867, grad_fn=<DivBackward1>)\n",
      "tensor(1.0004, grad_fn=<DivBackward1>)\n",
      "tensor(0.9753, grad_fn=<DivBackward1>)\n",
      "tensor(1.1664, grad_fn=<DivBackward1>)\n",
      "tensor(0.9317, grad_fn=<DivBackward1>)\n",
      "tensor(0.9643, grad_fn=<DivBackward1>)\n",
      "tensor(1.0956, grad_fn=<DivBackward1>)\n",
      "tensor(1.1200, grad_fn=<DivBackward1>)\n",
      "tensor(1.0209, grad_fn=<DivBackward1>)\n",
      "tensor(1.0227, grad_fn=<DivBackward1>)\n",
      "tensor(1.1436, grad_fn=<DivBackward1>)\n",
      "tensor(1.1815, grad_fn=<DivBackward1>)\n",
      "tensor(0.9929, grad_fn=<DivBackward1>)\n",
      "tensor(1.0971, grad_fn=<DivBackward1>)\n",
      "tensor(0.9642, grad_fn=<DivBackward1>)\n",
      "tensor(1.0826, grad_fn=<DivBackward1>)\n",
      "tensor(1.0379, grad_fn=<DivBackward1>)\n",
      "tensor(1.0830, grad_fn=<DivBackward1>)\n",
      "tensor(0.9949, grad_fn=<DivBackward1>)\n",
      "tensor(1.0574, grad_fn=<DivBackward1>)\n",
      "tensor(1.0758, grad_fn=<DivBackward1>)\n",
      "tensor(0.9983, grad_fn=<DivBackward1>)\n",
      "tensor(1.0747, grad_fn=<DivBackward1>)\n",
      "tensor(1.0227, grad_fn=<DivBackward1>)\n",
      "tensor(0.9013, grad_fn=<DivBackward1>)\n",
      "tensor(1.0835, grad_fn=<DivBackward1>)\n",
      "tensor(1.1489, grad_fn=<DivBackward1>)\n",
      "tensor(1.1309, grad_fn=<DivBackward1>)\n",
      "tensor(1.1057, grad_fn=<DivBackward1>)\n",
      "tensor(1.0298, grad_fn=<DivBackward1>)\n",
      "tensor(0.9156, grad_fn=<DivBackward1>)\n",
      "tensor(1.1313, grad_fn=<DivBackward1>)\n",
      "tensor(1.0394, grad_fn=<DivBackward1>)\n",
      "tensor(1.0811, grad_fn=<DivBackward1>)\n",
      "tensor(1.0335, grad_fn=<DivBackward1>)\n",
      "tensor(0.9650, grad_fn=<DivBackward1>)\n",
      "tensor(1.0242, grad_fn=<DivBackward1>)\n",
      "tensor(1.0844, grad_fn=<DivBackward1>)\n",
      "tensor(1.0452, grad_fn=<DivBackward1>)\n",
      "tensor(1.1182, grad_fn=<DivBackward1>)\n",
      "tensor(1.1256, grad_fn=<DivBackward1>)\n",
      "tensor(0.9804, grad_fn=<DivBackward1>)\n",
      "tensor(1.0809, grad_fn=<DivBackward1>)\n",
      "tensor(0.9752, grad_fn=<DivBackward1>)\n",
      "tensor(1.1756, grad_fn=<DivBackward1>)\n",
      "tensor(1.0604, grad_fn=<DivBackward1>)\n",
      "tensor(0.9837, grad_fn=<DivBackward1>)\n",
      "tensor(1.0585, grad_fn=<DivBackward1>)\n",
      "tensor(0.9263, grad_fn=<DivBackward1>)\n",
      "tensor(1.0521, grad_fn=<DivBackward1>)\n",
      "tensor(1.0640, grad_fn=<DivBackward1>)\n",
      "tensor(0.9039, grad_fn=<DivBackward1>)\n",
      "tensor(1.0542, grad_fn=<DivBackward1>)\n",
      "tensor(1.0430, grad_fn=<DivBackward1>)\n",
      "tensor(1.0720, grad_fn=<DivBackward1>)\n",
      "tensor(1.1274, grad_fn=<DivBackward1>)\n",
      "tensor(1.0372, grad_fn=<DivBackward1>)\n",
      "tensor(0.9830, grad_fn=<DivBackward1>)\n",
      "tensor(1.1242, grad_fn=<DivBackward1>)\n",
      "tensor(0.9623, grad_fn=<DivBackward1>)\n",
      "tensor(0.9094, grad_fn=<DivBackward1>)\n",
      "tensor(0.9545, grad_fn=<DivBackward1>)\n",
      "tensor(1.2156, grad_fn=<DivBackward1>)\n",
      "tensor(1.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.9788, grad_fn=<DivBackward1>)\n",
      "tensor(1.1340, grad_fn=<DivBackward1>)\n",
      "tensor(1.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.8992, grad_fn=<DivBackward1>)\n",
      "tensor(1.1242, grad_fn=<DivBackward1>)\n",
      "tensor(1.0449, grad_fn=<DivBackward1>)\n",
      "tensor(1.1217, grad_fn=<DivBackward1>)\n",
      "tensor(0.9880, grad_fn=<DivBackward1>)\n",
      "tensor(0.9641, grad_fn=<DivBackward1>)\n",
      "tensor(1.1543, grad_fn=<DivBackward1>)\n",
      "tensor(0.9017, grad_fn=<DivBackward1>)\n",
      "tensor(0.9521, grad_fn=<DivBackward1>)\n",
      "tensor(1.0952, grad_fn=<DivBackward1>)\n",
      "tensor(1.1090, grad_fn=<DivBackward1>)\n",
      "tensor(0.9710, grad_fn=<DivBackward1>)\n",
      "tensor(1.0162, grad_fn=<DivBackward1>)\n",
      "tensor(1.1178, grad_fn=<DivBackward1>)\n",
      "tensor(1.1394, grad_fn=<DivBackward1>)\n",
      "tensor(0.9639, grad_fn=<DivBackward1>)\n",
      "tensor(1.0650, grad_fn=<DivBackward1>)\n",
      "tensor(0.9594, grad_fn=<DivBackward1>)\n",
      "tensor(1.0496, grad_fn=<DivBackward1>)\n",
      "tensor(1.0132, grad_fn=<DivBackward1>)\n",
      "tensor(1.0479, grad_fn=<DivBackward1>)\n",
      "tensor(0.9698, grad_fn=<DivBackward1>)\n",
      "tensor(1.0420, grad_fn=<DivBackward1>)\n",
      "tensor(1.0252, grad_fn=<DivBackward1>)\n",
      "tensor(0.9782, grad_fn=<DivBackward1>)\n",
      "tensor(1.0203, grad_fn=<DivBackward1>)\n",
      "tensor(1.0073, grad_fn=<DivBackward1>)\n",
      "tensor(0.8884, grad_fn=<DivBackward1>)\n",
      "tensor(1.0496, grad_fn=<DivBackward1>)\n",
      "tensor(1.1155, grad_fn=<DivBackward1>)\n",
      "tensor(1.0805, grad_fn=<DivBackward1>)\n",
      "tensor(1.0797, grad_fn=<DivBackward1>)\n",
      "tensor(0.9776, grad_fn=<DivBackward1>)\n",
      "tensor(0.9131, grad_fn=<DivBackward1>)\n",
      "tensor(1.1044, grad_fn=<DivBackward1>)\n",
      "tensor(0.9961, grad_fn=<DivBackward1>)\n",
      "tensor(1.0383, grad_fn=<DivBackward1>)\n",
      "tensor(1.0182, grad_fn=<DivBackward1>)\n",
      "tensor(0.9513, grad_fn=<DivBackward1>)\n",
      "tensor(1.0068, grad_fn=<DivBackward1>)\n",
      "tensor(0.9957, grad_fn=<DivBackward1>)\n",
      "tensor(1.0056, grad_fn=<DivBackward1>)\n",
      "tensor(1.0532, grad_fn=<DivBackward1>)\n",
      "tensor(1.0635, grad_fn=<DivBackward1>)\n",
      "tensor(0.9471, grad_fn=<DivBackward1>)\n",
      "tensor(0.9967, grad_fn=<DivBackward1>)\n",
      "tensor(0.9695, grad_fn=<DivBackward1>)\n",
      "tensor(1.1494, grad_fn=<DivBackward1>)\n",
      "tensor(0.9972, grad_fn=<DivBackward1>)\n",
      "tensor(0.9450, grad_fn=<DivBackward1>)\n",
      "tensor(1.0379, grad_fn=<DivBackward1>)\n",
      "tensor(0.9481, grad_fn=<DivBackward1>)\n",
      "tensor(0.9733, grad_fn=<DivBackward1>)\n",
      "tensor(0.9992, grad_fn=<DivBackward1>)\n",
      "tensor(0.9005, grad_fn=<DivBackward1>)\n",
      "tensor(0.9745, grad_fn=<DivBackward1>)\n",
      "tensor(0.9953, grad_fn=<DivBackward1>)\n",
      "tensor(1.0210, grad_fn=<DivBackward1>)\n",
      "tensor(1.0632, grad_fn=<DivBackward1>)\n",
      "tensor(0.9542, grad_fn=<DivBackward1>)\n",
      "tensor(0.9550, grad_fn=<DivBackward1>)\n",
      "tensor(1.0525, grad_fn=<DivBackward1>)\n",
      "tensor(0.9397, grad_fn=<DivBackward1>)\n",
      "tensor(0.8674, grad_fn=<DivBackward1>)\n",
      "tensor(0.9000, grad_fn=<DivBackward1>)\n",
      "tensor(1.1763, grad_fn=<DivBackward1>)\n",
      "tensor(0.9980, grad_fn=<DivBackward1>)\n",
      "tensor(0.9430, grad_fn=<DivBackward1>)\n",
      "tensor(1.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.9717, grad_fn=<DivBackward1>)\n",
      "tensor(0.8812, grad_fn=<DivBackward1>)\n",
      "tensor(1.0893, grad_fn=<DivBackward1>)\n",
      "tensor(0.9558, grad_fn=<DivBackward1>)\n",
      "tensor(0.9672, grad_fn=<DivBackward1>)\n",
      "tensor(0.9594, grad_fn=<DivBackward1>)\n",
      "tensor(0.9366, grad_fn=<DivBackward1>)\n",
      "tensor(1.1082, grad_fn=<DivBackward1>)\n",
      "tensor(0.8433, grad_fn=<DivBackward1>)\n",
      "tensor(0.9255, grad_fn=<DivBackward1>)\n",
      "tensor(1.0845, grad_fn=<DivBackward1>)\n",
      "tensor(1.0719, grad_fn=<DivBackward1>)\n",
      "tensor(0.8694, grad_fn=<DivBackward1>)\n",
      "tensor(0.9953, grad_fn=<DivBackward1>)\n",
      "tensor(1.0536, grad_fn=<DivBackward1>)\n",
      "tensor(1.0360, grad_fn=<DivBackward1>)\n",
      "tensor(0.9065, grad_fn=<DivBackward1>)\n",
      "tensor(0.9843, grad_fn=<DivBackward1>)\n",
      "tensor(0.9540, grad_fn=<DivBackward1>)\n",
      "tensor(0.9702, grad_fn=<DivBackward1>)\n",
      "tensor(0.9616, grad_fn=<DivBackward1>)\n",
      "tensor(0.9645, grad_fn=<DivBackward1>)\n",
      "tensor(0.9138, grad_fn=<DivBackward1>)\n",
      "tensor(1.0030, grad_fn=<DivBackward1>)\n",
      "tensor(0.9082, grad_fn=<DivBackward1>)\n",
      "tensor(0.9379, grad_fn=<DivBackward1>)\n",
      "tensor(0.8998, grad_fn=<DivBackward1>)\n",
      "tensor(0.9650, grad_fn=<DivBackward1>)\n",
      "tensor(0.8677, grad_fn=<DivBackward1>)\n",
      "tensor(0.9653, grad_fn=<DivBackward1>)\n",
      "tensor(1.0340, grad_fn=<DivBackward1>)\n",
      "tensor(0.9593, grad_fn=<DivBackward1>)\n",
      "tensor(1.0219, grad_fn=<DivBackward1>)\n",
      "tensor(0.8752, grad_fn=<DivBackward1>)\n",
      "tensor(0.9128, grad_fn=<DivBackward1>)\n",
      "tensor(1.0507, grad_fn=<DivBackward1>)\n",
      "tensor(0.9032, grad_fn=<DivBackward1>)\n",
      "tensor(0.9377, grad_fn=<DivBackward1>)\n",
      "tensor(0.9880, grad_fn=<DivBackward1>)\n",
      "tensor(0.9197, grad_fn=<DivBackward1>)\n",
      "tensor(0.9612, grad_fn=<DivBackward1>)\n",
      "tensor(0.8093, grad_fn=<DivBackward1>)\n",
      "tensor(0.9225, grad_fn=<DivBackward1>)\n",
      "tensor(0.9172, grad_fn=<DivBackward1>)\n",
      "tensor(0.9239, grad_fn=<DivBackward1>)\n",
      "tensor(0.8844, grad_fn=<DivBackward1>)\n",
      "tensor(0.8194, grad_fn=<DivBackward1>)\n",
      "tensor(0.9594, grad_fn=<DivBackward1>)\n",
      "tensor(1.0869, grad_fn=<DivBackward1>)\n",
      "tensor(0.8708, grad_fn=<DivBackward1>)\n",
      "tensor(0.8581, grad_fn=<DivBackward1>)\n",
      "tensor(0.9814, grad_fn=<DivBackward1>)\n",
      "tensor(1.0196, grad_fn=<DivBackward1>)\n",
      "tensor(0.8192, grad_fn=<DivBackward1>)\n",
      "tensor(0.8627, grad_fn=<DivBackward1>)\n",
      "tensor(0.9032, grad_fn=<DivBackward1>)\n",
      "tensor(0.8204, grad_fn=<DivBackward1>)\n",
      "tensor(0.8910, grad_fn=<DivBackward1>)\n",
      "tensor(0.9192, grad_fn=<DivBackward1>)\n",
      "tensor(0.9338, grad_fn=<DivBackward1>)\n",
      "tensor(0.8071, grad_fn=<DivBackward1>)\n",
      "tensor(0.9135, grad_fn=<DivBackward1>)\n",
      "tensor(0.9096, grad_fn=<DivBackward1>)\n",
      "tensor(0.8850, grad_fn=<DivBackward1>)\n",
      "tensor(0.7926, grad_fn=<DivBackward1>)\n",
      "tensor(0.8060, grad_fn=<DivBackward1>)\n",
      "tensor(1.1045, grad_fn=<DivBackward1>)\n",
      "tensor(0.9348, grad_fn=<DivBackward1>)\n",
      "tensor(0.8872, grad_fn=<DivBackward1>)\n",
      "tensor(0.8531, grad_fn=<DivBackward1>)\n",
      "tensor(0.8711, grad_fn=<DivBackward1>)\n",
      "tensor(0.8369, grad_fn=<DivBackward1>)\n",
      "tensor(1.0018, grad_fn=<DivBackward1>)\n",
      "tensor(0.7886, grad_fn=<DivBackward1>)\n",
      "tensor(0.6893, grad_fn=<DivBackward1>)\n",
      "tensor(0.8945, grad_fn=<DivBackward1>)\n",
      "tensor(0.8736, grad_fn=<DivBackward1>)\n",
      "tensor(1.0112, grad_fn=<DivBackward1>)\n",
      "tensor(0.7430, grad_fn=<DivBackward1>)\n",
      "tensor(0.8639, grad_fn=<DivBackward1>)\n",
      "tensor(1.0475, grad_fn=<DivBackward1>)\n",
      "tensor(0.9891, grad_fn=<DivBackward1>)\n",
      "tensor(0.6915, grad_fn=<DivBackward1>)\n",
      "tensor(0.9455, grad_fn=<DivBackward1>)\n",
      "tensor(0.9476, grad_fn=<DivBackward1>)\n",
      "tensor(0.8438, grad_fn=<DivBackward1>)\n",
      "tensor(0.8216, grad_fn=<DivBackward1>)\n",
      "tensor(0.8352, grad_fn=<DivBackward1>)\n",
      "tensor(0.9688, grad_fn=<DivBackward1>)\n",
      "tensor(0.8260, grad_fn=<DivBackward1>)\n",
      "tensor(0.8798, grad_fn=<DivBackward1>)\n",
      "tensor(0.8193, grad_fn=<DivBackward1>)\n",
      "tensor(0.8179, grad_fn=<DivBackward1>)\n",
      "tensor(0.9320, grad_fn=<DivBackward1>)\n",
      "tensor(0.7179, grad_fn=<DivBackward1>)\n",
      "tensor(0.8755, grad_fn=<DivBackward1>)\n",
      "tensor(0.7141, grad_fn=<DivBackward1>)\n",
      "tensor(0.8804, grad_fn=<DivBackward1>)\n",
      "tensor(0.8414, grad_fn=<DivBackward1>)\n",
      "tensor(0.8218, grad_fn=<DivBackward1>)\n",
      "tensor(0.9079, grad_fn=<DivBackward1>)\n",
      "tensor(0.7629, grad_fn=<DivBackward1>)\n",
      "tensor(0.9268, grad_fn=<DivBackward1>)\n",
      "tensor(0.7295, grad_fn=<DivBackward1>)\n",
      "tensor(0.9081, grad_fn=<DivBackward1>)\n",
      "tensor(0.9942, grad_fn=<DivBackward1>)\n",
      "tensor(0.7598, grad_fn=<DivBackward1>)\n",
      "tensor(0.7872, grad_fn=<DivBackward1>)\n",
      "tensor(0.9729, grad_fn=<DivBackward1>)\n",
      "tensor(0.8669, grad_fn=<DivBackward1>)\n",
      "tensor(0.8721, grad_fn=<DivBackward1>)\n",
      "tensor(0.5661, grad_fn=<DivBackward1>)\n",
      "tensor(0.8005, grad_fn=<DivBackward1>)\n",
      "tensor(0.7420, grad_fn=<DivBackward1>)\n",
      "tensor(0.7290, grad_fn=<DivBackward1>)\n",
      "tensor(0.8129, grad_fn=<DivBackward1>)\n",
      "tensor(0.5806, grad_fn=<DivBackward1>)\n",
      "tensor(0.9641, grad_fn=<DivBackward1>)\n",
      "tensor(1.0016, grad_fn=<DivBackward1>)\n",
      "tensor(0.7099, grad_fn=<DivBackward1>)\n",
      "tensor(0.7332, grad_fn=<DivBackward1>)\n",
      "tensor(0.8786, grad_fn=<DivBackward1>)\n",
      "tensor(1.1795, grad_fn=<DivBackward1>)\n",
      "tensor(0.6385, grad_fn=<DivBackward1>)\n",
      "tensor(0.6924, grad_fn=<DivBackward1>)\n",
      "tensor(0.9141, grad_fn=<DivBackward1>)\n",
      "tensor(0.6478, grad_fn=<DivBackward1>)\n",
      "tensor(0.7584, grad_fn=<DivBackward1>)\n",
      "tensor(0.7929, grad_fn=<DivBackward1>)\n",
      "tensor(0.7834, grad_fn=<DivBackward1>)\n",
      "tensor(0.6459, grad_fn=<DivBackward1>)\n",
      "tensor(0.8864, grad_fn=<DivBackward1>)\n",
      "tensor(0.7466, grad_fn=<DivBackward1>)\n",
      "tensor(0.8070, grad_fn=<DivBackward1>)\n",
      "tensor(0.6978, grad_fn=<DivBackward1>)\n",
      "tensor(0.7020, grad_fn=<DivBackward1>)\n",
      "tensor(1.0412, grad_fn=<DivBackward1>)\n",
      "tensor(0.8327, grad_fn=<DivBackward1>)\n",
      "tensor(0.8372, grad_fn=<DivBackward1>)\n",
      "tensor(0.6789, grad_fn=<DivBackward1>)\n",
      "tensor(0.7710, grad_fn=<DivBackward1>)\n",
      "tensor(0.7716, grad_fn=<DivBackward1>)\n",
      "tensor(0.8857, grad_fn=<DivBackward1>)\n",
      "tensor(0.6306, grad_fn=<DivBackward1>)\n",
      "tensor(0.4491, grad_fn=<DivBackward1>)\n",
      "tensor(0.8015, grad_fn=<DivBackward1>)\n",
      "tensor(0.7905, grad_fn=<DivBackward1>)\n",
      "tensor(0.8863, grad_fn=<DivBackward1>)\n",
      "tensor(0.6438, grad_fn=<DivBackward1>)\n",
      "tensor(0.7836, grad_fn=<DivBackward1>)\n",
      "tensor(0.9631, grad_fn=<DivBackward1>)\n",
      "tensor(0.8851, grad_fn=<DivBackward1>)\n",
      "tensor(0.5518, grad_fn=<DivBackward1>)\n",
      "tensor(0.8686, grad_fn=<DivBackward1>)\n",
      "tensor(0.8617, grad_fn=<DivBackward1>)\n",
      "tensor(0.6656, grad_fn=<DivBackward1>)\n",
      "tensor(0.7668, grad_fn=<DivBackward1>)\n",
      "tensor(0.6917, grad_fn=<DivBackward1>)\n",
      "tensor(1.0181, grad_fn=<DivBackward1>)\n",
      "tensor(0.7067, grad_fn=<DivBackward1>)\n",
      "tensor(0.8122, grad_fn=<DivBackward1>)\n",
      "tensor(0.7055, grad_fn=<DivBackward1>)\n",
      "tensor(0.7198, grad_fn=<DivBackward1>)\n",
      "tensor(0.8591, grad_fn=<DivBackward1>)\n",
      "tensor(0.5743, grad_fn=<DivBackward1>)\n",
      "tensor(0.8069, grad_fn=<DivBackward1>)\n",
      "tensor(0.5789, grad_fn=<DivBackward1>)\n",
      "tensor(0.7893, grad_fn=<DivBackward1>)\n",
      "tensor(0.8042, grad_fn=<DivBackward1>)\n",
      "tensor(0.7012, grad_fn=<DivBackward1>)\n",
      "tensor(0.8162, grad_fn=<DivBackward1>)\n",
      "tensor(0.6143, grad_fn=<DivBackward1>)\n",
      "tensor(0.8326, grad_fn=<DivBackward1>)\n",
      "tensor(0.6392, grad_fn=<DivBackward1>)\n",
      "tensor(0.8485, grad_fn=<DivBackward1>)\n",
      "tensor(1.0319, grad_fn=<DivBackward1>)\n",
      "tensor(0.6472, grad_fn=<DivBackward1>)\n",
      "tensor(0.6918, grad_fn=<DivBackward1>)\n",
      "tensor(0.9824, grad_fn=<DivBackward1>)\n",
      "tensor(0.8091, grad_fn=<DivBackward1>)\n",
      "tensor(0.7821, grad_fn=<DivBackward1>)\n",
      "tensor(0.4422, grad_fn=<DivBackward1>)\n",
      "tensor(0.7052, grad_fn=<DivBackward1>)\n",
      "tensor(0.6309, grad_fn=<DivBackward1>)\n",
      "tensor(0.6116, grad_fn=<DivBackward1>)\n",
      "tensor(0.7512, grad_fn=<DivBackward1>)\n",
      "tensor(0.4406, grad_fn=<DivBackward1>)\n",
      "tensor(0.9739, grad_fn=<DivBackward1>)\n",
      "tensor(0.9600, grad_fn=<DivBackward1>)\n",
      "tensor(0.6309, grad_fn=<DivBackward1>)\n",
      "tensor(0.6456, grad_fn=<DivBackward1>)\n",
      "tensor(0.7786, grad_fn=<DivBackward1>)\n",
      "tensor(1.2634, grad_fn=<DivBackward1>)\n",
      "tensor(0.5421, grad_fn=<DivBackward1>)\n",
      "tensor(0.6048, grad_fn=<DivBackward1>)\n",
      "tensor(0.8611, grad_fn=<DivBackward1>)\n",
      "tensor(0.5652, grad_fn=<DivBackward1>)\n",
      "tensor(0.6793, grad_fn=<DivBackward1>)\n",
      "tensor(0.6964, grad_fn=<DivBackward1>)\n",
      "tensor(0.7198, grad_fn=<DivBackward1>)\n",
      "tensor(0.5515, grad_fn=<DivBackward1>)\n",
      "tensor(0.8928, grad_fn=<DivBackward1>)\n",
      "tensor(0.6599, grad_fn=<DivBackward1>)\n",
      "tensor(0.7526, grad_fn=<DivBackward1>)\n",
      "tensor(0.6097, grad_fn=<DivBackward1>)\n",
      "tensor(0.6070, grad_fn=<DivBackward1>)\n",
      "tensor(1.0027, grad_fn=<DivBackward1>)\n",
      "tensor(0.7489, grad_fn=<DivBackward1>)\n",
      "tensor(0.7816, grad_fn=<DivBackward1>)\n",
      "tensor(0.5813, grad_fn=<DivBackward1>)\n",
      "tensor(0.7264, grad_fn=<DivBackward1>)\n",
      "tensor(0.7136, grad_fn=<DivBackward1>)\n",
      "tensor(0.8068, grad_fn=<DivBackward1>)\n",
      "tensor(0.5594, grad_fn=<DivBackward1>)\n",
      "tensor(0.3497, grad_fn=<DivBackward1>)\n",
      "tensor(0.7140, grad_fn=<DivBackward1>)\n",
      "tensor(0.7297, grad_fn=<DivBackward1>)\n",
      "tensor(0.7922, grad_fn=<DivBackward1>)\n",
      "tensor(0.5734, grad_fn=<DivBackward1>)\n",
      "tensor(0.7194, grad_fn=<DivBackward1>)\n",
      "tensor(0.8654, grad_fn=<DivBackward1>)\n",
      "tensor(0.8056, grad_fn=<DivBackward1>)\n",
      "tensor(0.4890, grad_fn=<DivBackward1>)\n",
      "tensor(0.7984, grad_fn=<DivBackward1>)\n",
      "tensor(0.7923, grad_fn=<DivBackward1>)\n",
      "tensor(0.5717, grad_fn=<DivBackward1>)\n",
      "tensor(0.7380, grad_fn=<DivBackward1>)\n",
      "tensor(0.6101, grad_fn=<DivBackward1>)\n",
      "tensor(1.0514, grad_fn=<DivBackward1>)\n",
      "tensor(0.6557, grad_fn=<DivBackward1>)\n",
      "tensor(0.7581, grad_fn=<DivBackward1>)\n",
      "tensor(0.6541, grad_fn=<DivBackward1>)\n",
      "tensor(0.6438, grad_fn=<DivBackward1>)\n",
      "tensor(0.8014, grad_fn=<DivBackward1>)\n",
      "tensor(0.5067, grad_fn=<DivBackward1>)\n",
      "tensor(0.7525, grad_fn=<DivBackward1>)\n",
      "tensor(0.5205, grad_fn=<DivBackward1>)\n",
      "tensor(0.7338, grad_fn=<DivBackward1>)\n",
      "tensor(0.7641, grad_fn=<DivBackward1>)\n",
      "tensor(0.6186, grad_fn=<DivBackward1>)\n",
      "tensor(0.7779, grad_fn=<DivBackward1>)\n",
      "tensor(0.5376, grad_fn=<DivBackward1>)\n",
      "tensor(0.7680, grad_fn=<DivBackward1>)\n",
      "tensor(0.6007, grad_fn=<DivBackward1>)\n",
      "tensor(0.7720, grad_fn=<DivBackward1>)\n",
      "tensor(1.1098, grad_fn=<DivBackward1>)\n",
      "tensor(0.5855, grad_fn=<DivBackward1>)\n",
      "tensor(0.6498, grad_fn=<DivBackward1>)\n",
      "tensor(0.9649, grad_fn=<DivBackward1>)\n",
      "tensor(0.7745, grad_fn=<DivBackward1>)\n",
      "tensor(0.7263, grad_fn=<DivBackward1>)\n",
      "tensor(0.3958, grad_fn=<DivBackward1>)\n",
      "tensor(0.6470, grad_fn=<DivBackward1>)\n",
      "tensor(0.5715, grad_fn=<DivBackward1>)\n",
      "tensor(0.5564, grad_fn=<DivBackward1>)\n",
      "tensor(0.6964, grad_fn=<DivBackward1>)\n",
      "tensor(0.3728, grad_fn=<DivBackward1>)\n",
      "tensor(0.9634, grad_fn=<DivBackward1>)\n",
      "tensor(0.9588, grad_fn=<DivBackward1>)\n",
      "tensor(0.5968, grad_fn=<DivBackward1>)\n",
      "tensor(0.5930, grad_fn=<DivBackward1>)\n",
      "tensor(0.7149, grad_fn=<DivBackward1>)\n",
      "tensor(1.2497, grad_fn=<DivBackward1>)\n",
      "tensor(0.5011, grad_fn=<DivBackward1>)\n",
      "tensor(0.5640, grad_fn=<DivBackward1>)\n",
      "tensor(0.7828, grad_fn=<DivBackward1>)\n",
      "tensor(0.5340, grad_fn=<DivBackward1>)\n",
      "tensor(0.6418, grad_fn=<DivBackward1>)\n",
      "tensor(0.6222, grad_fn=<DivBackward1>)\n",
      "tensor(0.7059, grad_fn=<DivBackward1>)\n",
      "tensor(0.5058, grad_fn=<DivBackward1>)\n",
      "tensor(0.9243, grad_fn=<DivBackward1>)\n",
      "tensor(0.6181, grad_fn=<DivBackward1>)\n",
      "tensor(0.7274, grad_fn=<DivBackward1>)\n",
      "tensor(0.5386, grad_fn=<DivBackward1>)\n",
      "tensor(0.5316, grad_fn=<DivBackward1>)\n",
      "tensor(0.9777, grad_fn=<DivBackward1>)\n",
      "tensor(0.6971, grad_fn=<DivBackward1>)\n",
      "tensor(0.7250, grad_fn=<DivBackward1>)\n",
      "tensor(0.5134, grad_fn=<DivBackward1>)\n",
      "tensor(0.6955, grad_fn=<DivBackward1>)\n",
      "tensor(0.6703, grad_fn=<DivBackward1>)\n",
      "tensor(0.7638, grad_fn=<DivBackward1>)\n",
      "tensor(0.5323, grad_fn=<DivBackward1>)\n",
      "tensor(0.2961, grad_fn=<DivBackward1>)\n",
      "tensor(0.6469, grad_fn=<DivBackward1>)\n",
      "tensor(0.6907, grad_fn=<DivBackward1>)\n",
      "tensor(0.7436, grad_fn=<DivBackward1>)\n",
      "tensor(0.5221, grad_fn=<DivBackward1>)\n",
      "tensor(0.6752, grad_fn=<DivBackward1>)\n",
      "tensor(0.8028, grad_fn=<DivBackward1>)\n",
      "tensor(0.7444, grad_fn=<DivBackward1>)\n",
      "tensor(0.4568, grad_fn=<DivBackward1>)\n",
      "tensor(0.7528, grad_fn=<DivBackward1>)\n",
      "tensor(0.7150, grad_fn=<DivBackward1>)\n",
      "tensor(0.5100, grad_fn=<DivBackward1>)\n",
      "tensor(0.7260, grad_fn=<DivBackward1>)\n",
      "tensor(0.5695, grad_fn=<DivBackward1>)\n",
      "tensor(1.0787, grad_fn=<DivBackward1>)\n",
      "tensor(0.6270, grad_fn=<DivBackward1>)\n",
      "tensor(0.7049, grad_fn=<DivBackward1>)\n",
      "tensor(0.6237, grad_fn=<DivBackward1>)\n",
      "tensor(0.5876, grad_fn=<DivBackward1>)\n",
      "tensor(0.7531, grad_fn=<DivBackward1>)\n",
      "tensor(0.4676, grad_fn=<DivBackward1>)\n",
      "tensor(0.7216, grad_fn=<DivBackward1>)\n",
      "tensor(0.4987, grad_fn=<DivBackward1>)\n",
      "tensor(0.7009, grad_fn=<DivBackward1>)\n",
      "tensor(0.7295, grad_fn=<DivBackward1>)\n",
      "tensor(0.5611, grad_fn=<DivBackward1>)\n",
      "tensor(0.7596, grad_fn=<DivBackward1>)\n",
      "tensor(0.4931, grad_fn=<DivBackward1>)\n",
      "tensor(0.7386, grad_fn=<DivBackward1>)\n",
      "tensor(0.5858, grad_fn=<DivBackward1>)\n",
      "tensor(0.7109, grad_fn=<DivBackward1>)\n",
      "tensor(1.1665, grad_fn=<DivBackward1>)\n",
      "tensor(0.5517, grad_fn=<DivBackward1>)\n",
      "tensor(0.6250, grad_fn=<DivBackward1>)\n",
      "tensor(0.9113, grad_fn=<DivBackward1>)\n",
      "tensor(0.7600, grad_fn=<DivBackward1>)\n",
      "tensor(0.6930, grad_fn=<DivBackward1>)\n",
      "tensor(0.3787, grad_fn=<DivBackward1>)\n",
      "tensor(0.6113, grad_fn=<DivBackward1>)\n",
      "tensor(0.5323, grad_fn=<DivBackward1>)\n",
      "tensor(0.5286, grad_fn=<DivBackward1>)\n",
      "tensor(0.6394, grad_fn=<DivBackward1>)\n",
      "tensor(0.3307, grad_fn=<DivBackward1>)\n",
      "tensor(0.9361, grad_fn=<DivBackward1>)\n",
      "tensor(0.9665, grad_fn=<DivBackward1>)\n",
      "tensor(0.5741, grad_fn=<DivBackward1>)\n",
      "tensor(0.5520, grad_fn=<DivBackward1>)\n",
      "tensor(0.6752, grad_fn=<DivBackward1>)\n",
      "tensor(1.1900, grad_fn=<DivBackward1>)\n",
      "tensor(0.4838, grad_fn=<DivBackward1>)\n",
      "tensor(0.5379, grad_fn=<DivBackward1>)\n",
      "tensor(0.7043, grad_fn=<DivBackward1>)\n",
      "tensor(0.5176, grad_fn=<DivBackward1>)\n",
      "tensor(0.6177, grad_fn=<DivBackward1>)\n",
      "tensor(0.5640, grad_fn=<DivBackward1>)\n",
      "tensor(0.7072, grad_fn=<DivBackward1>)\n",
      "tensor(0.4909, grad_fn=<DivBackward1>)\n",
      "tensor(0.9550, grad_fn=<DivBackward1>)\n",
      "tensor(0.5928, grad_fn=<DivBackward1>)\n",
      "tensor(0.7157, grad_fn=<DivBackward1>)\n",
      "tensor(0.4796, grad_fn=<DivBackward1>)\n",
      "tensor(0.4749, grad_fn=<DivBackward1>)\n",
      "tensor(0.9639, grad_fn=<DivBackward1>)\n",
      "tensor(0.6602, grad_fn=<DivBackward1>)\n",
      "tensor(0.6758, grad_fn=<DivBackward1>)\n",
      "tensor(0.4569, grad_fn=<DivBackward1>)\n",
      "tensor(0.6706, grad_fn=<DivBackward1>)\n",
      "tensor(0.6385, grad_fn=<DivBackward1>)\n",
      "tensor(0.7428, grad_fn=<DivBackward1>)\n",
      "tensor(0.5269, grad_fn=<DivBackward1>)\n",
      "tensor(0.2619, grad_fn=<DivBackward1>)\n",
      "tensor(0.5967, grad_fn=<DivBackward1>)\n",
      "tensor(0.6610, grad_fn=<DivBackward1>)\n",
      "tensor(0.7109, grad_fn=<DivBackward1>)\n",
      "tensor(0.4813, grad_fn=<DivBackward1>)\n",
      "tensor(0.6393, grad_fn=<DivBackward1>)\n",
      "tensor(0.7655, grad_fn=<DivBackward1>)\n",
      "tensor(0.6904, grad_fn=<DivBackward1>)\n",
      "tensor(0.4365, grad_fn=<DivBackward1>)\n",
      "tensor(0.7167, grad_fn=<DivBackward1>)\n",
      "tensor(0.6269, grad_fn=<DivBackward1>)\n",
      "tensor(0.4667, grad_fn=<DivBackward1>)\n",
      "tensor(0.7217, grad_fn=<DivBackward1>)\n",
      "tensor(0.5466, grad_fn=<DivBackward1>)\n",
      "tensor(1.1016, grad_fn=<DivBackward1>)\n",
      "tensor(0.6096, grad_fn=<DivBackward1>)\n",
      "tensor(0.6540, grad_fn=<DivBackward1>)\n",
      "tensor(0.5992, grad_fn=<DivBackward1>)\n",
      "tensor(0.5425, grad_fn=<DivBackward1>)\n",
      "tensor(0.7121, grad_fn=<DivBackward1>)\n",
      "tensor(0.4361, grad_fn=<DivBackward1>)\n",
      "tensor(0.7043, grad_fn=<DivBackward1>)\n",
      "tensor(0.4952, grad_fn=<DivBackward1>)\n",
      "tensor(0.6756, grad_fn=<DivBackward1>)\n",
      "tensor(0.6973, grad_fn=<DivBackward1>)\n",
      "tensor(0.5160, grad_fn=<DivBackward1>)\n",
      "tensor(0.7443, grad_fn=<DivBackward1>)\n",
      "tensor(0.4570, grad_fn=<DivBackward1>)\n",
      "tensor(0.7253, grad_fn=<DivBackward1>)\n",
      "tensor(0.5803, grad_fn=<DivBackward1>)\n",
      "tensor(0.6643, grad_fn=<DivBackward1>)\n",
      "tensor(1.1935, grad_fn=<DivBackward1>)\n",
      "tensor(0.5307, grad_fn=<DivBackward1>)\n",
      "tensor(0.6094, grad_fn=<DivBackward1>)\n",
      "tensor(0.8448, grad_fn=<DivBackward1>)\n",
      "tensor(0.7615, grad_fn=<DivBackward1>)\n",
      "tensor(0.6700, grad_fn=<DivBackward1>)\n",
      "tensor(0.3723, grad_fn=<DivBackward1>)\n",
      "tensor(0.5852, grad_fn=<DivBackward1>)\n",
      "tensor(0.5028, grad_fn=<DivBackward1>)\n",
      "tensor(0.5057, grad_fn=<DivBackward1>)\n",
      "tensor(0.5842, grad_fn=<DivBackward1>)\n",
      "tensor(0.2972, grad_fn=<DivBackward1>)\n",
      "tensor(0.9025, grad_fn=<DivBackward1>)\n",
      "tensor(0.9559, grad_fn=<DivBackward1>)\n",
      "tensor(0.5521, grad_fn=<DivBackward1>)\n",
      "tensor(0.5125, grad_fn=<DivBackward1>)\n",
      "tensor(0.6432, grad_fn=<DivBackward1>)\n",
      "tensor(1.1339, grad_fn=<DivBackward1>)\n",
      "tensor(0.4771, grad_fn=<DivBackward1>)\n",
      "tensor(0.5119, grad_fn=<DivBackward1>)\n",
      "tensor(0.6370, grad_fn=<DivBackward1>)\n",
      "tensor(0.5063, grad_fn=<DivBackward1>)\n",
      "tensor(0.5972, grad_fn=<DivBackward1>)\n",
      "tensor(0.5175, grad_fn=<DivBackward1>)\n",
      "tensor(0.7060, grad_fn=<DivBackward1>)\n",
      "tensor(0.5001, grad_fn=<DivBackward1>)\n",
      "tensor(0.9851, grad_fn=<DivBackward1>)\n",
      "tensor(0.5678, grad_fn=<DivBackward1>)\n",
      "tensor(0.7159, grad_fn=<DivBackward1>)\n",
      "tensor(0.4310, grad_fn=<DivBackward1>)\n",
      "tensor(0.4341, grad_fn=<DivBackward1>)\n",
      "tensor(0.9541, grad_fn=<DivBackward1>)\n",
      "tensor(0.6262, grad_fn=<DivBackward1>)\n",
      "tensor(0.6427, grad_fn=<DivBackward1>)\n",
      "tensor(0.4053, grad_fn=<DivBackward1>)\n",
      "tensor(0.6549, grad_fn=<DivBackward1>)\n",
      "tensor(0.6149, grad_fn=<DivBackward1>)\n",
      "tensor(0.7383, grad_fn=<DivBackward1>)\n",
      "tensor(0.5328, grad_fn=<DivBackward1>)\n",
      "tensor(0.2357, grad_fn=<DivBackward1>)\n",
      "tensor(0.5591, grad_fn=<DivBackward1>)\n",
      "tensor(0.6327, grad_fn=<DivBackward1>)\n",
      "tensor(0.6762, grad_fn=<DivBackward1>)\n",
      "tensor(0.4505, grad_fn=<DivBackward1>)\n",
      "tensor(0.6090, grad_fn=<DivBackward1>)\n",
      "tensor(0.7328, grad_fn=<DivBackward1>)\n",
      "tensor(0.6420, grad_fn=<DivBackward1>)\n",
      "tensor(0.4267, grad_fn=<DivBackward1>)\n",
      "tensor(0.6788, grad_fn=<DivBackward1>)\n",
      "tensor(0.5391, grad_fn=<DivBackward1>)\n",
      "tensor(0.4354, grad_fn=<DivBackward1>)\n",
      "tensor(0.7223, grad_fn=<DivBackward1>)\n",
      "tensor(0.5281, grad_fn=<DivBackward1>)\n",
      "tensor(1.1167, grad_fn=<DivBackward1>)\n",
      "tensor(0.6044, grad_fn=<DivBackward1>)\n",
      "tensor(0.6099, grad_fn=<DivBackward1>)\n",
      "tensor(0.5764, grad_fn=<DivBackward1>)\n",
      "tensor(0.5051, grad_fn=<DivBackward1>)\n",
      "tensor(0.6755, grad_fn=<DivBackward1>)\n",
      "tensor(0.4088, grad_fn=<DivBackward1>)\n",
      "tensor(0.6928, grad_fn=<DivBackward1>)\n",
      "tensor(0.4999, grad_fn=<DivBackward1>)\n",
      "tensor(0.6469, grad_fn=<DivBackward1>)\n",
      "tensor(0.6673, grad_fn=<DivBackward1>)\n",
      "tensor(0.4777, grad_fn=<DivBackward1>)\n",
      "tensor(0.7335, grad_fn=<DivBackward1>)\n",
      "tensor(0.4267, grad_fn=<DivBackward1>)\n",
      "tensor(0.7193, grad_fn=<DivBackward1>)\n",
      "tensor(0.5785, grad_fn=<DivBackward1>)\n",
      "tensor(0.6276, grad_fn=<DivBackward1>)\n",
      "tensor(1.1957, grad_fn=<DivBackward1>)\n",
      "tensor(0.5130, grad_fn=<DivBackward1>)\n",
      "tensor(0.6000, grad_fn=<DivBackward1>)\n",
      "tensor(0.7758, grad_fn=<DivBackward1>)\n",
      "tensor(0.7658, grad_fn=<DivBackward1>)\n",
      "tensor(0.6478, grad_fn=<DivBackward1>)\n",
      "tensor(0.3763, grad_fn=<DivBackward1>)\n",
      "tensor(0.5609, grad_fn=<DivBackward1>)\n",
      "tensor(0.4749, grad_fn=<DivBackward1>)\n",
      "tensor(0.4842, grad_fn=<DivBackward1>)\n",
      "tensor(0.5352, grad_fn=<DivBackward1>)\n",
      "tensor(0.2679, grad_fn=<DivBackward1>)\n",
      "tensor(0.8674, grad_fn=<DivBackward1>)\n",
      "tensor(0.9346, grad_fn=<DivBackward1>)\n",
      "tensor(0.5319, grad_fn=<DivBackward1>)\n",
      "tensor(0.4717, grad_fn=<DivBackward1>)\n",
      "tensor(0.6131, grad_fn=<DivBackward1>)\n",
      "tensor(1.0791, grad_fn=<DivBackward1>)\n",
      "tensor(0.4785, grad_fn=<DivBackward1>)\n",
      "tensor(0.4845, grad_fn=<DivBackward1>)\n",
      "tensor(0.5786, grad_fn=<DivBackward1>)\n",
      "tensor(0.4993, grad_fn=<DivBackward1>)\n",
      "tensor(0.5720, grad_fn=<DivBackward1>)\n",
      "tensor(0.4824, grad_fn=<DivBackward1>)\n",
      "tensor(0.7002, grad_fn=<DivBackward1>)\n",
      "tensor(0.5259, grad_fn=<DivBackward1>)\n",
      "tensor(1.0048, grad_fn=<DivBackward1>)\n",
      "tensor(0.5407, grad_fn=<DivBackward1>)\n",
      "tensor(0.7232, grad_fn=<DivBackward1>)\n",
      "tensor(0.3878, grad_fn=<DivBackward1>)\n",
      "tensor(0.3978, grad_fn=<DivBackward1>)\n",
      "tensor(0.9516, grad_fn=<DivBackward1>)\n",
      "tensor(0.5933, grad_fn=<DivBackward1>)\n",
      "tensor(0.6155, grad_fn=<DivBackward1>)\n",
      "tensor(0.3602, grad_fn=<DivBackward1>)\n",
      "tensor(0.6474, grad_fn=<DivBackward1>)\n",
      "tensor(0.5983, grad_fn=<DivBackward1>)\n",
      "tensor(0.7483, grad_fn=<DivBackward1>)\n",
      "tensor(0.5403, grad_fn=<DivBackward1>)\n",
      "tensor(0.2097, grad_fn=<DivBackward1>)\n",
      "tensor(0.5302, grad_fn=<DivBackward1>)\n",
      "tensor(0.6019, grad_fn=<DivBackward1>)\n",
      "tensor(0.6324, grad_fn=<DivBackward1>)\n",
      "tensor(0.4177, grad_fn=<DivBackward1>)\n",
      "tensor(0.5799, grad_fn=<DivBackward1>)\n",
      "tensor(0.7107, grad_fn=<DivBackward1>)\n",
      "tensor(0.6094, grad_fn=<DivBackward1>)\n",
      "tensor(0.4202, grad_fn=<DivBackward1>)\n",
      "tensor(0.6384, grad_fn=<DivBackward1>)\n",
      "tensor(0.4644, grad_fn=<DivBackward1>)\n",
      "tensor(0.4114, grad_fn=<DivBackward1>)\n",
      "tensor(0.7252, grad_fn=<DivBackward1>)\n",
      "tensor(0.5165, grad_fn=<DivBackward1>)\n",
      "tensor(1.1213, grad_fn=<DivBackward1>)\n",
      "tensor(0.6109, grad_fn=<DivBackward1>)\n",
      "tensor(0.5712, grad_fn=<DivBackward1>)\n",
      "tensor(0.5564, grad_fn=<DivBackward1>)\n",
      "tensor(0.4745, grad_fn=<DivBackward1>)\n",
      "tensor(0.6530, grad_fn=<DivBackward1>)\n",
      "tensor(0.3810, grad_fn=<DivBackward1>)\n",
      "tensor(0.6728, grad_fn=<DivBackward1>)\n",
      "tensor(0.5082, grad_fn=<DivBackward1>)\n",
      "tensor(0.6124, grad_fn=<DivBackward1>)\n",
      "tensor(0.6262, grad_fn=<DivBackward1>)\n",
      "tensor(0.4443, grad_fn=<DivBackward1>)\n",
      "tensor(0.7298, grad_fn=<DivBackward1>)\n",
      "tensor(0.4004, grad_fn=<DivBackward1>)\n",
      "tensor(0.7189, grad_fn=<DivBackward1>)\n",
      "tensor(0.5726, grad_fn=<DivBackward1>)\n",
      "tensor(0.5972, grad_fn=<DivBackward1>)\n",
      "tensor(1.1395, grad_fn=<DivBackward1>)\n",
      "tensor(0.4957, grad_fn=<DivBackward1>)\n",
      "tensor(0.5936, grad_fn=<DivBackward1>)\n",
      "tensor(0.7046, grad_fn=<DivBackward1>)\n",
      "tensor(0.7602, grad_fn=<DivBackward1>)\n",
      "tensor(0.6355, grad_fn=<DivBackward1>)\n",
      "tensor(0.3870, grad_fn=<DivBackward1>)\n",
      "tensor(0.5354, grad_fn=<DivBackward1>)\n",
      "tensor(0.4568, grad_fn=<DivBackward1>)\n",
      "tensor(0.4537, grad_fn=<DivBackward1>)\n",
      "tensor(0.4915, grad_fn=<DivBackward1>)\n",
      "tensor(0.2346, grad_fn=<DivBackward1>)\n",
      "tensor(0.8336, grad_fn=<DivBackward1>)\n",
      "tensor(0.8939, grad_fn=<DivBackward1>)\n",
      "tensor(0.5071, grad_fn=<DivBackward1>)\n",
      "tensor(0.4295, grad_fn=<DivBackward1>)\n",
      "tensor(0.5862, grad_fn=<DivBackward1>)\n",
      "tensor(1.0215, grad_fn=<DivBackward1>)\n",
      "tensor(0.4829, grad_fn=<DivBackward1>)\n",
      "tensor(0.4568, grad_fn=<DivBackward1>)\n",
      "tensor(0.5362, grad_fn=<DivBackward1>)\n",
      "tensor(0.4824, grad_fn=<DivBackward1>)\n",
      "tensor(0.5396, grad_fn=<DivBackward1>)\n",
      "tensor(0.4562, grad_fn=<DivBackward1>)\n",
      "tensor(0.6913, grad_fn=<DivBackward1>)\n",
      "tensor(0.5698, grad_fn=<DivBackward1>)\n",
      "tensor(1.0104, grad_fn=<DivBackward1>)\n",
      "tensor(0.5093, grad_fn=<DivBackward1>)\n",
      "tensor(0.7331, grad_fn=<DivBackward1>)\n",
      "tensor(0.3489, grad_fn=<DivBackward1>)\n",
      "tensor(0.3580, grad_fn=<DivBackward1>)\n",
      "tensor(0.9646, grad_fn=<DivBackward1>)\n",
      "tensor(0.5616, grad_fn=<DivBackward1>)\n",
      "tensor(0.5922, grad_fn=<DivBackward1>)\n",
      "tensor(0.3183, grad_fn=<DivBackward1>)\n",
      "tensor(0.6451, grad_fn=<DivBackward1>)\n",
      "tensor(0.5863, grad_fn=<DivBackward1>)\n",
      "tensor(0.7679, grad_fn=<DivBackward1>)\n",
      "tensor(0.5464, grad_fn=<DivBackward1>)\n",
      "tensor(0.1859, grad_fn=<DivBackward1>)\n",
      "tensor(0.5054, grad_fn=<DivBackward1>)\n",
      "tensor(0.5802, grad_fn=<DivBackward1>)\n",
      "tensor(0.5677, grad_fn=<DivBackward1>)\n",
      "tensor(0.3882, grad_fn=<DivBackward1>)\n",
      "tensor(0.5551, grad_fn=<DivBackward1>)\n",
      "tensor(0.6750, grad_fn=<DivBackward1>)\n",
      "tensor(0.5822, grad_fn=<DivBackward1>)\n",
      "tensor(0.4109, grad_fn=<DivBackward1>)\n",
      "tensor(0.5982, grad_fn=<DivBackward1>)\n",
      "tensor(0.4119, grad_fn=<DivBackward1>)\n",
      "tensor(0.3952, grad_fn=<DivBackward1>)\n",
      "tensor(0.7238, grad_fn=<DivBackward1>)\n",
      "tensor(0.5111, grad_fn=<DivBackward1>)\n",
      "tensor(1.1113, grad_fn=<DivBackward1>)\n",
      "tensor(0.6177, grad_fn=<DivBackward1>)\n",
      "tensor(0.5391, grad_fn=<DivBackward1>)\n",
      "tensor(0.5320, grad_fn=<DivBackward1>)\n",
      "tensor(0.4543, grad_fn=<DivBackward1>)\n",
      "tensor(0.6424, grad_fn=<DivBackward1>)\n",
      "tensor(0.3556, grad_fn=<DivBackward1>)\n",
      "tensor(0.6452, grad_fn=<DivBackward1>)\n",
      "tensor(0.5197, grad_fn=<DivBackward1>)\n",
      "tensor(0.5730, grad_fn=<DivBackward1>)\n",
      "tensor(0.5701, grad_fn=<DivBackward1>)\n",
      "tensor(0.4185, grad_fn=<DivBackward1>)\n",
      "tensor(0.7322, grad_fn=<DivBackward1>)\n",
      "tensor(0.3776, grad_fn=<DivBackward1>)\n",
      "tensor(0.7048, grad_fn=<DivBackward1>)\n",
      "tensor(0.5615, grad_fn=<DivBackward1>)\n",
      "tensor(0.5697, grad_fn=<DivBackward1>)\n",
      "tensor(1.1002, grad_fn=<DivBackward1>)\n",
      "tensor(0.4708, grad_fn=<DivBackward1>)\n",
      "tensor(0.5884, grad_fn=<DivBackward1>)\n",
      "tensor(0.6323, grad_fn=<DivBackward1>)\n",
      "tensor(0.7490, grad_fn=<DivBackward1>)\n",
      "tensor(0.6189, grad_fn=<DivBackward1>)\n",
      "tensor(0.4044, grad_fn=<DivBackward1>)\n",
      "tensor(0.5062, grad_fn=<DivBackward1>)\n",
      "tensor(0.4366, grad_fn=<DivBackward1>)\n",
      "tensor(0.4296, grad_fn=<DivBackward1>)\n",
      "tensor(0.4578, grad_fn=<DivBackward1>)\n",
      "tensor(0.2126, grad_fn=<DivBackward1>)\n",
      "tensor(0.8055, grad_fn=<DivBackward1>)\n",
      "tensor(0.8573, grad_fn=<DivBackward1>)\n",
      "tensor(0.4977, grad_fn=<DivBackward1>)\n",
      "tensor(0.3967, grad_fn=<DivBackward1>)\n",
      "tensor(0.5581, grad_fn=<DivBackward1>)\n",
      "tensor(0.9760, grad_fn=<DivBackward1>)\n",
      "tensor(0.4847, grad_fn=<DivBackward1>)\n",
      "tensor(0.4366, grad_fn=<DivBackward1>)\n",
      "tensor(0.5075, grad_fn=<DivBackward1>)\n",
      "tensor(0.4694, grad_fn=<DivBackward1>)\n",
      "tensor(0.5084, grad_fn=<DivBackward1>)\n",
      "tensor(0.4388, grad_fn=<DivBackward1>)\n",
      "tensor(0.6817, grad_fn=<DivBackward1>)\n",
      "tensor(0.6176, grad_fn=<DivBackward1>)\n",
      "tensor(1.0166, grad_fn=<DivBackward1>)\n",
      "tensor(0.4772, grad_fn=<DivBackward1>)\n",
      "tensor(0.7492, grad_fn=<DivBackward1>)\n",
      "tensor(0.3198, grad_fn=<DivBackward1>)\n",
      "tensor(0.3252, grad_fn=<DivBackward1>)\n",
      "tensor(0.9724, grad_fn=<DivBackward1>)\n",
      "tensor(0.5260, grad_fn=<DivBackward1>)\n",
      "tensor(0.5643, grad_fn=<DivBackward1>)\n",
      "tensor(0.2850, grad_fn=<DivBackward1>)\n",
      "tensor(0.6470, grad_fn=<DivBackward1>)\n",
      "tensor(0.5680, grad_fn=<DivBackward1>)\n",
      "tensor(0.7897, grad_fn=<DivBackward1>)\n",
      "tensor(0.5553, grad_fn=<DivBackward1>)\n",
      "tensor(0.1640, grad_fn=<DivBackward1>)\n",
      "tensor(0.4825, grad_fn=<DivBackward1>)\n",
      "tensor(0.5639, grad_fn=<DivBackward1>)\n",
      "tensor(0.5127, grad_fn=<DivBackward1>)\n",
      "tensor(0.3555, grad_fn=<DivBackward1>)\n",
      "tensor(0.5400, grad_fn=<DivBackward1>)\n",
      "tensor(0.6409, grad_fn=<DivBackward1>)\n",
      "tensor(0.5558, grad_fn=<DivBackward1>)\n",
      "tensor(0.3999, grad_fn=<DivBackward1>)\n",
      "tensor(0.5594, grad_fn=<DivBackward1>)\n",
      "tensor(0.3783, grad_fn=<DivBackward1>)\n",
      "tensor(0.3808, grad_fn=<DivBackward1>)\n",
      "tensor(0.7265, grad_fn=<DivBackward1>)\n",
      "tensor(0.5086, grad_fn=<DivBackward1>)\n",
      "tensor(1.1166, grad_fn=<DivBackward1>)\n",
      "tensor(0.6259, grad_fn=<DivBackward1>)\n",
      "tensor(0.5185, grad_fn=<DivBackward1>)\n",
      "tensor(0.5103, grad_fn=<DivBackward1>)\n",
      "tensor(0.4454, grad_fn=<DivBackward1>)\n",
      "tensor(0.6409, grad_fn=<DivBackward1>)\n",
      "tensor(0.3315, grad_fn=<DivBackward1>)\n",
      "tensor(0.6144, grad_fn=<DivBackward1>)\n",
      "tensor(0.5235, grad_fn=<DivBackward1>)\n",
      "tensor(0.5397, grad_fn=<DivBackward1>)\n",
      "tensor(0.5219, grad_fn=<DivBackward1>)\n",
      "tensor(0.4015, grad_fn=<DivBackward1>)\n",
      "tensor(0.7487, grad_fn=<DivBackward1>)\n",
      "tensor(0.3623, grad_fn=<DivBackward1>)\n",
      "tensor(0.6864, grad_fn=<DivBackward1>)\n",
      "tensor(0.5499, grad_fn=<DivBackward1>)\n",
      "tensor(0.5462, grad_fn=<DivBackward1>)\n",
      "tensor(1.0658, grad_fn=<DivBackward1>)\n",
      "tensor(0.4489, grad_fn=<DivBackward1>)\n",
      "tensor(0.5825, grad_fn=<DivBackward1>)\n",
      "tensor(0.5721, grad_fn=<DivBackward1>)\n",
      "tensor(0.7424, grad_fn=<DivBackward1>)\n",
      "tensor(0.5974, grad_fn=<DivBackward1>)\n",
      "tensor(0.4195, grad_fn=<DivBackward1>)\n",
      "tensor(0.4818, grad_fn=<DivBackward1>)\n",
      "tensor(0.4220, grad_fn=<DivBackward1>)\n",
      "tensor(0.4121, grad_fn=<DivBackward1>)\n",
      "tensor(0.4330, grad_fn=<DivBackward1>)\n",
      "tensor(0.1963, grad_fn=<DivBackward1>)\n",
      "tensor(0.7819, grad_fn=<DivBackward1>)\n",
      "tensor(0.8289, grad_fn=<DivBackward1>)\n",
      "tensor(0.4913, grad_fn=<DivBackward1>)\n",
      "tensor(0.3674, grad_fn=<DivBackward1>)\n",
      "tensor(0.5334, grad_fn=<DivBackward1>)\n",
      "tensor(0.9431, grad_fn=<DivBackward1>)\n",
      "tensor(0.4811, grad_fn=<DivBackward1>)\n",
      "tensor(0.4157, grad_fn=<DivBackward1>)\n",
      "tensor(0.4851, grad_fn=<DivBackward1>)\n",
      "tensor(0.4573, grad_fn=<DivBackward1>)\n",
      "tensor(0.4797, grad_fn=<DivBackward1>)\n",
      "tensor(0.4253, grad_fn=<DivBackward1>)\n",
      "tensor(0.6712, grad_fn=<DivBackward1>)\n",
      "tensor(0.6699, grad_fn=<DivBackward1>)\n",
      "tensor(1.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.4456, grad_fn=<DivBackward1>)\n",
      "tensor(0.7625, grad_fn=<DivBackward1>)\n",
      "tensor(0.2943, grad_fn=<DivBackward1>)\n",
      "tensor(0.2969, grad_fn=<DivBackward1>)\n",
      "tensor(0.9910, grad_fn=<DivBackward1>)\n",
      "tensor(0.4975, grad_fn=<DivBackward1>)\n",
      "tensor(0.5450, grad_fn=<DivBackward1>)\n",
      "tensor(0.2597, grad_fn=<DivBackward1>)\n",
      "tensor(0.6480, grad_fn=<DivBackward1>)\n",
      "tensor(0.5398, grad_fn=<DivBackward1>)\n",
      "tensor(0.8132, grad_fn=<DivBackward1>)\n",
      "tensor(0.5579, grad_fn=<DivBackward1>)\n",
      "tensor(0.1434, grad_fn=<DivBackward1>)\n",
      "tensor(0.4576, grad_fn=<DivBackward1>)\n",
      "tensor(0.5467, grad_fn=<DivBackward1>)\n",
      "tensor(0.4597, grad_fn=<DivBackward1>)\n",
      "tensor(0.3252, grad_fn=<DivBackward1>)\n",
      "tensor(0.5276, grad_fn=<DivBackward1>)\n",
      "tensor(0.6070, grad_fn=<DivBackward1>)\n",
      "tensor(0.5314, grad_fn=<DivBackward1>)\n",
      "tensor(0.3887, grad_fn=<DivBackward1>)\n",
      "tensor(0.5260, grad_fn=<DivBackward1>)\n",
      "tensor(0.3543, grad_fn=<DivBackward1>)\n",
      "tensor(0.3746, grad_fn=<DivBackward1>)\n",
      "tensor(0.7261, grad_fn=<DivBackward1>)\n",
      "tensor(0.5067, grad_fn=<DivBackward1>)\n",
      "tensor(1.1191, grad_fn=<DivBackward1>)\n",
      "tensor(0.6351, grad_fn=<DivBackward1>)\n",
      "tensor(0.5026, grad_fn=<DivBackward1>)\n",
      "tensor(0.4979, grad_fn=<DivBackward1>)\n",
      "tensor(0.4382, grad_fn=<DivBackward1>)\n",
      "tensor(0.6386, grad_fn=<DivBackward1>)\n",
      "tensor(0.3078, grad_fn=<DivBackward1>)\n",
      "tensor(0.5878, grad_fn=<DivBackward1>)\n",
      "tensor(0.5255, grad_fn=<DivBackward1>)\n",
      "tensor(0.5080, grad_fn=<DivBackward1>)\n",
      "tensor(0.4763, grad_fn=<DivBackward1>)\n",
      "tensor(0.3907, grad_fn=<DivBackward1>)\n",
      "tensor(0.7713, grad_fn=<DivBackward1>)\n",
      "tensor(0.3524, grad_fn=<DivBackward1>)\n",
      "tensor(0.6724, grad_fn=<DivBackward1>)\n",
      "tensor(0.5309, grad_fn=<DivBackward1>)\n",
      "tensor(0.5359, grad_fn=<DivBackward1>)\n",
      "tensor(1.0303, grad_fn=<DivBackward1>)\n",
      "tensor(0.4318, grad_fn=<DivBackward1>)\n",
      "tensor(0.5822, grad_fn=<DivBackward1>)\n",
      "tensor(0.5129, grad_fn=<DivBackward1>)\n",
      "tensor(0.7329, grad_fn=<DivBackward1>)\n",
      "tensor(0.5779, grad_fn=<DivBackward1>)\n",
      "tensor(0.4424, grad_fn=<DivBackward1>)\n",
      "tensor(0.4569, grad_fn=<DivBackward1>)\n",
      "tensor(0.4117, grad_fn=<DivBackward1>)\n",
      "tensor(0.3991, grad_fn=<DivBackward1>)\n",
      "tensor(0.4181, grad_fn=<DivBackward1>)\n",
      "tensor(0.1854, grad_fn=<DivBackward1>)\n",
      "tensor(0.7573, grad_fn=<DivBackward1>)\n",
      "tensor(0.7940, grad_fn=<DivBackward1>)\n",
      "tensor(0.4862, grad_fn=<DivBackward1>)\n",
      "tensor(0.3437, grad_fn=<DivBackward1>)\n",
      "tensor(0.5117, grad_fn=<DivBackward1>)\n",
      "tensor(0.9055, grad_fn=<DivBackward1>)\n",
      "tensor(0.4822, grad_fn=<DivBackward1>)\n",
      "tensor(0.3965, grad_fn=<DivBackward1>)\n",
      "tensor(0.4639, grad_fn=<DivBackward1>)\n",
      "tensor(0.4433, grad_fn=<DivBackward1>)\n",
      "tensor(0.4544, grad_fn=<DivBackward1>)\n",
      "tensor(0.4148, grad_fn=<DivBackward1>)\n",
      "tensor(0.6588, grad_fn=<DivBackward1>)\n",
      "tensor(0.7220, grad_fn=<DivBackward1>)\n",
      "tensor(1.0185, grad_fn=<DivBackward1>)\n",
      "tensor(0.4139, grad_fn=<DivBackward1>)\n",
      "tensor(0.7716, grad_fn=<DivBackward1>)\n",
      "tensor(0.2763, grad_fn=<DivBackward1>)\n",
      "tensor(0.2757, grad_fn=<DivBackward1>)\n",
      "tensor(1.0033, grad_fn=<DivBackward1>)\n",
      "tensor(0.4668, grad_fn=<DivBackward1>)\n",
      "tensor(0.5264, grad_fn=<DivBackward1>)\n",
      "tensor(0.2408, grad_fn=<DivBackward1>)\n",
      "tensor(0.6548, grad_fn=<DivBackward1>)\n",
      "tensor(0.5115, grad_fn=<DivBackward1>)\n",
      "tensor(0.8351, grad_fn=<DivBackward1>)\n",
      "tensor(0.5710, grad_fn=<DivBackward1>)\n",
      "tensor(0.1276, grad_fn=<DivBackward1>)\n",
      "tensor(0.4314, grad_fn=<DivBackward1>)\n",
      "tensor(0.5327, grad_fn=<DivBackward1>)\n",
      "tensor(0.4140, grad_fn=<DivBackward1>)\n",
      "tensor(0.2947, grad_fn=<DivBackward1>)\n",
      "tensor(0.5178, grad_fn=<DivBackward1>)\n",
      "tensor(0.5835, grad_fn=<DivBackward1>)\n",
      "tensor(0.5119, grad_fn=<DivBackward1>)\n",
      "tensor(0.3723, grad_fn=<DivBackward1>)\n",
      "tensor(0.5025, grad_fn=<DivBackward1>)\n",
      "tensor(0.3421, grad_fn=<DivBackward1>)\n",
      "tensor(0.3681, grad_fn=<DivBackward1>)\n",
      "tensor(0.7259, grad_fn=<DivBackward1>)\n",
      "tensor(0.5080, grad_fn=<DivBackward1>)\n",
      "tensor(1.1208, grad_fn=<DivBackward1>)\n",
      "tensor(0.6428, grad_fn=<DivBackward1>)\n",
      "tensor(0.4943, grad_fn=<DivBackward1>)\n",
      "tensor(0.4917, grad_fn=<DivBackward1>)\n",
      "tensor(0.4315, grad_fn=<DivBackward1>)\n",
      "tensor(0.6371, grad_fn=<DivBackward1>)\n",
      "tensor(0.2870, grad_fn=<DivBackward1>)\n",
      "tensor(0.5629, grad_fn=<DivBackward1>)\n",
      "tensor(0.5223, grad_fn=<DivBackward1>)\n",
      "tensor(0.4822, grad_fn=<DivBackward1>)\n",
      "tensor(0.4302, grad_fn=<DivBackward1>)\n",
      "tensor(0.3841, grad_fn=<DivBackward1>)\n",
      "tensor(0.7961, grad_fn=<DivBackward1>)\n",
      "tensor(0.3448, grad_fn=<DivBackward1>)\n",
      "tensor(0.6583, grad_fn=<DivBackward1>)\n",
      "tensor(0.5145, grad_fn=<DivBackward1>)\n",
      "tensor(0.5276, grad_fn=<DivBackward1>)\n",
      "tensor(1.0112, grad_fn=<DivBackward1>)\n",
      "tensor(0.4084, grad_fn=<DivBackward1>)\n",
      "tensor(0.5745, grad_fn=<DivBackward1>)\n",
      "tensor(0.4557, grad_fn=<DivBackward1>)\n",
      "tensor(0.7292, grad_fn=<DivBackward1>)\n",
      "tensor(0.5599, grad_fn=<DivBackward1>)\n",
      "tensor(0.4625, grad_fn=<DivBackward1>)\n",
      "tensor(0.4360, grad_fn=<DivBackward1>)\n",
      "tensor(0.4068, grad_fn=<DivBackward1>)\n",
      "tensor(0.3863, grad_fn=<DivBackward1>)\n",
      "tensor(0.4064, grad_fn=<DivBackward1>)\n",
      "tensor(0.1731, grad_fn=<DivBackward1>)\n",
      "tensor(0.7416, grad_fn=<DivBackward1>)\n",
      "tensor(0.7690, grad_fn=<DivBackward1>)\n",
      "tensor(0.4818, grad_fn=<DivBackward1>)\n",
      "tensor(0.3195, grad_fn=<DivBackward1>)\n",
      "tensor(0.4986, grad_fn=<DivBackward1>)\n",
      "tensor(0.8834, grad_fn=<DivBackward1>)\n",
      "tensor(0.4836, grad_fn=<DivBackward1>)\n",
      "tensor(0.3775, grad_fn=<DivBackward1>)\n",
      "tensor(0.4502, grad_fn=<DivBackward1>)\n",
      "tensor(0.4297, grad_fn=<DivBackward1>)\n",
      "tensor(0.4343, grad_fn=<DivBackward1>)\n",
      "tensor(0.4044, grad_fn=<DivBackward1>)\n",
      "tensor(0.6492, grad_fn=<DivBackward1>)\n",
      "tensor(0.7657, grad_fn=<DivBackward1>)\n",
      "tensor(1.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.3802, grad_fn=<DivBackward1>)\n",
      "tensor(0.7744, grad_fn=<DivBackward1>)\n",
      "tensor(0.2636, grad_fn=<DivBackward1>)\n",
      "tensor(0.2584, grad_fn=<DivBackward1>)\n",
      "tensor(1.0151, grad_fn=<DivBackward1>)\n",
      "tensor(0.4346, grad_fn=<DivBackward1>)\n",
      "tensor(0.5076, grad_fn=<DivBackward1>)\n",
      "tensor(0.2270, grad_fn=<DivBackward1>)\n",
      "tensor(0.6614, grad_fn=<DivBackward1>)\n",
      "tensor(0.4835, grad_fn=<DivBackward1>)\n",
      "tensor(0.8525, grad_fn=<DivBackward1>)\n",
      "tensor(0.5788, grad_fn=<DivBackward1>)\n",
      "tensor(0.1174, grad_fn=<DivBackward1>)\n",
      "tensor(0.4015, grad_fn=<DivBackward1>)\n",
      "tensor(0.5226, grad_fn=<DivBackward1>)\n",
      "tensor(0.3682, grad_fn=<DivBackward1>)\n",
      "tensor(0.2695, grad_fn=<DivBackward1>)\n",
      "tensor(0.5170, grad_fn=<DivBackward1>)\n",
      "tensor(0.5543, grad_fn=<DivBackward1>)\n",
      "tensor(0.4913, grad_fn=<DivBackward1>)\n",
      "tensor(0.3534, grad_fn=<DivBackward1>)\n",
      "tensor(0.4786, grad_fn=<DivBackward1>)\n",
      "tensor(0.3323, grad_fn=<DivBackward1>)\n",
      "tensor(0.3647, grad_fn=<DivBackward1>)\n",
      "tensor(0.7190, grad_fn=<DivBackward1>)\n",
      "tensor(0.5122, grad_fn=<DivBackward1>)\n",
      "tensor(1.1189, grad_fn=<DivBackward1>)\n",
      "tensor(0.6565, grad_fn=<DivBackward1>)\n",
      "tensor(0.4943, grad_fn=<DivBackward1>)\n",
      "tensor(0.4885, grad_fn=<DivBackward1>)\n",
      "tensor(0.4213, grad_fn=<DivBackward1>)\n",
      "tensor(0.6298, grad_fn=<DivBackward1>)\n",
      "tensor(0.2703, grad_fn=<DivBackward1>)\n",
      "tensor(0.5402, grad_fn=<DivBackward1>)\n",
      "tensor(0.5226, grad_fn=<DivBackward1>)\n",
      "tensor(0.4599, grad_fn=<DivBackward1>)\n",
      "tensor(0.3898, grad_fn=<DivBackward1>)\n",
      "tensor(0.3761, grad_fn=<DivBackward1>)\n",
      "tensor(0.8145, grad_fn=<DivBackward1>)\n",
      "tensor(0.3376, grad_fn=<DivBackward1>)\n",
      "tensor(0.6472, grad_fn=<DivBackward1>)\n",
      "tensor(0.5000, grad_fn=<DivBackward1>)\n",
      "tensor(0.5238, grad_fn=<DivBackward1>)\n",
      "tensor(0.9961, grad_fn=<DivBackward1>)\n",
      "tensor(0.3887, grad_fn=<DivBackward1>)\n",
      "tensor(0.5723, grad_fn=<DivBackward1>)\n",
      "tensor(0.4045, grad_fn=<DivBackward1>)\n",
      "tensor(0.7248, grad_fn=<DivBackward1>)\n",
      "tensor(0.5384, grad_fn=<DivBackward1>)\n",
      "tensor(0.4799, grad_fn=<DivBackward1>)\n",
      "tensor(0.4139, grad_fn=<DivBackward1>)\n",
      "tensor(0.3982, grad_fn=<DivBackward1>)\n",
      "tensor(0.3745, grad_fn=<DivBackward1>)\n",
      "tensor(0.3946, grad_fn=<DivBackward1>)\n",
      "tensor(0.1660, grad_fn=<DivBackward1>)\n",
      "tensor(0.7239, grad_fn=<DivBackward1>)\n",
      "tensor(0.7512, grad_fn=<DivBackward1>)\n",
      "tensor(0.4801, grad_fn=<DivBackward1>)\n",
      "tensor(0.3013, grad_fn=<DivBackward1>)\n",
      "tensor(0.4900, grad_fn=<DivBackward1>)\n",
      "tensor(0.8543, grad_fn=<DivBackward1>)\n",
      "tensor(0.4820, grad_fn=<DivBackward1>)\n",
      "tensor(0.3568, grad_fn=<DivBackward1>)\n",
      "tensor(0.4357, grad_fn=<DivBackward1>)\n",
      "tensor(0.4186, grad_fn=<DivBackward1>)\n",
      "tensor(0.4156, grad_fn=<DivBackward1>)\n",
      "tensor(0.3950, grad_fn=<DivBackward1>)\n",
      "tensor(0.6456, grad_fn=<DivBackward1>)\n",
      "tensor(0.7931, grad_fn=<DivBackward1>)\n",
      "tensor(1.0031, grad_fn=<DivBackward1>)\n",
      "tensor(0.3495, grad_fn=<DivBackward1>)\n",
      "tensor(0.7718, grad_fn=<DivBackward1>)\n",
      "tensor(0.2536, grad_fn=<DivBackward1>)\n",
      "tensor(0.2451, grad_fn=<DivBackward1>)\n",
      "tensor(1.0131, grad_fn=<DivBackward1>)\n",
      "tensor(0.4073, grad_fn=<DivBackward1>)\n",
      "tensor(0.4929, grad_fn=<DivBackward1>)\n",
      "tensor(0.2167, grad_fn=<DivBackward1>)\n",
      "tensor(0.6758, grad_fn=<DivBackward1>)\n",
      "tensor(0.4556, grad_fn=<DivBackward1>)\n",
      "tensor(0.8714, grad_fn=<DivBackward1>)\n",
      "tensor(0.5649, grad_fn=<DivBackward1>)\n",
      "tensor(0.1073, grad_fn=<DivBackward1>)\n",
      "tensor(0.3740, grad_fn=<DivBackward1>)\n",
      "tensor(0.5120, grad_fn=<DivBackward1>)\n",
      "tensor(0.3353, grad_fn=<DivBackward1>)\n",
      "tensor(0.2515, grad_fn=<DivBackward1>)\n",
      "tensor(0.5149, grad_fn=<DivBackward1>)\n",
      "tensor(0.5298, grad_fn=<DivBackward1>)\n",
      "tensor(0.4682, grad_fn=<DivBackward1>)\n",
      "tensor(0.3365, grad_fn=<DivBackward1>)\n",
      "tensor(0.4567, grad_fn=<DivBackward1>)\n",
      "tensor(0.3228, grad_fn=<DivBackward1>)\n",
      "tensor(0.3609, grad_fn=<DivBackward1>)\n",
      "tensor(0.7142, grad_fn=<DivBackward1>)\n",
      "tensor(0.5153, grad_fn=<DivBackward1>)\n",
      "tensor(1.1189, grad_fn=<DivBackward1>)\n",
      "tensor(0.6701, grad_fn=<DivBackward1>)\n",
      "tensor(0.5000, grad_fn=<DivBackward1>)\n",
      "tensor(0.4948, grad_fn=<DivBackward1>)\n",
      "tensor(0.4157, grad_fn=<DivBackward1>)\n",
      "tensor(0.6278, grad_fn=<DivBackward1>)\n",
      "tensor(0.2564, grad_fn=<DivBackward1>)\n",
      "tensor(0.5139, grad_fn=<DivBackward1>)\n",
      "tensor(0.5309, grad_fn=<DivBackward1>)\n",
      "tensor(0.4421, grad_fn=<DivBackward1>)\n",
      "tensor(0.3530, grad_fn=<DivBackward1>)\n",
      "tensor(0.3661, grad_fn=<DivBackward1>)\n",
      "tensor(0.8172, grad_fn=<DivBackward1>)\n",
      "tensor(0.3299, grad_fn=<DivBackward1>)\n",
      "tensor(0.6284, grad_fn=<DivBackward1>)\n",
      "tensor(0.4810, grad_fn=<DivBackward1>)\n",
      "tensor(0.5144, grad_fn=<DivBackward1>)\n",
      "tensor(0.9818, grad_fn=<DivBackward1>)\n",
      "tensor(0.3703, grad_fn=<DivBackward1>)\n",
      "tensor(0.5654, grad_fn=<DivBackward1>)\n",
      "tensor(0.3617, grad_fn=<DivBackward1>)\n",
      "tensor(0.7202, grad_fn=<DivBackward1>)\n",
      "tensor(0.5102, grad_fn=<DivBackward1>)\n",
      "tensor(0.4943, grad_fn=<DivBackward1>)\n",
      "tensor(0.4054, grad_fn=<DivBackward1>)\n",
      "tensor(0.3914, grad_fn=<DivBackward1>)\n",
      "tensor(0.3622, grad_fn=<DivBackward1>)\n",
      "tensor(0.3786, grad_fn=<DivBackward1>)\n",
      "tensor(0.1633, grad_fn=<DivBackward1>)\n",
      "tensor(0.7050, grad_fn=<DivBackward1>)\n",
      "tensor(0.7419, grad_fn=<DivBackward1>)\n",
      "tensor(0.4738, grad_fn=<DivBackward1>)\n",
      "tensor(0.2840, grad_fn=<DivBackward1>)\n",
      "tensor(0.4877, grad_fn=<DivBackward1>)\n",
      "tensor(0.8422, grad_fn=<DivBackward1>)\n",
      "tensor(0.4782, grad_fn=<DivBackward1>)\n",
      "tensor(0.3429, grad_fn=<DivBackward1>)\n",
      "tensor(0.4200, grad_fn=<DivBackward1>)\n",
      "tensor(0.4091, grad_fn=<DivBackward1>)\n",
      "tensor(0.3985, grad_fn=<DivBackward1>)\n",
      "tensor(0.3776, grad_fn=<DivBackward1>)\n",
      "tensor(0.6402, grad_fn=<DivBackward1>)\n",
      "tensor(0.8196, grad_fn=<DivBackward1>)\n",
      "tensor(0.9857, grad_fn=<DivBackward1>)\n",
      "tensor(0.3233, grad_fn=<DivBackward1>)\n",
      "tensor(0.7673, grad_fn=<DivBackward1>)\n",
      "tensor(0.2448, grad_fn=<DivBackward1>)\n",
      "tensor(0.2319, grad_fn=<DivBackward1>)\n",
      "tensor(1.0137, grad_fn=<DivBackward1>)\n",
      "tensor(0.3823, grad_fn=<DivBackward1>)\n",
      "tensor(0.4760, grad_fn=<DivBackward1>)\n",
      "tensor(0.2131, grad_fn=<DivBackward1>)\n",
      "tensor(0.6905, grad_fn=<DivBackward1>)\n",
      "tensor(0.4222, grad_fn=<DivBackward1>)\n",
      "tensor(0.8863, grad_fn=<DivBackward1>)\n",
      "tensor(0.5540, grad_fn=<DivBackward1>)\n",
      "tensor(0.0993, grad_fn=<DivBackward1>)\n",
      "tensor(0.3488, grad_fn=<DivBackward1>)\n",
      "tensor(0.5033, grad_fn=<DivBackward1>)\n",
      "tensor(0.3122, grad_fn=<DivBackward1>)\n",
      "tensor(0.2314, grad_fn=<DivBackward1>)\n",
      "tensor(0.5118, grad_fn=<DivBackward1>)\n",
      "tensor(0.5137, grad_fn=<DivBackward1>)\n",
      "tensor(0.4458, grad_fn=<DivBackward1>)\n",
      "tensor(0.3158, grad_fn=<DivBackward1>)\n",
      "tensor(0.4383, grad_fn=<DivBackward1>)\n",
      "tensor(0.3154, grad_fn=<DivBackward1>)\n",
      "tensor(0.3553, grad_fn=<DivBackward1>)\n",
      "tensor(0.7080, grad_fn=<DivBackward1>)\n",
      "tensor(0.5224, grad_fn=<DivBackward1>)\n",
      "tensor(1.1258, grad_fn=<DivBackward1>)\n",
      "tensor(0.6672, grad_fn=<DivBackward1>)\n",
      "tensor(0.4864, grad_fn=<DivBackward1>)\n",
      "tensor(0.4831, grad_fn=<DivBackward1>)\n",
      "tensor(0.4040, grad_fn=<DivBackward1>)\n",
      "tensor(0.6186, grad_fn=<DivBackward1>)\n",
      "tensor(0.2430, grad_fn=<DivBackward1>)\n",
      "tensor(0.4965, grad_fn=<DivBackward1>)\n",
      "tensor(0.5416, grad_fn=<DivBackward1>)\n",
      "tensor(0.4252, grad_fn=<DivBackward1>)\n",
      "tensor(0.3228, grad_fn=<DivBackward1>)\n",
      "tensor(0.3585, grad_fn=<DivBackward1>)\n",
      "tensor(0.8102, grad_fn=<DivBackward1>)\n",
      "tensor(0.3153, grad_fn=<DivBackward1>)\n",
      "tensor(0.6213, grad_fn=<DivBackward1>)\n",
      "tensor(0.4669, grad_fn=<DivBackward1>)\n",
      "tensor(0.5044, grad_fn=<DivBackward1>)\n",
      "tensor(0.9797, grad_fn=<DivBackward1>)\n",
      "tensor(0.3563, grad_fn=<DivBackward1>)\n",
      "tensor(0.5556, grad_fn=<DivBackward1>)\n",
      "tensor(0.3255, grad_fn=<DivBackward1>)\n",
      "tensor(0.7111, grad_fn=<DivBackward1>)\n",
      "tensor(0.4819, grad_fn=<DivBackward1>)\n",
      "tensor(0.5089, grad_fn=<DivBackward1>)\n",
      "tensor(0.3974, grad_fn=<DivBackward1>)\n",
      "tensor(0.3787, grad_fn=<DivBackward1>)\n",
      "tensor(0.3498, grad_fn=<DivBackward1>)\n",
      "tensor(0.3648, grad_fn=<DivBackward1>)\n",
      "tensor(0.1604, grad_fn=<DivBackward1>)\n",
      "tensor(0.6879, grad_fn=<DivBackward1>)\n",
      "tensor(0.7278, grad_fn=<DivBackward1>)\n",
      "tensor(0.4645, grad_fn=<DivBackward1>)\n",
      "tensor(0.2683, grad_fn=<DivBackward1>)\n",
      "tensor(0.4872, grad_fn=<DivBackward1>)\n",
      "tensor(0.8377, grad_fn=<DivBackward1>)\n",
      "tensor(0.4747, grad_fn=<DivBackward1>)\n",
      "tensor(0.3292, grad_fn=<DivBackward1>)\n",
      "tensor(0.4090, grad_fn=<DivBackward1>)\n",
      "tensor(0.4029, grad_fn=<DivBackward1>)\n",
      "tensor(0.3855, grad_fn=<DivBackward1>)\n",
      "tensor(0.3639, grad_fn=<DivBackward1>)\n",
      "tensor(0.6416, grad_fn=<DivBackward1>)\n",
      "tensor(0.8476, grad_fn=<DivBackward1>)\n",
      "tensor(0.9665, grad_fn=<DivBackward1>)\n",
      "tensor(0.3018, grad_fn=<DivBackward1>)\n",
      "tensor(0.7635, grad_fn=<DivBackward1>)\n",
      "tensor(0.2374, grad_fn=<DivBackward1>)\n",
      "tensor(0.2197, grad_fn=<DivBackward1>)\n",
      "tensor(1.0107, grad_fn=<DivBackward1>)\n",
      "tensor(0.3554, grad_fn=<DivBackward1>)\n",
      "tensor(0.4580, grad_fn=<DivBackward1>)\n",
      "tensor(0.2090, grad_fn=<DivBackward1>)\n",
      "tensor(0.7077, grad_fn=<DivBackward1>)\n",
      "tensor(0.3971, grad_fn=<DivBackward1>)\n",
      "tensor(0.9027, grad_fn=<DivBackward1>)\n",
      "tensor(0.5446, grad_fn=<DivBackward1>)\n",
      "tensor(0.0916, grad_fn=<DivBackward1>)\n",
      "tensor(0.3254, grad_fn=<DivBackward1>)\n",
      "tensor(0.4942, grad_fn=<DivBackward1>)\n",
      "tensor(0.2905, grad_fn=<DivBackward1>)\n",
      "tensor(0.2125, grad_fn=<DivBackward1>)\n",
      "tensor(0.5056, grad_fn=<DivBackward1>)\n",
      "tensor(0.5091, grad_fn=<DivBackward1>)\n",
      "tensor(0.4200, grad_fn=<DivBackward1>)\n",
      "tensor(0.2999, grad_fn=<DivBackward1>)\n",
      "tensor(0.4236, grad_fn=<DivBackward1>)\n",
      "tensor(0.3076, grad_fn=<DivBackward1>)\n",
      "tensor(0.3511, grad_fn=<DivBackward1>)\n",
      "tensor(0.7005, grad_fn=<DivBackward1>)\n",
      "tensor(0.5287, grad_fn=<DivBackward1>)\n",
      "tensor(1.1261, grad_fn=<DivBackward1>)\n",
      "tensor(0.6605, grad_fn=<DivBackward1>)\n",
      "tensor(0.4742, grad_fn=<DivBackward1>)\n",
      "tensor(0.4709, grad_fn=<DivBackward1>)\n",
      "tensor(0.3902, grad_fn=<DivBackward1>)\n",
      "tensor(0.6084, grad_fn=<DivBackward1>)\n",
      "tensor(0.2363, grad_fn=<DivBackward1>)\n",
      "tensor(0.4828, grad_fn=<DivBackward1>)\n",
      "tensor(0.5584, grad_fn=<DivBackward1>)\n",
      "tensor(0.4120, grad_fn=<DivBackward1>)\n",
      "tensor(0.3032, grad_fn=<DivBackward1>)\n",
      "tensor(0.3480, grad_fn=<DivBackward1>)\n",
      "tensor(0.7978, grad_fn=<DivBackward1>)\n",
      "tensor(0.3023, grad_fn=<DivBackward1>)\n",
      "tensor(0.6176, grad_fn=<DivBackward1>)\n",
      "tensor(0.4495, grad_fn=<DivBackward1>)\n",
      "tensor(0.4932, grad_fn=<DivBackward1>)\n",
      "tensor(0.9759, grad_fn=<DivBackward1>)\n",
      "tensor(0.3456, grad_fn=<DivBackward1>)\n",
      "tensor(0.5307, grad_fn=<DivBackward1>)\n",
      "tensor(0.2989, grad_fn=<DivBackward1>)\n",
      "tensor(0.7125, grad_fn=<DivBackward1>)\n",
      "tensor(0.4572, grad_fn=<DivBackward1>)\n",
      "tensor(0.5175, grad_fn=<DivBackward1>)\n",
      "tensor(0.3904, grad_fn=<DivBackward1>)\n",
      "tensor(0.3679, grad_fn=<DivBackward1>)\n",
      "tensor(0.3367, grad_fn=<DivBackward1>)\n",
      "tensor(0.3451, grad_fn=<DivBackward1>)\n",
      "tensor(0.1563, grad_fn=<DivBackward1>)\n",
      "tensor(0.6794, grad_fn=<DivBackward1>)\n",
      "tensor(0.7136, grad_fn=<DivBackward1>)\n",
      "tensor(0.4527, grad_fn=<DivBackward1>)\n",
      "tensor(0.2532, grad_fn=<DivBackward1>)\n",
      "tensor(0.4871, grad_fn=<DivBackward1>)\n",
      "tensor(0.8359, grad_fn=<DivBackward1>)\n",
      "tensor(0.4826, grad_fn=<DivBackward1>)\n",
      "tensor(0.3193, grad_fn=<DivBackward1>)\n",
      "tensor(0.3941, grad_fn=<DivBackward1>)\n",
      "tensor(0.3984, grad_fn=<DivBackward1>)\n",
      "tensor(0.3715, grad_fn=<DivBackward1>)\n",
      "tensor(0.3469, grad_fn=<DivBackward1>)\n",
      "tensor(0.6461, grad_fn=<DivBackward1>)\n",
      "tensor(0.8741, grad_fn=<DivBackward1>)\n",
      "tensor(0.9497, grad_fn=<DivBackward1>)\n",
      "tensor(0.2862, grad_fn=<DivBackward1>)\n",
      "tensor(0.7578, grad_fn=<DivBackward1>)\n",
      "tensor(0.2308, grad_fn=<DivBackward1>)\n",
      "tensor(0.2057, grad_fn=<DivBackward1>)\n",
      "tensor(1.0076, grad_fn=<DivBackward1>)\n",
      "tensor(0.3312, grad_fn=<DivBackward1>)\n",
      "tensor(0.4386, grad_fn=<DivBackward1>)\n",
      "tensor(0.2068, grad_fn=<DivBackward1>)\n",
      "tensor(0.7222, grad_fn=<DivBackward1>)\n",
      "tensor(0.3763, grad_fn=<DivBackward1>)\n",
      "tensor(0.9162, grad_fn=<DivBackward1>)\n",
      "tensor(0.5452, grad_fn=<DivBackward1>)\n",
      "tensor(0.0851, grad_fn=<DivBackward1>)\n",
      "tensor(0.3046, grad_fn=<DivBackward1>)\n",
      "tensor(0.4882, grad_fn=<DivBackward1>)\n",
      "tensor(0.2736, grad_fn=<DivBackward1>)\n",
      "tensor(0.1990, grad_fn=<DivBackward1>)\n",
      "tensor(0.5004, grad_fn=<DivBackward1>)\n",
      "tensor(0.4962, grad_fn=<DivBackward1>)\n",
      "tensor(0.3947, grad_fn=<DivBackward1>)\n",
      "tensor(0.2873, grad_fn=<DivBackward1>)\n",
      "tensor(0.4096, grad_fn=<DivBackward1>)\n",
      "tensor(0.3031, grad_fn=<DivBackward1>)\n",
      "tensor(0.3457, grad_fn=<DivBackward1>)\n",
      "tensor(0.6935, grad_fn=<DivBackward1>)\n",
      "tensor(0.5326, grad_fn=<DivBackward1>)\n",
      "tensor(1.1233, grad_fn=<DivBackward1>)\n",
      "tensor(0.6502, grad_fn=<DivBackward1>)\n",
      "tensor(0.4658, grad_fn=<DivBackward1>)\n",
      "tensor(0.4610, grad_fn=<DivBackward1>)\n",
      "tensor(0.3746, grad_fn=<DivBackward1>)\n",
      "tensor(0.5962, grad_fn=<DivBackward1>)\n",
      "tensor(0.2306, grad_fn=<DivBackward1>)\n",
      "tensor(0.4683, grad_fn=<DivBackward1>)\n",
      "tensor(0.5749, grad_fn=<DivBackward1>)\n",
      "tensor(0.3982, grad_fn=<DivBackward1>)\n",
      "tensor(0.2859, grad_fn=<DivBackward1>)\n",
      "tensor(0.3390, grad_fn=<DivBackward1>)\n",
      "tensor(0.7910, grad_fn=<DivBackward1>)\n",
      "tensor(0.2902, grad_fn=<DivBackward1>)\n",
      "tensor(0.6047, grad_fn=<DivBackward1>)\n",
      "tensor(0.4341, grad_fn=<DivBackward1>)\n",
      "tensor(0.4851, grad_fn=<DivBackward1>)\n",
      "tensor(0.9622, grad_fn=<DivBackward1>)\n",
      "tensor(0.3345, grad_fn=<DivBackward1>)\n",
      "tensor(0.5114, grad_fn=<DivBackward1>)\n",
      "tensor(0.2809, grad_fn=<DivBackward1>)\n",
      "tensor(0.7169, grad_fn=<DivBackward1>)\n",
      "tensor(0.4278, grad_fn=<DivBackward1>)\n",
      "tensor(0.5239, grad_fn=<DivBackward1>)\n",
      "tensor(0.3815, grad_fn=<DivBackward1>)\n",
      "tensor(0.3585, grad_fn=<DivBackward1>)\n",
      "tensor(0.3254, grad_fn=<DivBackward1>)\n",
      "tensor(0.3342, grad_fn=<DivBackward1>)\n",
      "tensor(0.1543, grad_fn=<DivBackward1>)\n",
      "tensor(0.6608, grad_fn=<DivBackward1>)\n",
      "tensor(0.7105, grad_fn=<DivBackward1>)\n",
      "tensor(0.4475, grad_fn=<DivBackward1>)\n",
      "tensor(0.2379, grad_fn=<DivBackward1>)\n",
      "tensor(0.4791, grad_fn=<DivBackward1>)\n",
      "tensor(0.8229, grad_fn=<DivBackward1>)\n",
      "tensor(0.4850, grad_fn=<DivBackward1>)\n",
      "tensor(0.3093, grad_fn=<DivBackward1>)\n",
      "tensor(0.3862, grad_fn=<DivBackward1>)\n",
      "tensor(0.3913, grad_fn=<DivBackward1>)\n",
      "tensor(0.3601, grad_fn=<DivBackward1>)\n",
      "tensor(0.3360, grad_fn=<DivBackward1>)\n",
      "tensor(0.6556, grad_fn=<DivBackward1>)\n",
      "tensor(0.8955, grad_fn=<DivBackward1>)\n",
      "tensor(0.9368, grad_fn=<DivBackward1>)\n",
      "tensor(0.2745, grad_fn=<DivBackward1>)\n",
      "tensor(0.7517, grad_fn=<DivBackward1>)\n",
      "tensor(0.2256, grad_fn=<DivBackward1>)\n",
      "tensor(0.1936, grad_fn=<DivBackward1>)\n",
      "tensor(0.9943, grad_fn=<DivBackward1>)\n",
      "tensor(0.3102, grad_fn=<DivBackward1>)\n",
      "tensor(0.4233, grad_fn=<DivBackward1>)\n",
      "tensor(0.2076, grad_fn=<DivBackward1>)\n",
      "tensor(0.7283, grad_fn=<DivBackward1>)\n",
      "tensor(0.3534, grad_fn=<DivBackward1>)\n",
      "tensor(0.9236, grad_fn=<DivBackward1>)\n",
      "tensor(0.5384, grad_fn=<DivBackward1>)\n",
      "tensor(0.0783, grad_fn=<DivBackward1>)\n",
      "tensor(0.2857, grad_fn=<DivBackward1>)\n",
      "tensor(0.4892, grad_fn=<DivBackward1>)\n",
      "tensor(0.2551, grad_fn=<DivBackward1>)\n",
      "tensor(0.1828, grad_fn=<DivBackward1>)\n",
      "tensor(0.5019, grad_fn=<DivBackward1>)\n",
      "tensor(0.4823, grad_fn=<DivBackward1>)\n",
      "tensor(0.3748, grad_fn=<DivBackward1>)\n",
      "tensor(0.2712, grad_fn=<DivBackward1>)\n",
      "tensor(0.4005, grad_fn=<DivBackward1>)\n",
      "tensor(0.2979, grad_fn=<DivBackward1>)\n",
      "tensor(0.3372, grad_fn=<DivBackward1>)\n",
      "tensor(0.6814, grad_fn=<DivBackward1>)\n",
      "tensor(0.5357, grad_fn=<DivBackward1>)\n",
      "tensor(1.1256, grad_fn=<DivBackward1>)\n",
      "tensor(0.6396, grad_fn=<DivBackward1>)\n",
      "tensor(0.4520, grad_fn=<DivBackward1>)\n",
      "tensor(0.4520, grad_fn=<DivBackward1>)\n",
      "tensor(0.3543, grad_fn=<DivBackward1>)\n",
      "tensor(0.5769, grad_fn=<DivBackward1>)\n",
      "tensor(0.2249, grad_fn=<DivBackward1>)\n",
      "tensor(0.4558, grad_fn=<DivBackward1>)\n",
      "tensor(0.5835, grad_fn=<DivBackward1>)\n",
      "tensor(0.3839, grad_fn=<DivBackward1>)\n",
      "tensor(0.2659, grad_fn=<DivBackward1>)\n",
      "tensor(0.3299, grad_fn=<DivBackward1>)\n",
      "tensor(0.7760, grad_fn=<DivBackward1>)\n",
      "tensor(0.2798, grad_fn=<DivBackward1>)\n",
      "tensor(0.6052, grad_fn=<DivBackward1>)\n",
      "tensor(0.4174, grad_fn=<DivBackward1>)\n",
      "tensor(0.4742, grad_fn=<DivBackward1>)\n",
      "tensor(0.9585, grad_fn=<DivBackward1>)\n",
      "tensor(0.3264, grad_fn=<DivBackward1>)\n",
      "tensor(0.4986, grad_fn=<DivBackward1>)\n",
      "tensor(0.2582, grad_fn=<DivBackward1>)\n",
      "tensor(0.7189, grad_fn=<DivBackward1>)\n",
      "tensor(0.4003, grad_fn=<DivBackward1>)\n",
      "tensor(0.5297, grad_fn=<DivBackward1>)\n",
      "tensor(0.3702, grad_fn=<DivBackward1>)\n",
      "tensor(0.3483, grad_fn=<DivBackward1>)\n",
      "tensor(0.3188, grad_fn=<DivBackward1>)\n",
      "tensor(0.3280, grad_fn=<DivBackward1>)\n",
      "tensor(0.1511, grad_fn=<DivBackward1>)\n",
      "tensor(0.6520, grad_fn=<DivBackward1>)\n",
      "tensor(0.7021, grad_fn=<DivBackward1>)\n",
      "tensor(0.4358, grad_fn=<DivBackward1>)\n",
      "tensor(0.2231, grad_fn=<DivBackward1>)\n",
      "tensor(0.4667, grad_fn=<DivBackward1>)\n",
      "tensor(0.8006, grad_fn=<DivBackward1>)\n",
      "tensor(0.4905, grad_fn=<DivBackward1>)\n",
      "tensor(0.2970, grad_fn=<DivBackward1>)\n",
      "tensor(0.3752, grad_fn=<DivBackward1>)\n",
      "tensor(0.3890, grad_fn=<DivBackward1>)\n",
      "tensor(0.3520, grad_fn=<DivBackward1>)\n",
      "tensor(0.3225, grad_fn=<DivBackward1>)\n",
      "tensor(0.6613, grad_fn=<DivBackward1>)\n",
      "tensor(0.9180, grad_fn=<DivBackward1>)\n",
      "tensor(0.9210, grad_fn=<DivBackward1>)\n",
      "tensor(0.2628, grad_fn=<DivBackward1>)\n",
      "tensor(0.7518, grad_fn=<DivBackward1>)\n",
      "tensor(0.2200, grad_fn=<DivBackward1>)\n",
      "tensor(0.1822, grad_fn=<DivBackward1>)\n",
      "tensor(0.9838, grad_fn=<DivBackward1>)\n",
      "tensor(0.2882, grad_fn=<DivBackward1>)\n",
      "tensor(0.4038, grad_fn=<DivBackward1>)\n",
      "tensor(0.2089, grad_fn=<DivBackward1>)\n",
      "tensor(0.7419, grad_fn=<DivBackward1>)\n",
      "tensor(0.3333, grad_fn=<DivBackward1>)\n",
      "tensor(0.9314, grad_fn=<DivBackward1>)\n",
      "tensor(0.5569, grad_fn=<DivBackward1>)\n",
      "tensor(0.0770, grad_fn=<DivBackward1>)\n",
      "tensor(0.2706, grad_fn=<DivBackward1>)\n",
      "tensor(0.4900, grad_fn=<DivBackward1>)\n",
      "tensor(0.2442, grad_fn=<DivBackward1>)\n",
      "tensor(0.1705, grad_fn=<DivBackward1>)\n",
      "tensor(0.4937, grad_fn=<DivBackward1>)\n",
      "tensor(0.4705, grad_fn=<DivBackward1>)\n",
      "tensor(0.3551, grad_fn=<DivBackward1>)\n",
      "tensor(0.2575, grad_fn=<DivBackward1>)\n",
      "tensor(0.3918, grad_fn=<DivBackward1>)\n",
      "tensor(0.2959, grad_fn=<DivBackward1>)\n",
      "tensor(0.3255, grad_fn=<DivBackward1>)\n",
      "tensor(0.6766, grad_fn=<DivBackward1>)\n",
      "tensor(0.5411, grad_fn=<DivBackward1>)\n",
      "tensor(1.1227, grad_fn=<DivBackward1>)\n",
      "tensor(0.6321, grad_fn=<DivBackward1>)\n",
      "tensor(0.4496, grad_fn=<DivBackward1>)\n",
      "tensor(0.4386, grad_fn=<DivBackward1>)\n",
      "tensor(0.3435, grad_fn=<DivBackward1>)\n",
      "tensor(0.5644, grad_fn=<DivBackward1>)\n",
      "tensor(0.2179, grad_fn=<DivBackward1>)\n",
      "tensor(0.4347, grad_fn=<DivBackward1>)\n",
      "tensor(0.5958, grad_fn=<DivBackward1>)\n",
      "tensor(0.3725, grad_fn=<DivBackward1>)\n",
      "tensor(0.2504, grad_fn=<DivBackward1>)\n",
      "tensor(0.3239, grad_fn=<DivBackward1>)\n",
      "tensor(0.7597, grad_fn=<DivBackward1>)\n",
      "tensor(0.2684, grad_fn=<DivBackward1>)\n",
      "tensor(0.5922, grad_fn=<DivBackward1>)\n",
      "tensor(0.4048, grad_fn=<DivBackward1>)\n",
      "tensor(0.4595, grad_fn=<DivBackward1>)\n",
      "tensor(0.9483, grad_fn=<DivBackward1>)\n",
      "tensor(0.3185, grad_fn=<DivBackward1>)\n",
      "tensor(0.4986, grad_fn=<DivBackward1>)\n",
      "tensor(0.2418, grad_fn=<DivBackward1>)\n",
      "tensor(0.7214, grad_fn=<DivBackward1>)\n",
      "tensor(0.3719, grad_fn=<DivBackward1>)\n",
      "tensor(0.5312, grad_fn=<DivBackward1>)\n",
      "tensor(0.3591, grad_fn=<DivBackward1>)\n",
      "tensor(0.3444, grad_fn=<DivBackward1>)\n",
      "tensor(0.3128, grad_fn=<DivBackward1>)\n",
      "tensor(0.3254, grad_fn=<DivBackward1>)\n",
      "tensor(0.1505, grad_fn=<DivBackward1>)\n",
      "tensor(0.6397, grad_fn=<DivBackward1>)\n",
      "tensor(0.6997, grad_fn=<DivBackward1>)\n",
      "tensor(0.4294, grad_fn=<DivBackward1>)\n",
      "tensor(0.2089, grad_fn=<DivBackward1>)\n",
      "tensor(0.4562, grad_fn=<DivBackward1>)\n",
      "tensor(0.7926, grad_fn=<DivBackward1>)\n",
      "tensor(0.4800, grad_fn=<DivBackward1>)\n",
      "tensor(0.2930, grad_fn=<DivBackward1>)\n",
      "tensor(0.3664, grad_fn=<DivBackward1>)\n",
      "tensor(0.3758, grad_fn=<DivBackward1>)\n",
      "tensor(0.3430, grad_fn=<DivBackward1>)\n",
      "tensor(0.3112, grad_fn=<DivBackward1>)\n",
      "tensor(0.6620, grad_fn=<DivBackward1>)\n",
      "tensor(0.9354, grad_fn=<DivBackward1>)\n",
      "tensor(0.9009, grad_fn=<DivBackward1>)\n",
      "tensor(0.2509, grad_fn=<DivBackward1>)\n",
      "tensor(0.7467, grad_fn=<DivBackward1>)\n",
      "tensor(0.2144, grad_fn=<DivBackward1>)\n",
      "tensor(0.1724, grad_fn=<DivBackward1>)\n",
      "tensor(0.9865, grad_fn=<DivBackward1>)\n",
      "tensor(0.2699, grad_fn=<DivBackward1>)\n",
      "tensor(0.3979, grad_fn=<DivBackward1>)\n",
      "tensor(0.2173, grad_fn=<DivBackward1>)\n",
      "tensor(0.7262, grad_fn=<DivBackward1>)\n",
      "tensor(0.3119, grad_fn=<DivBackward1>)\n",
      "tensor(0.9315, grad_fn=<DivBackward1>)\n",
      "tensor(0.5366, grad_fn=<DivBackward1>)\n",
      "tensor(0.0716, grad_fn=<DivBackward1>)\n",
      "tensor(0.2590, grad_fn=<DivBackward1>)\n",
      "tensor(0.4980, grad_fn=<DivBackward1>)\n",
      "tensor(0.2268, grad_fn=<DivBackward1>)\n",
      "tensor(0.1602, grad_fn=<DivBackward1>)\n",
      "tensor(0.4993, grad_fn=<DivBackward1>)\n",
      "tensor(0.4597, grad_fn=<DivBackward1>)\n",
      "tensor(0.3372, grad_fn=<DivBackward1>)\n",
      "tensor(0.2495, grad_fn=<DivBackward1>)\n",
      "tensor(0.3848, grad_fn=<DivBackward1>)\n",
      "tensor(0.2954, grad_fn=<DivBackward1>)\n",
      "tensor(0.3183, grad_fn=<DivBackward1>)\n",
      "tensor(0.6643, grad_fn=<DivBackward1>)\n",
      "tensor(0.5408, grad_fn=<DivBackward1>)\n",
      "tensor(1.1339, grad_fn=<DivBackward1>)\n",
      "tensor(0.6110, grad_fn=<DivBackward1>)\n",
      "tensor(0.4215, grad_fn=<DivBackward1>)\n",
      "tensor(0.4236, grad_fn=<DivBackward1>)\n",
      "tensor(0.3346, grad_fn=<DivBackward1>)\n",
      "tensor(0.5418, grad_fn=<DivBackward1>)\n",
      "tensor(0.2088, grad_fn=<DivBackward1>)\n",
      "tensor(0.4236, grad_fn=<DivBackward1>)\n",
      "tensor(0.5989, grad_fn=<DivBackward1>)\n",
      "tensor(0.3539, grad_fn=<DivBackward1>)\n",
      "tensor(0.2419, grad_fn=<DivBackward1>)\n",
      "tensor(0.3169, grad_fn=<DivBackward1>)\n",
      "tensor(0.7416, grad_fn=<DivBackward1>)\n",
      "tensor(0.2588, grad_fn=<DivBackward1>)\n",
      "tensor(0.5877, grad_fn=<DivBackward1>)\n",
      "tensor(0.3856, grad_fn=<DivBackward1>)\n",
      "tensor(0.4410, grad_fn=<DivBackward1>)\n",
      "tensor(0.9422, grad_fn=<DivBackward1>)\n",
      "tensor(0.3051, grad_fn=<DivBackward1>)\n",
      "tensor(0.4799, grad_fn=<DivBackward1>)\n",
      "tensor(0.2282, grad_fn=<DivBackward1>)\n",
      "tensor(0.7224, grad_fn=<DivBackward1>)\n",
      "tensor(0.3495, grad_fn=<DivBackward1>)\n",
      "tensor(0.5340, grad_fn=<DivBackward1>)\n",
      "tensor(0.3512, grad_fn=<DivBackward1>)\n",
      "tensor(0.3374, grad_fn=<DivBackward1>)\n",
      "tensor(0.3041, grad_fn=<DivBackward1>)\n",
      "tensor(0.3137, grad_fn=<DivBackward1>)\n",
      "tensor(0.1431, grad_fn=<DivBackward1>)\n",
      "tensor(0.6299, grad_fn=<DivBackward1>)\n",
      "tensor(0.7050, grad_fn=<DivBackward1>)\n",
      "tensor(0.4171, grad_fn=<DivBackward1>)\n",
      "tensor(0.1921, grad_fn=<DivBackward1>)\n",
      "tensor(0.4556, grad_fn=<DivBackward1>)\n",
      "tensor(0.7963, grad_fn=<DivBackward1>)\n",
      "tensor(0.4620, grad_fn=<DivBackward1>)\n",
      "tensor(0.2819, grad_fn=<DivBackward1>)\n",
      "tensor(0.3603, grad_fn=<DivBackward1>)\n",
      "tensor(0.3646, grad_fn=<DivBackward1>)\n",
      "tensor(0.3363, grad_fn=<DivBackward1>)\n",
      "tensor(0.2979, grad_fn=<DivBackward1>)\n",
      "tensor(0.6670, grad_fn=<DivBackward1>)\n",
      "tensor(0.9598, grad_fn=<DivBackward1>)\n",
      "tensor(0.8783, grad_fn=<DivBackward1>)\n",
      "tensor(0.2415, grad_fn=<DivBackward1>)\n",
      "tensor(0.7426, grad_fn=<DivBackward1>)\n",
      "tensor(0.2097, grad_fn=<DivBackward1>)\n",
      "tensor(0.1588, grad_fn=<DivBackward1>)\n",
      "tensor(0.9971, grad_fn=<DivBackward1>)\n",
      "tensor(0.2539, grad_fn=<DivBackward1>)\n",
      "tensor(0.3872, grad_fn=<DivBackward1>)\n",
      "tensor(0.2098, grad_fn=<DivBackward1>)\n",
      "tensor(0.7429, grad_fn=<DivBackward1>)\n",
      "tensor(0.2966, grad_fn=<DivBackward1>)\n",
      "tensor(0.9280, grad_fn=<DivBackward1>)\n",
      "tensor(0.5403, grad_fn=<DivBackward1>)\n",
      "tensor(0.0689, grad_fn=<DivBackward1>)\n",
      "tensor(0.2427, grad_fn=<DivBackward1>)\n",
      "tensor(0.4997, grad_fn=<DivBackward1>)\n",
      "tensor(0.2110, grad_fn=<DivBackward1>)\n",
      "tensor(0.1484, grad_fn=<DivBackward1>)\n",
      "tensor(0.5089, grad_fn=<DivBackward1>)\n",
      "tensor(0.4525, grad_fn=<DivBackward1>)\n",
      "tensor(0.3229, grad_fn=<DivBackward1>)\n",
      "tensor(0.2316, grad_fn=<DivBackward1>)\n",
      "tensor(0.3823, grad_fn=<DivBackward1>)\n",
      "tensor(0.2843, grad_fn=<DivBackward1>)\n",
      "tensor(0.3139, grad_fn=<DivBackward1>)\n",
      "tensor(0.6451, grad_fn=<DivBackward1>)\n",
      "tensor(0.5450, grad_fn=<DivBackward1>)\n",
      "tensor(1.1235, grad_fn=<DivBackward1>)\n",
      "tensor(0.6080, grad_fn=<DivBackward1>)\n",
      "tensor(0.4119, grad_fn=<DivBackward1>)\n",
      "tensor(0.4167, grad_fn=<DivBackward1>)\n",
      "tensor(0.3209, grad_fn=<DivBackward1>)\n",
      "tensor(0.5194, grad_fn=<DivBackward1>)\n",
      "tensor(0.2060, grad_fn=<DivBackward1>)\n",
      "tensor(0.4102, grad_fn=<DivBackward1>)\n",
      "tensor(0.6116, grad_fn=<DivBackward1>)\n",
      "tensor(0.3438, grad_fn=<DivBackward1>)\n",
      "tensor(0.2288, grad_fn=<DivBackward1>)\n",
      "tensor(0.3103, grad_fn=<DivBackward1>)\n",
      "tensor(0.7235, grad_fn=<DivBackward1>)\n",
      "tensor(0.2491, grad_fn=<DivBackward1>)\n",
      "tensor(0.5821, grad_fn=<DivBackward1>)\n",
      "tensor(0.3637, grad_fn=<DivBackward1>)\n",
      "tensor(0.4229, grad_fn=<DivBackward1>)\n",
      "tensor(0.9296, grad_fn=<DivBackward1>)\n",
      "tensor(0.2946, grad_fn=<DivBackward1>)\n",
      "tensor(0.4690, grad_fn=<DivBackward1>)\n",
      "tensor(0.2138, grad_fn=<DivBackward1>)\n",
      "tensor(0.7233, grad_fn=<DivBackward1>)\n",
      "tensor(0.3278, grad_fn=<DivBackward1>)\n",
      "tensor(0.5368, grad_fn=<DivBackward1>)\n",
      "tensor(0.3401, grad_fn=<DivBackward1>)\n",
      "tensor(0.3299, grad_fn=<DivBackward1>)\n",
      "tensor(0.2957, grad_fn=<DivBackward1>)\n",
      "tensor(0.3066, grad_fn=<DivBackward1>)\n",
      "tensor(0.1381, grad_fn=<DivBackward1>)\n",
      "tensor(0.6182, grad_fn=<DivBackward1>)\n",
      "tensor(0.6993, grad_fn=<DivBackward1>)\n",
      "tensor(0.4110, grad_fn=<DivBackward1>)\n",
      "tensor(0.1789, grad_fn=<DivBackward1>)\n",
      "tensor(0.4486, grad_fn=<DivBackward1>)\n",
      "tensor(0.7754, grad_fn=<DivBackward1>)\n",
      "tensor(0.4542, grad_fn=<DivBackward1>)\n",
      "tensor(0.2807, grad_fn=<DivBackward1>)\n",
      "tensor(0.3536, grad_fn=<DivBackward1>)\n",
      "tensor(0.3556, grad_fn=<DivBackward1>)\n",
      "tensor(0.3334, grad_fn=<DivBackward1>)\n",
      "tensor(0.2815, grad_fn=<DivBackward1>)\n",
      "tensor(0.6708, grad_fn=<DivBackward1>)\n",
      "tensor(0.9754, grad_fn=<DivBackward1>)\n",
      "tensor(0.8545, grad_fn=<DivBackward1>)\n",
      "tensor(0.2315, grad_fn=<DivBackward1>)\n",
      "tensor(0.7381, grad_fn=<DivBackward1>)\n",
      "tensor(0.2077, grad_fn=<DivBackward1>)\n",
      "tensor(0.1486, grad_fn=<DivBackward1>)\n",
      "tensor(0.9797, grad_fn=<DivBackward1>)\n",
      "tensor(0.2386, grad_fn=<DivBackward1>)\n",
      "tensor(0.3760, grad_fn=<DivBackward1>)\n",
      "tensor(0.2033, grad_fn=<DivBackward1>)\n",
      "tensor(0.7512, grad_fn=<DivBackward1>)\n",
      "tensor(0.2809, grad_fn=<DivBackward1>)\n",
      "tensor(0.9124, grad_fn=<DivBackward1>)\n",
      "tensor(0.5483, grad_fn=<DivBackward1>)\n",
      "tensor(0.0672, grad_fn=<DivBackward1>)\n",
      "tensor(0.2332, grad_fn=<DivBackward1>)\n",
      "tensor(0.5005, grad_fn=<DivBackward1>)\n",
      "tensor(0.2012, grad_fn=<DivBackward1>)\n",
      "tensor(0.1392, grad_fn=<DivBackward1>)\n",
      "tensor(0.5150, grad_fn=<DivBackward1>)\n",
      "tensor(0.4519, grad_fn=<DivBackward1>)\n",
      "tensor(0.3087, grad_fn=<DivBackward1>)\n",
      "tensor(0.2194, grad_fn=<DivBackward1>)\n",
      "tensor(0.3795, grad_fn=<DivBackward1>)\n",
      "tensor(0.2766, grad_fn=<DivBackward1>)\n",
      "tensor(0.3061, grad_fn=<DivBackward1>)\n",
      "tensor(0.6371, grad_fn=<DivBackward1>)\n",
      "tensor(0.5481, grad_fn=<DivBackward1>)\n",
      "tensor(1.1258, grad_fn=<DivBackward1>)\n",
      "tensor(0.6005, grad_fn=<DivBackward1>)\n",
      "tensor(0.3845, grad_fn=<DivBackward1>)\n",
      "tensor(0.4022, grad_fn=<DivBackward1>)\n",
      "tensor(0.3132, grad_fn=<DivBackward1>)\n",
      "tensor(0.4913, grad_fn=<DivBackward1>)\n",
      "tensor(0.2042, grad_fn=<DivBackward1>)\n",
      "tensor(0.3986, grad_fn=<DivBackward1>)\n",
      "tensor(0.6244, grad_fn=<DivBackward1>)\n",
      "tensor(0.3352, grad_fn=<DivBackward1>)\n",
      "tensor(0.2217, grad_fn=<DivBackward1>)\n",
      "tensor(0.3040, grad_fn=<DivBackward1>)\n",
      "tensor(0.7034, grad_fn=<DivBackward1>)\n",
      "tensor(0.2361, grad_fn=<DivBackward1>)\n",
      "tensor(0.5812, grad_fn=<DivBackward1>)\n",
      "tensor(0.3427, grad_fn=<DivBackward1>)\n",
      "tensor(0.4157, grad_fn=<DivBackward1>)\n",
      "tensor(0.9141, grad_fn=<DivBackward1>)\n",
      "tensor(0.2850, grad_fn=<DivBackward1>)\n",
      "tensor(0.4457, grad_fn=<DivBackward1>)\n",
      "tensor(0.2090, grad_fn=<DivBackward1>)\n",
      "tensor(0.7079, grad_fn=<DivBackward1>)\n",
      "tensor(0.3120, grad_fn=<DivBackward1>)\n",
      "tensor(0.5410, grad_fn=<DivBackward1>)\n",
      "tensor(0.3303, grad_fn=<DivBackward1>)\n",
      "tensor(0.3136, grad_fn=<DivBackward1>)\n",
      "tensor(0.2877, grad_fn=<DivBackward1>)\n",
      "tensor(0.2982, grad_fn=<DivBackward1>)\n",
      "tensor(0.1287, grad_fn=<DivBackward1>)\n",
      "tensor(0.6005, grad_fn=<DivBackward1>)\n",
      "tensor(0.6964, grad_fn=<DivBackward1>)\n",
      "tensor(0.4030, grad_fn=<DivBackward1>)\n",
      "tensor(0.1677, grad_fn=<DivBackward1>)\n",
      "tensor(0.4354, grad_fn=<DivBackward1>)\n",
      "tensor(0.7568, grad_fn=<DivBackward1>)\n",
      "tensor(0.4462, grad_fn=<DivBackward1>)\n",
      "tensor(0.2736, grad_fn=<DivBackward1>)\n",
      "tensor(0.3483, grad_fn=<DivBackward1>)\n",
      "tensor(0.3455, grad_fn=<DivBackward1>)\n",
      "tensor(0.3323, grad_fn=<DivBackward1>)\n",
      "tensor(0.2707, grad_fn=<DivBackward1>)\n",
      "tensor(0.6770, grad_fn=<DivBackward1>)\n",
      "tensor(0.9983, grad_fn=<DivBackward1>)\n",
      "tensor(0.8439, grad_fn=<DivBackward1>)\n",
      "tensor(0.2258, grad_fn=<DivBackward1>)\n",
      "tensor(0.7280, grad_fn=<DivBackward1>)\n",
      "tensor(0.2066, grad_fn=<DivBackward1>)\n",
      "tensor(0.1369, grad_fn=<DivBackward1>)\n",
      "tensor(0.9634, grad_fn=<DivBackward1>)\n",
      "tensor(0.2255, grad_fn=<DivBackward1>)\n",
      "tensor(0.3635, grad_fn=<DivBackward1>)\n",
      "tensor(0.1983, grad_fn=<DivBackward1>)\n",
      "tensor(0.7494, grad_fn=<DivBackward1>)\n",
      "tensor(0.2618, grad_fn=<DivBackward1>)\n",
      "tensor(0.8887, grad_fn=<DivBackward1>)\n",
      "tensor(0.5456, grad_fn=<DivBackward1>)\n",
      "tensor(0.0684, grad_fn=<DivBackward1>)\n",
      "tensor(0.2216, grad_fn=<DivBackward1>)\n",
      "tensor(0.5016, grad_fn=<DivBackward1>)\n",
      "tensor(0.1988, grad_fn=<DivBackward1>)\n",
      "tensor(0.1341, grad_fn=<DivBackward1>)\n",
      "tensor(0.5234, grad_fn=<DivBackward1>)\n",
      "tensor(0.4336, grad_fn=<DivBackward1>)\n",
      "tensor(0.2986, grad_fn=<DivBackward1>)\n",
      "tensor(0.2108, grad_fn=<DivBackward1>)\n",
      "tensor(0.3628, grad_fn=<DivBackward1>)\n",
      "tensor(0.2700, grad_fn=<DivBackward1>)\n",
      "tensor(0.2966, grad_fn=<DivBackward1>)\n",
      "tensor(0.6138, grad_fn=<DivBackward1>)\n",
      "tensor(0.5409, grad_fn=<DivBackward1>)\n",
      "tensor(1.1124, grad_fn=<DivBackward1>)\n",
      "tensor(0.6036, grad_fn=<DivBackward1>)\n",
      "tensor(0.3688, grad_fn=<DivBackward1>)\n",
      "tensor(0.3868, grad_fn=<DivBackward1>)\n",
      "tensor(0.2969, grad_fn=<DivBackward1>)\n",
      "tensor(0.4686, grad_fn=<DivBackward1>)\n",
      "tensor(0.2012, grad_fn=<DivBackward1>)\n",
      "tensor(0.3890, grad_fn=<DivBackward1>)\n",
      "tensor(0.6261, grad_fn=<DivBackward1>)\n",
      "tensor(0.3283, grad_fn=<DivBackward1>)\n",
      "tensor(0.2052, grad_fn=<DivBackward1>)\n",
      "tensor(0.2985, grad_fn=<DivBackward1>)\n",
      "tensor(0.6818, grad_fn=<DivBackward1>)\n",
      "tensor(0.2334, grad_fn=<DivBackward1>)\n",
      "tensor(0.5800, grad_fn=<DivBackward1>)\n",
      "tensor(0.3244, grad_fn=<DivBackward1>)\n",
      "tensor(0.4073, grad_fn=<DivBackward1>)\n",
      "tensor(0.8902, grad_fn=<DivBackward1>)\n",
      "tensor(0.2746, grad_fn=<DivBackward1>)\n",
      "tensor(0.4323, grad_fn=<DivBackward1>)\n",
      "tensor(0.1947, grad_fn=<DivBackward1>)\n",
      "tensor(0.7091, grad_fn=<DivBackward1>)\n",
      "tensor(0.2946, grad_fn=<DivBackward1>)\n",
      "tensor(0.5372, grad_fn=<DivBackward1>)\n",
      "tensor(0.3152, grad_fn=<DivBackward1>)\n",
      "tensor(0.3116, grad_fn=<DivBackward1>)\n",
      "tensor(0.2866, grad_fn=<DivBackward1>)\n",
      "tensor(0.2771, grad_fn=<DivBackward1>)\n",
      "tensor(0.1190, grad_fn=<DivBackward1>)\n",
      "tensor(0.5812, grad_fn=<DivBackward1>)\n",
      "tensor(0.6945, grad_fn=<DivBackward1>)\n",
      "tensor(0.3894, grad_fn=<DivBackward1>)\n",
      "tensor(0.1571, grad_fn=<DivBackward1>)\n",
      "tensor(0.4305, grad_fn=<DivBackward1>)\n",
      "tensor(0.7341, grad_fn=<DivBackward1>)\n",
      "tensor(0.4294, grad_fn=<DivBackward1>)\n",
      "tensor(0.2672, grad_fn=<DivBackward1>)\n",
      "tensor(0.3433, grad_fn=<DivBackward1>)\n",
      "tensor(0.3356, grad_fn=<DivBackward1>)\n",
      "tensor(0.3312, grad_fn=<DivBackward1>)\n",
      "tensor(0.2580, grad_fn=<DivBackward1>)\n",
      "tensor(0.6801, grad_fn=<DivBackward1>)\n",
      "tensor(1.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.8225, grad_fn=<DivBackward1>)\n",
      "tensor(0.2161, grad_fn=<DivBackward1>)\n",
      "tensor(0.7230, grad_fn=<DivBackward1>)\n",
      "tensor(0.2048, grad_fn=<DivBackward1>)\n",
      "tensor(0.1270, grad_fn=<DivBackward1>)\n",
      "tensor(0.9404, grad_fn=<DivBackward1>)\n",
      "tensor(0.2062, grad_fn=<DivBackward1>)\n",
      "tensor(0.3491, grad_fn=<DivBackward1>)\n",
      "tensor(0.1955, grad_fn=<DivBackward1>)\n",
      "tensor(0.7369, grad_fn=<DivBackward1>)\n",
      "tensor(0.2429, grad_fn=<DivBackward1>)\n",
      "tensor(0.8815, grad_fn=<DivBackward1>)\n",
      "tensor(0.5409, grad_fn=<DivBackward1>)\n",
      "tensor(0.0670, grad_fn=<DivBackward1>)\n",
      "tensor(0.2103, grad_fn=<DivBackward1>)\n",
      "tensor(0.5095, grad_fn=<DivBackward1>)\n",
      "tensor(0.1822, grad_fn=<DivBackward1>)\n",
      "tensor(0.1268, grad_fn=<DivBackward1>)\n",
      "tensor(0.5373, grad_fn=<DivBackward1>)\n",
      "tensor(0.4266, grad_fn=<DivBackward1>)\n",
      "tensor(0.2881, grad_fn=<DivBackward1>)\n",
      "tensor(0.1979, grad_fn=<DivBackward1>)\n",
      "tensor(0.3515, grad_fn=<DivBackward1>)\n",
      "tensor(0.2652, grad_fn=<DivBackward1>)\n",
      "tensor(0.2877, grad_fn=<DivBackward1>)\n",
      "tensor(0.5956, grad_fn=<DivBackward1>)\n",
      "tensor(0.5372, grad_fn=<DivBackward1>)\n",
      "tensor(1.1147, grad_fn=<DivBackward1>)\n",
      "tensor(0.6098, grad_fn=<DivBackward1>)\n",
      "tensor(0.3515, grad_fn=<DivBackward1>)\n",
      "tensor(0.3717, grad_fn=<DivBackward1>)\n",
      "tensor(0.2849, grad_fn=<DivBackward1>)\n",
      "tensor(0.4500, grad_fn=<DivBackward1>)\n",
      "tensor(0.1978, grad_fn=<DivBackward1>)\n",
      "tensor(0.3708, grad_fn=<DivBackward1>)\n",
      "tensor(0.6266, grad_fn=<DivBackward1>)\n",
      "tensor(0.3219, grad_fn=<DivBackward1>)\n",
      "tensor(0.1922, grad_fn=<DivBackward1>)\n",
      "tensor(0.3008, grad_fn=<DivBackward1>)\n",
      "tensor(0.6634, grad_fn=<DivBackward1>)\n",
      "tensor(0.2337, grad_fn=<DivBackward1>)\n",
      "tensor(0.5759, grad_fn=<DivBackward1>)\n",
      "tensor(0.3002, grad_fn=<DivBackward1>)\n",
      "tensor(0.3856, grad_fn=<DivBackward1>)\n",
      "tensor(0.8713, grad_fn=<DivBackward1>)\n",
      "tensor(0.2622, grad_fn=<DivBackward1>)\n",
      "tensor(0.4153, grad_fn=<DivBackward1>)\n",
      "tensor(0.1849, grad_fn=<DivBackward1>)\n",
      "tensor(0.6960, grad_fn=<DivBackward1>)\n",
      "tensor(0.2796, grad_fn=<DivBackward1>)\n",
      "tensor(0.5367, grad_fn=<DivBackward1>)\n",
      "tensor(0.3001, grad_fn=<DivBackward1>)\n",
      "tensor(0.3062, grad_fn=<DivBackward1>)\n",
      "tensor(0.2781, grad_fn=<DivBackward1>)\n",
      "tensor(0.2639, grad_fn=<DivBackward1>)\n",
      "tensor(0.1124, grad_fn=<DivBackward1>)\n",
      "tensor(0.5691, grad_fn=<DivBackward1>)\n",
      "tensor(0.6799, grad_fn=<DivBackward1>)\n",
      "tensor(0.3723, grad_fn=<DivBackward1>)\n",
      "tensor(0.1431, grad_fn=<DivBackward1>)\n",
      "tensor(0.4159, grad_fn=<DivBackward1>)\n",
      "tensor(0.7050, grad_fn=<DivBackward1>)\n",
      "tensor(0.4097, grad_fn=<DivBackward1>)\n",
      "tensor(0.2652, grad_fn=<DivBackward1>)\n",
      "tensor(0.3318, grad_fn=<DivBackward1>)\n",
      "tensor(0.3226, grad_fn=<DivBackward1>)\n",
      "tensor(0.3225, grad_fn=<DivBackward1>)\n",
      "tensor(0.2440, grad_fn=<DivBackward1>)\n",
      "tensor(0.6857, grad_fn=<DivBackward1>)\n",
      "tensor(1.0298, grad_fn=<DivBackward1>)\n",
      "tensor(0.7979, grad_fn=<DivBackward1>)\n",
      "tensor(0.2130, grad_fn=<DivBackward1>)\n",
      "tensor(0.7096, grad_fn=<DivBackward1>)\n",
      "tensor(0.2055, grad_fn=<DivBackward1>)\n",
      "tensor(0.1210, grad_fn=<DivBackward1>)\n",
      "tensor(0.9036, grad_fn=<DivBackward1>)\n",
      "tensor(0.1928, grad_fn=<DivBackward1>)\n",
      "tensor(0.3316, grad_fn=<DivBackward1>)\n",
      "tensor(0.1894, grad_fn=<DivBackward1>)\n",
      "tensor(0.7254, grad_fn=<DivBackward1>)\n",
      "tensor(0.2267, grad_fn=<DivBackward1>)\n",
      "tensor(0.8484, grad_fn=<DivBackward1>)\n",
      "tensor(0.5263, grad_fn=<DivBackward1>)\n",
      "tensor(0.0643, grad_fn=<DivBackward1>)\n",
      "tensor(0.2003, grad_fn=<DivBackward1>)\n",
      "tensor(0.5179, grad_fn=<DivBackward1>)\n",
      "tensor(0.1745, grad_fn=<DivBackward1>)\n",
      "tensor(0.1244, grad_fn=<DivBackward1>)\n",
      "tensor(0.5490, grad_fn=<DivBackward1>)\n",
      "tensor(0.4220, grad_fn=<DivBackward1>)\n",
      "tensor(0.2731, grad_fn=<DivBackward1>)\n",
      "tensor(0.1915, grad_fn=<DivBackward1>)\n",
      "tensor(0.3411, grad_fn=<DivBackward1>)\n",
      "tensor(0.2541, grad_fn=<DivBackward1>)\n",
      "tensor(0.2767, grad_fn=<DivBackward1>)\n",
      "tensor(0.5815, grad_fn=<DivBackward1>)\n",
      "tensor(0.5325, grad_fn=<DivBackward1>)\n",
      "tensor(1.1342, grad_fn=<DivBackward1>)\n",
      "tensor(0.6052, grad_fn=<DivBackward1>)\n",
      "tensor(0.3335, grad_fn=<DivBackward1>)\n",
      "tensor(0.3578, grad_fn=<DivBackward1>)\n",
      "tensor(0.2679, grad_fn=<DivBackward1>)\n",
      "tensor(0.4260, grad_fn=<DivBackward1>)\n",
      "tensor(0.1994, grad_fn=<DivBackward1>)\n",
      "tensor(0.3552, grad_fn=<DivBackward1>)\n",
      "tensor(0.6303, grad_fn=<DivBackward1>)\n",
      "tensor(0.3084, grad_fn=<DivBackward1>)\n",
      "tensor(0.1867, grad_fn=<DivBackward1>)\n",
      "tensor(0.2998, grad_fn=<DivBackward1>)\n",
      "tensor(0.6303, grad_fn=<DivBackward1>)\n",
      "tensor(0.2400, grad_fn=<DivBackward1>)\n",
      "tensor(0.5566, grad_fn=<DivBackward1>)\n",
      "tensor(0.2975, grad_fn=<DivBackward1>)\n",
      "tensor(0.3693, grad_fn=<DivBackward1>)\n",
      "tensor(0.8597, grad_fn=<DivBackward1>)\n",
      "tensor(0.2531, grad_fn=<DivBackward1>)\n",
      "tensor(0.4045, grad_fn=<DivBackward1>)\n",
      "tensor(0.1768, grad_fn=<DivBackward1>)\n",
      "tensor(0.6731, grad_fn=<DivBackward1>)\n",
      "tensor(0.2690, grad_fn=<DivBackward1>)\n",
      "tensor(0.5397, grad_fn=<DivBackward1>)\n",
      "tensor(0.2869, grad_fn=<DivBackward1>)\n",
      "tensor(0.2876, grad_fn=<DivBackward1>)\n",
      "tensor(0.2793, grad_fn=<DivBackward1>)\n",
      "tensor(0.2524, grad_fn=<DivBackward1>)\n",
      "tensor(0.1056, grad_fn=<DivBackward1>)\n",
      "tensor(0.5597, grad_fn=<DivBackward1>)\n",
      "tensor(0.6900, grad_fn=<DivBackward1>)\n",
      "tensor(0.3602, grad_fn=<DivBackward1>)\n",
      "tensor(0.1321, grad_fn=<DivBackward1>)\n",
      "tensor(0.4044, grad_fn=<DivBackward1>)\n",
      "tensor(0.6722, grad_fn=<DivBackward1>)\n",
      "tensor(0.4067, grad_fn=<DivBackward1>)\n",
      "tensor(0.2600, grad_fn=<DivBackward1>)\n",
      "tensor(0.3337, grad_fn=<DivBackward1>)\n",
      "tensor(0.3118, grad_fn=<DivBackward1>)\n",
      "tensor(0.3140, grad_fn=<DivBackward1>)\n",
      "tensor(0.2352, grad_fn=<DivBackward1>)\n",
      "tensor(0.6866, grad_fn=<DivBackward1>)\n",
      "tensor(1.0335, grad_fn=<DivBackward1>)\n",
      "tensor(0.7687, grad_fn=<DivBackward1>)\n",
      "tensor(0.2098, grad_fn=<DivBackward1>)\n",
      "tensor(0.6964, grad_fn=<DivBackward1>)\n",
      "tensor(0.2002, grad_fn=<DivBackward1>)\n",
      "tensor(0.1124, grad_fn=<DivBackward1>)\n",
      "tensor(0.8789, grad_fn=<DivBackward1>)\n",
      "tensor(0.1813, grad_fn=<DivBackward1>)\n",
      "tensor(0.3131, grad_fn=<DivBackward1>)\n",
      "tensor(0.1892, grad_fn=<DivBackward1>)\n",
      "tensor(0.7242, grad_fn=<DivBackward1>)\n",
      "tensor(0.2046, grad_fn=<DivBackward1>)\n",
      "tensor(0.8299, grad_fn=<DivBackward1>)\n",
      "tensor(0.5185, grad_fn=<DivBackward1>)\n",
      "tensor(0.0650, grad_fn=<DivBackward1>)\n",
      "tensor(0.1911, grad_fn=<DivBackward1>)\n",
      "tensor(0.5206, grad_fn=<DivBackward1>)\n",
      "tensor(0.1680, grad_fn=<DivBackward1>)\n",
      "tensor(0.1229, grad_fn=<DivBackward1>)\n",
      "tensor(0.5564, grad_fn=<DivBackward1>)\n",
      "tensor(0.4145, grad_fn=<DivBackward1>)\n",
      "tensor(0.2650, grad_fn=<DivBackward1>)\n",
      "tensor(0.1807, grad_fn=<DivBackward1>)\n",
      "tensor(0.3257, grad_fn=<DivBackward1>)\n",
      "tensor(0.2416, grad_fn=<DivBackward1>)\n",
      "tensor(0.2750, grad_fn=<DivBackward1>)\n",
      "tensor(0.5583, grad_fn=<DivBackward1>)\n",
      "tensor(0.5220, grad_fn=<DivBackward1>)\n",
      "tensor(1.1299, grad_fn=<DivBackward1>)\n",
      "tensor(0.6066, grad_fn=<DivBackward1>)\n",
      "tensor(0.3063, grad_fn=<DivBackward1>)\n",
      "tensor(0.3482, grad_fn=<DivBackward1>)\n",
      "tensor(0.2520, grad_fn=<DivBackward1>)\n",
      "tensor(0.3987, grad_fn=<DivBackward1>)\n",
      "tensor(0.1950, grad_fn=<DivBackward1>)\n",
      "tensor(0.3282, grad_fn=<DivBackward1>)\n",
      "tensor(0.6350, grad_fn=<DivBackward1>)\n",
      "tensor(0.2930, grad_fn=<DivBackward1>)\n",
      "tensor(0.1729, grad_fn=<DivBackward1>)\n",
      "tensor(0.3019, grad_fn=<DivBackward1>)\n",
      "tensor(0.6201, grad_fn=<DivBackward1>)\n",
      "tensor(0.2364, grad_fn=<DivBackward1>)\n",
      "tensor(0.5600, grad_fn=<DivBackward1>)\n",
      "tensor(0.2938, grad_fn=<DivBackward1>)\n",
      "tensor(0.3684, grad_fn=<DivBackward1>)\n",
      "tensor(0.8349, grad_fn=<DivBackward1>)\n",
      "tensor(0.2419, grad_fn=<DivBackward1>)\n",
      "tensor(0.3819, grad_fn=<DivBackward1>)\n",
      "tensor(0.1660, grad_fn=<DivBackward1>)\n",
      "tensor(0.6738, grad_fn=<DivBackward1>)\n",
      "tensor(0.2698, grad_fn=<DivBackward1>)\n",
      "tensor(0.5422, grad_fn=<DivBackward1>)\n",
      "tensor(0.2644, grad_fn=<DivBackward1>)\n",
      "tensor(0.2709, grad_fn=<DivBackward1>)\n",
      "tensor(0.2728, grad_fn=<DivBackward1>)\n",
      "tensor(0.2395, grad_fn=<DivBackward1>)\n",
      "tensor(0.0978, grad_fn=<DivBackward1>)\n",
      "tensor(0.5487, grad_fn=<DivBackward1>)\n",
      "tensor(0.6899, grad_fn=<DivBackward1>)\n",
      "tensor(0.3650, grad_fn=<DivBackward1>)\n",
      "tensor(0.1254, grad_fn=<DivBackward1>)\n",
      "tensor(0.3822, grad_fn=<DivBackward1>)\n",
      "tensor(0.6315, grad_fn=<DivBackward1>)\n",
      "tensor(0.3970, grad_fn=<DivBackward1>)\n",
      "tensor(0.2541, grad_fn=<DivBackward1>)\n",
      "tensor(0.3192, grad_fn=<DivBackward1>)\n",
      "tensor(0.3076, grad_fn=<DivBackward1>)\n",
      "tensor(0.3077, grad_fn=<DivBackward1>)\n",
      "tensor(0.2230, grad_fn=<DivBackward1>)\n",
      "tensor(0.6947, grad_fn=<DivBackward1>)\n",
      "tensor(1.0275, grad_fn=<DivBackward1>)\n",
      "tensor(0.7463, grad_fn=<DivBackward1>)\n",
      "tensor(0.2115, grad_fn=<DivBackward1>)\n",
      "tensor(0.6957, grad_fn=<DivBackward1>)\n",
      "tensor(0.2026, grad_fn=<DivBackward1>)\n",
      "tensor(0.1029, grad_fn=<DivBackward1>)\n",
      "tensor(0.8376, grad_fn=<DivBackward1>)\n",
      "tensor(0.1664, grad_fn=<DivBackward1>)\n",
      "tensor(0.3002, grad_fn=<DivBackward1>)\n",
      "tensor(0.1860, grad_fn=<DivBackward1>)\n",
      "tensor(0.7010, grad_fn=<DivBackward1>)\n",
      "tensor(0.1838, grad_fn=<DivBackward1>)\n",
      "tensor(0.8053, grad_fn=<DivBackward1>)\n",
      "tensor(0.5038, grad_fn=<DivBackward1>)\n",
      "tensor(0.0689, grad_fn=<DivBackward1>)\n",
      "tensor(0.1815, grad_fn=<DivBackward1>)\n",
      "tensor(0.5317, grad_fn=<DivBackward1>)\n",
      "tensor(0.1557, grad_fn=<DivBackward1>)\n",
      "tensor(0.1168, grad_fn=<DivBackward1>)\n",
      "tensor(0.5726, grad_fn=<DivBackward1>)\n",
      "tensor(0.4062, grad_fn=<DivBackward1>)\n",
      "tensor(0.2646, grad_fn=<DivBackward1>)\n",
      "tensor(0.1641, grad_fn=<DivBackward1>)\n",
      "tensor(0.3191, grad_fn=<DivBackward1>)\n",
      "tensor(0.2266, grad_fn=<DivBackward1>)\n",
      "tensor(0.2747, grad_fn=<DivBackward1>)\n",
      "tensor(0.5435, grad_fn=<DivBackward1>)\n",
      "tensor(0.5085, grad_fn=<DivBackward1>)\n",
      "tensor(1.1412, grad_fn=<DivBackward1>)\n",
      "tensor(0.6114, grad_fn=<DivBackward1>)\n",
      "tensor(0.2887, grad_fn=<DivBackward1>)\n",
      "tensor(0.3393, grad_fn=<DivBackward1>)\n",
      "tensor(0.2528, grad_fn=<DivBackward1>)\n",
      "tensor(0.3777, grad_fn=<DivBackward1>)\n",
      "tensor(0.1864, grad_fn=<DivBackward1>)\n",
      "tensor(0.3098, grad_fn=<DivBackward1>)\n",
      "tensor(0.6330, grad_fn=<DivBackward1>)\n",
      "tensor(0.2834, grad_fn=<DivBackward1>)\n",
      "tensor(0.1531, grad_fn=<DivBackward1>)\n",
      "tensor(0.3088, grad_fn=<DivBackward1>)\n",
      "tensor(0.6081, grad_fn=<DivBackward1>)\n",
      "tensor(0.2354, grad_fn=<DivBackward1>)\n",
      "tensor(0.5339, grad_fn=<DivBackward1>)\n",
      "tensor(0.2752, grad_fn=<DivBackward1>)\n",
      "tensor(0.3416, grad_fn=<DivBackward1>)\n",
      "tensor(0.8144, grad_fn=<DivBackward1>)\n",
      "tensor(0.2295, grad_fn=<DivBackward1>)\n",
      "tensor(0.3531, grad_fn=<DivBackward1>)\n",
      "tensor(0.1596, grad_fn=<DivBackward1>)\n",
      "tensor(0.6634, grad_fn=<DivBackward1>)\n",
      "tensor(0.2571, grad_fn=<DivBackward1>)\n",
      "tensor(0.5378, grad_fn=<DivBackward1>)\n",
      "tensor(0.2437, grad_fn=<DivBackward1>)\n",
      "tensor(0.2520, grad_fn=<DivBackward1>)\n",
      "tensor(0.2616, grad_fn=<DivBackward1>)\n",
      "tensor(0.2252, grad_fn=<DivBackward1>)\n",
      "tensor(0.0894, grad_fn=<DivBackward1>)\n",
      "tensor(0.5423, grad_fn=<DivBackward1>)\n",
      "tensor(0.6952, grad_fn=<DivBackward1>)\n",
      "tensor(0.3514, grad_fn=<DivBackward1>)\n",
      "tensor(0.1165, grad_fn=<DivBackward1>)\n",
      "tensor(0.3748, grad_fn=<DivBackward1>)\n",
      "tensor(0.6023, grad_fn=<DivBackward1>)\n",
      "tensor(0.3873, grad_fn=<DivBackward1>)\n",
      "tensor(0.2428, grad_fn=<DivBackward1>)\n",
      "tensor(0.3126, grad_fn=<DivBackward1>)\n",
      "tensor(0.2989, grad_fn=<DivBackward1>)\n",
      "tensor(0.3039, grad_fn=<DivBackward1>)\n",
      "tensor(0.2155, grad_fn=<DivBackward1>)\n",
      "tensor(0.7002, grad_fn=<DivBackward1>)\n",
      "tensor(1.0157, grad_fn=<DivBackward1>)\n",
      "tensor(0.7164, grad_fn=<DivBackward1>)\n",
      "tensor(0.1974, grad_fn=<DivBackward1>)\n",
      "tensor(0.6826, grad_fn=<DivBackward1>)\n",
      "tensor(0.1970, grad_fn=<DivBackward1>)\n",
      "tensor(0.0956, grad_fn=<DivBackward1>)\n",
      "tensor(0.8121, grad_fn=<DivBackward1>)\n",
      "tensor(0.1546, grad_fn=<DivBackward1>)\n",
      "tensor(0.2853, grad_fn=<DivBackward1>)\n",
      "tensor(0.1843, grad_fn=<DivBackward1>)\n",
      "tensor(0.6983, grad_fn=<DivBackward1>)\n",
      "tensor(0.1692, grad_fn=<DivBackward1>)\n",
      "tensor(0.7653, grad_fn=<DivBackward1>)\n",
      "tensor(0.4894, grad_fn=<DivBackward1>)\n",
      "tensor(0.0693, grad_fn=<DivBackward1>)\n",
      "tensor(0.1719, grad_fn=<DivBackward1>)\n",
      "tensor(0.5390, grad_fn=<DivBackward1>)\n",
      "tensor(0.1523, grad_fn=<DivBackward1>)\n",
      "tensor(0.1171, grad_fn=<DivBackward1>)\n",
      "tensor(0.5692, grad_fn=<DivBackward1>)\n",
      "tensor(0.4110, grad_fn=<DivBackward1>)\n",
      "tensor(0.2584, grad_fn=<DivBackward1>)\n",
      "tensor(0.1531, grad_fn=<DivBackward1>)\n",
      "tensor(0.3016, grad_fn=<DivBackward1>)\n",
      "tensor(0.2195, grad_fn=<DivBackward1>)\n",
      "tensor(0.2681, grad_fn=<DivBackward1>)\n",
      "tensor(0.5286, grad_fn=<DivBackward1>)\n",
      "tensor(0.4970, grad_fn=<DivBackward1>)\n",
      "tensor(1.1393, grad_fn=<DivBackward1>)\n",
      "tensor(0.6105, grad_fn=<DivBackward1>)\n",
      "tensor(0.2777, grad_fn=<DivBackward1>)\n",
      "tensor(0.3287, grad_fn=<DivBackward1>)\n",
      "tensor(0.2428, grad_fn=<DivBackward1>)\n",
      "tensor(0.3615, grad_fn=<DivBackward1>)\n",
      "tensor(0.1847, grad_fn=<DivBackward1>)\n",
      "tensor(0.2901, grad_fn=<DivBackward1>)\n",
      "tensor(0.6386, grad_fn=<DivBackward1>)\n",
      "tensor(0.2708, grad_fn=<DivBackward1>)\n",
      "tensor(0.1532, grad_fn=<DivBackward1>)\n",
      "tensor(0.2972, grad_fn=<DivBackward1>)\n",
      "tensor(0.5894, grad_fn=<DivBackward1>)\n",
      "tensor(0.2320, grad_fn=<DivBackward1>)\n",
      "tensor(0.5127, grad_fn=<DivBackward1>)\n",
      "tensor(0.2647, grad_fn=<DivBackward1>)\n",
      "tensor(0.3128, grad_fn=<DivBackward1>)\n",
      "tensor(0.7705, grad_fn=<DivBackward1>)\n",
      "tensor(0.2275, grad_fn=<DivBackward1>)\n",
      "tensor(0.3313, grad_fn=<DivBackward1>)\n",
      "tensor(0.1576, grad_fn=<DivBackward1>)\n",
      "tensor(0.6609, grad_fn=<DivBackward1>)\n",
      "tensor(0.2543, grad_fn=<DivBackward1>)\n",
      "tensor(0.5289, grad_fn=<DivBackward1>)\n",
      "tensor(0.2303, grad_fn=<DivBackward1>)\n",
      "tensor(0.2229, grad_fn=<DivBackward1>)\n",
      "tensor(0.2616, grad_fn=<DivBackward1>)\n",
      "tensor(0.2096, grad_fn=<DivBackward1>)\n",
      "tensor(0.0855, grad_fn=<DivBackward1>)\n",
      "tensor(0.5412, grad_fn=<DivBackward1>)\n",
      "tensor(0.7228, grad_fn=<DivBackward1>)\n",
      "tensor(0.3657, grad_fn=<DivBackward1>)\n",
      "tensor(0.1072, grad_fn=<DivBackward1>)\n",
      "tensor(0.3538, grad_fn=<DivBackward1>)\n",
      "tensor(0.5755, grad_fn=<DivBackward1>)\n",
      "tensor(0.3680, grad_fn=<DivBackward1>)\n",
      "tensor(0.2386, grad_fn=<DivBackward1>)\n",
      "tensor(0.3029, grad_fn=<DivBackward1>)\n",
      "tensor(0.2772, grad_fn=<DivBackward1>)\n",
      "tensor(0.2978, grad_fn=<DivBackward1>)\n",
      "tensor(0.1948, grad_fn=<DivBackward1>)\n",
      "tensor(0.7080, grad_fn=<DivBackward1>)\n",
      "tensor(1.0060, grad_fn=<DivBackward1>)\n",
      "tensor(0.6746, grad_fn=<DivBackward1>)\n",
      "tensor(0.2046, grad_fn=<DivBackward1>)\n",
      "tensor(0.6745, grad_fn=<DivBackward1>)\n",
      "tensor(0.1976, grad_fn=<DivBackward1>)\n",
      "tensor(0.0896, grad_fn=<DivBackward1>)\n",
      "tensor(0.7685, grad_fn=<DivBackward1>)\n",
      "tensor(0.1432, grad_fn=<DivBackward1>)\n",
      "tensor(0.2716, grad_fn=<DivBackward1>)\n",
      "tensor(0.1810, grad_fn=<DivBackward1>)\n",
      "tensor(0.6502, grad_fn=<DivBackward1>)\n",
      "tensor(0.1537, grad_fn=<DivBackward1>)\n",
      "tensor(0.7409, grad_fn=<DivBackward1>)\n",
      "tensor(0.4769, grad_fn=<DivBackward1>)\n",
      "tensor(0.0692, grad_fn=<DivBackward1>)\n",
      "tensor(0.1654, grad_fn=<DivBackward1>)\n",
      "tensor(0.5349, grad_fn=<DivBackward1>)\n",
      "tensor(0.1500, grad_fn=<DivBackward1>)\n",
      "tensor(0.1114, grad_fn=<DivBackward1>)\n",
      "tensor(0.5809, grad_fn=<DivBackward1>)\n",
      "tensor(0.4213, grad_fn=<DivBackward1>)\n",
      "tensor(0.2575, grad_fn=<DivBackward1>)\n",
      "tensor(0.1447, grad_fn=<DivBackward1>)\n",
      "tensor(0.2889, grad_fn=<DivBackward1>)\n",
      "tensor(0.2078, grad_fn=<DivBackward1>)\n",
      "tensor(0.2656, grad_fn=<DivBackward1>)\n",
      "tensor(0.5219, grad_fn=<DivBackward1>)\n",
      "tensor(0.4916, grad_fn=<DivBackward1>)\n",
      "tensor(1.1271, grad_fn=<DivBackward1>)\n",
      "tensor(0.6060, grad_fn=<DivBackward1>)\n",
      "tensor(0.2638, grad_fn=<DivBackward1>)\n",
      "tensor(0.3173, grad_fn=<DivBackward1>)\n",
      "tensor(0.2374, grad_fn=<DivBackward1>)\n",
      "tensor(0.3326, grad_fn=<DivBackward1>)\n",
      "tensor(0.1791, grad_fn=<DivBackward1>)\n",
      "tensor(0.2739, grad_fn=<DivBackward1>)\n",
      "tensor(0.6467, grad_fn=<DivBackward1>)\n",
      "tensor(0.2660, grad_fn=<DivBackward1>)\n",
      "tensor(0.1410, grad_fn=<DivBackward1>)\n",
      "tensor(0.2940, grad_fn=<DivBackward1>)\n",
      "tensor(0.5902, grad_fn=<DivBackward1>)\n",
      "tensor(0.2370, grad_fn=<DivBackward1>)\n",
      "tensor(0.4787, grad_fn=<DivBackward1>)\n",
      "tensor(0.2578, grad_fn=<DivBackward1>)\n",
      "tensor(0.2946, grad_fn=<DivBackward1>)\n",
      "tensor(0.7456, grad_fn=<DivBackward1>)\n",
      "tensor(0.2267, grad_fn=<DivBackward1>)\n",
      "tensor(0.3073, grad_fn=<DivBackward1>)\n",
      "tensor(0.1495, grad_fn=<DivBackward1>)\n",
      "tensor(0.6462, grad_fn=<DivBackward1>)\n",
      "tensor(0.2603, grad_fn=<DivBackward1>)\n",
      "tensor(0.5446, grad_fn=<DivBackward1>)\n",
      "tensor(0.2065, grad_fn=<DivBackward1>)\n",
      "tensor(0.2109, grad_fn=<DivBackward1>)\n",
      "tensor(0.2479, grad_fn=<DivBackward1>)\n",
      "tensor(0.1970, grad_fn=<DivBackward1>)\n",
      "tensor(0.0766, grad_fn=<DivBackward1>)\n",
      "tensor(0.5255, grad_fn=<DivBackward1>)\n",
      "tensor(0.7029, grad_fn=<DivBackward1>)\n",
      "tensor(0.3469, grad_fn=<DivBackward1>)\n",
      "tensor(0.0981, grad_fn=<DivBackward1>)\n",
      "tensor(0.3499, grad_fn=<DivBackward1>)\n",
      "tensor(0.5221, grad_fn=<DivBackward1>)\n",
      "tensor(0.3496, grad_fn=<DivBackward1>)\n",
      "tensor(0.2219, grad_fn=<DivBackward1>)\n",
      "tensor(0.3045, grad_fn=<DivBackward1>)\n",
      "tensor(0.2633, grad_fn=<DivBackward1>)\n",
      "tensor(0.2821, grad_fn=<DivBackward1>)\n",
      "tensor(0.1799, grad_fn=<DivBackward1>)\n",
      "tensor(0.7153, grad_fn=<DivBackward1>)\n",
      "tensor(1.0076, grad_fn=<DivBackward1>)\n",
      "tensor(0.6574, grad_fn=<DivBackward1>)\n",
      "tensor(0.1923, grad_fn=<DivBackward1>)\n",
      "tensor(0.6604, grad_fn=<DivBackward1>)\n",
      "tensor(0.1900, grad_fn=<DivBackward1>)\n",
      "tensor(0.0805, grad_fn=<DivBackward1>)\n",
      "tensor(0.7452, grad_fn=<DivBackward1>)\n",
      "tensor(0.1302, grad_fn=<DivBackward1>)\n",
      "tensor(0.2568, grad_fn=<DivBackward1>)\n",
      "tensor(0.1807, grad_fn=<DivBackward1>)\n",
      "tensor(0.6290, grad_fn=<DivBackward1>)\n",
      "tensor(0.1422, grad_fn=<DivBackward1>)\n",
      "tensor(0.7153, grad_fn=<DivBackward1>)\n",
      "tensor(0.4503, grad_fn=<DivBackward1>)\n",
      "tensor(0.0669, grad_fn=<DivBackward1>)\n",
      "tensor(0.1566, grad_fn=<DivBackward1>)\n",
      "tensor(0.5389, grad_fn=<DivBackward1>)\n",
      "tensor(0.1402, grad_fn=<DivBackward1>)\n",
      "tensor(0.1100, grad_fn=<DivBackward1>)\n",
      "tensor(0.5715, grad_fn=<DivBackward1>)\n",
      "tensor(0.4294, grad_fn=<DivBackward1>)\n",
      "tensor(0.2558, grad_fn=<DivBackward1>)\n",
      "tensor(0.1394, grad_fn=<DivBackward1>)\n",
      "tensor(0.2697, grad_fn=<DivBackward1>)\n",
      "tensor(0.2034, grad_fn=<DivBackward1>)\n",
      "tensor(0.2614, grad_fn=<DivBackward1>)\n",
      "tensor(0.4947, grad_fn=<DivBackward1>)\n",
      "tensor(0.4760, grad_fn=<DivBackward1>)\n",
      "tensor(1.1168, grad_fn=<DivBackward1>)\n",
      "tensor(0.6042, grad_fn=<DivBackward1>)\n",
      "tensor(0.2504, grad_fn=<DivBackward1>)\n",
      "tensor(0.2961, grad_fn=<DivBackward1>)\n",
      "tensor(0.2251, grad_fn=<DivBackward1>)\n",
      "tensor(0.3121, grad_fn=<DivBackward1>)\n",
      "tensor(0.1749, grad_fn=<DivBackward1>)\n",
      "tensor(0.2566, grad_fn=<DivBackward1>)\n",
      "tensor(0.6472, grad_fn=<DivBackward1>)\n",
      "tensor(0.2632, grad_fn=<DivBackward1>)\n",
      "tensor(0.1341, grad_fn=<DivBackward1>)\n",
      "tensor(0.2841, grad_fn=<DivBackward1>)\n",
      "tensor(0.5830, grad_fn=<DivBackward1>)\n",
      "tensor(0.2366, grad_fn=<DivBackward1>)\n",
      "tensor(0.4908, grad_fn=<DivBackward1>)\n",
      "tensor(0.2401, grad_fn=<DivBackward1>)\n",
      "tensor(0.2805, grad_fn=<DivBackward1>)\n",
      "tensor(0.7144, grad_fn=<DivBackward1>)\n",
      "tensor(0.2271, grad_fn=<DivBackward1>)\n",
      "tensor(0.2915, grad_fn=<DivBackward1>)\n",
      "tensor(0.1398, grad_fn=<DivBackward1>)\n",
      "tensor(0.6126, grad_fn=<DivBackward1>)\n",
      "tensor(0.2376, grad_fn=<DivBackward1>)\n",
      "tensor(0.5289, grad_fn=<DivBackward1>)\n",
      "tensor(0.1888, grad_fn=<DivBackward1>)\n",
      "tensor(0.2141, grad_fn=<DivBackward1>)\n",
      "tensor(0.2298, grad_fn=<DivBackward1>)\n",
      "tensor(0.2071, grad_fn=<DivBackward1>)\n",
      "tensor(0.0725, grad_fn=<DivBackward1>)\n",
      "tensor(0.5029, grad_fn=<DivBackward1>)\n",
      "tensor(0.6915, grad_fn=<DivBackward1>)\n",
      "tensor(0.3231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0882, grad_fn=<DivBackward1>)\n",
      "tensor(0.3278, grad_fn=<DivBackward1>)\n",
      "tensor(0.4949, grad_fn=<DivBackward1>)\n",
      "tensor(0.3512, grad_fn=<DivBackward1>)\n",
      "tensor(0.2133, grad_fn=<DivBackward1>)\n",
      "tensor(0.2968, grad_fn=<DivBackward1>)\n",
      "tensor(0.2665, grad_fn=<DivBackward1>)\n",
      "tensor(0.2690, grad_fn=<DivBackward1>)\n",
      "tensor(0.1635, grad_fn=<DivBackward1>)\n",
      "tensor(0.7143, grad_fn=<DivBackward1>)\n",
      "tensor(1.0048, grad_fn=<DivBackward1>)\n",
      "tensor(0.6188, grad_fn=<DivBackward1>)\n",
      "tensor(0.1895, grad_fn=<DivBackward1>)\n",
      "tensor(0.6474, grad_fn=<DivBackward1>)\n",
      "tensor(0.1891, grad_fn=<DivBackward1>)\n",
      "tensor(0.0756, grad_fn=<DivBackward1>)\n",
      "tensor(0.7087, grad_fn=<DivBackward1>)\n",
      "tensor(0.1185, grad_fn=<DivBackward1>)\n",
      "tensor(0.2453, grad_fn=<DivBackward1>)\n",
      "tensor(0.1713, grad_fn=<DivBackward1>)\n",
      "tensor(0.6195, grad_fn=<DivBackward1>)\n",
      "tensor(0.1292, grad_fn=<DivBackward1>)\n",
      "tensor(0.6855, grad_fn=<DivBackward1>)\n",
      "tensor(0.4222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0678, grad_fn=<DivBackward1>)\n",
      "tensor(0.1448, grad_fn=<DivBackward1>)\n",
      "tensor(0.5401, grad_fn=<DivBackward1>)\n",
      "tensor(0.1256, grad_fn=<DivBackward1>)\n",
      "tensor(0.1030, grad_fn=<DivBackward1>)\n",
      "tensor(0.5860, grad_fn=<DivBackward1>)\n",
      "tensor(0.4322, grad_fn=<DivBackward1>)\n",
      "tensor(0.2638, grad_fn=<DivBackward1>)\n",
      "tensor(0.1275, grad_fn=<DivBackward1>)\n",
      "tensor(0.2622, grad_fn=<DivBackward1>)\n",
      "tensor(0.1923, grad_fn=<DivBackward1>)\n",
      "tensor(0.2549, grad_fn=<DivBackward1>)\n",
      "tensor(0.4767, grad_fn=<DivBackward1>)\n",
      "tensor(0.4672, grad_fn=<DivBackward1>)\n",
      "tensor(1.1080, grad_fn=<DivBackward1>)\n",
      "tensor(0.6141, grad_fn=<DivBackward1>)\n",
      "tensor(0.2419, grad_fn=<DivBackward1>)\n",
      "tensor(0.2712, grad_fn=<DivBackward1>)\n",
      "tensor(0.2238, grad_fn=<DivBackward1>)\n",
      "tensor(0.3007, grad_fn=<DivBackward1>)\n",
      "tensor(0.1697, grad_fn=<DivBackward1>)\n",
      "tensor(0.2401, grad_fn=<DivBackward1>)\n",
      "tensor(0.6493, grad_fn=<DivBackward1>)\n",
      "tensor(0.2661, grad_fn=<DivBackward1>)\n",
      "tensor(0.1259, grad_fn=<DivBackward1>)\n",
      "tensor(0.2958, grad_fn=<DivBackward1>)\n",
      "tensor(0.5611, grad_fn=<DivBackward1>)\n",
      "tensor(0.2237, grad_fn=<DivBackward1>)\n",
      "tensor(0.4658, grad_fn=<DivBackward1>)\n",
      "tensor(0.2179, grad_fn=<DivBackward1>)\n",
      "tensor(0.2510, grad_fn=<DivBackward1>)\n",
      "tensor(0.6760, grad_fn=<DivBackward1>)\n",
      "tensor(0.2232, grad_fn=<DivBackward1>)\n",
      "tensor(0.2601, grad_fn=<DivBackward1>)\n",
      "tensor(0.1429, grad_fn=<DivBackward1>)\n",
      "tensor(0.6089, grad_fn=<DivBackward1>)\n",
      "tensor(0.2279, grad_fn=<DivBackward1>)\n",
      "tensor(0.5186, grad_fn=<DivBackward1>)\n",
      "tensor(0.1888, grad_fn=<DivBackward1>)\n",
      "tensor(0.2042, grad_fn=<DivBackward1>)\n",
      "tensor(0.2281, grad_fn=<DivBackward1>)\n",
      "tensor(0.1868, grad_fn=<DivBackward1>)\n",
      "tensor(0.0709, grad_fn=<DivBackward1>)\n",
      "tensor(0.5020, grad_fn=<DivBackward1>)\n",
      "tensor(0.6540, grad_fn=<DivBackward1>)\n",
      "tensor(0.3153, grad_fn=<DivBackward1>)\n",
      "tensor(0.0875, grad_fn=<DivBackward1>)\n",
      "tensor(0.3046, grad_fn=<DivBackward1>)\n",
      "tensor(0.4487, grad_fn=<DivBackward1>)\n",
      "tensor(0.3505, grad_fn=<DivBackward1>)\n",
      "tensor(0.1945, grad_fn=<DivBackward1>)\n",
      "tensor(0.2840, grad_fn=<DivBackward1>)\n",
      "tensor(0.2444, grad_fn=<DivBackward1>)\n",
      "tensor(0.2543, grad_fn=<DivBackward1>)\n",
      "tensor(0.1549, grad_fn=<DivBackward1>)\n",
      "tensor(0.7260, grad_fn=<DivBackward1>)\n",
      "tensor(1.0096, grad_fn=<DivBackward1>)\n",
      "tensor(0.5884, grad_fn=<DivBackward1>)\n",
      "tensor(0.2035, grad_fn=<DivBackward1>)\n",
      "tensor(0.6455, grad_fn=<DivBackward1>)\n",
      "tensor(0.1885, grad_fn=<DivBackward1>)\n",
      "tensor(0.0695, grad_fn=<DivBackward1>)\n",
      "tensor(0.6771, grad_fn=<DivBackward1>)\n",
      "tensor(0.1073, grad_fn=<DivBackward1>)\n",
      "tensor(0.2387, grad_fn=<DivBackward1>)\n",
      "tensor(0.1759, grad_fn=<DivBackward1>)\n",
      "tensor(0.5932, grad_fn=<DivBackward1>)\n",
      "tensor(0.1161, grad_fn=<DivBackward1>)\n",
      "tensor(0.6405, grad_fn=<DivBackward1>)\n",
      "tensor(0.3824, grad_fn=<DivBackward1>)\n",
      "tensor(0.0683, grad_fn=<DivBackward1>)\n",
      "tensor(0.1311, grad_fn=<DivBackward1>)\n",
      "tensor(0.5336, grad_fn=<DivBackward1>)\n",
      "tensor(0.1200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0988, grad_fn=<DivBackward1>)\n",
      "tensor(0.5984, grad_fn=<DivBackward1>)\n",
      "tensor(0.4395, grad_fn=<DivBackward1>)\n",
      "tensor(0.2748, grad_fn=<DivBackward1>)\n",
      "tensor(0.1151, grad_fn=<DivBackward1>)\n",
      "tensor(0.2550, grad_fn=<DivBackward1>)\n",
      "tensor(0.1816, grad_fn=<DivBackward1>)\n",
      "tensor(0.2484, grad_fn=<DivBackward1>)\n",
      "tensor(0.4530, grad_fn=<DivBackward1>)\n",
      "tensor(0.4553, grad_fn=<DivBackward1>)\n",
      "tensor(1.0931, grad_fn=<DivBackward1>)\n",
      "tensor(0.6193, grad_fn=<DivBackward1>)\n",
      "tensor(0.2311, grad_fn=<DivBackward1>)\n",
      "tensor(0.2640, grad_fn=<DivBackward1>)\n",
      "tensor(0.2142, grad_fn=<DivBackward1>)\n",
      "tensor(0.2841, grad_fn=<DivBackward1>)\n",
      "tensor(0.1593, grad_fn=<DivBackward1>)\n",
      "tensor(0.2254, grad_fn=<DivBackward1>)\n",
      "tensor(0.6561, grad_fn=<DivBackward1>)\n",
      "tensor(0.2622, grad_fn=<DivBackward1>)\n",
      "tensor(0.1185, grad_fn=<DivBackward1>)\n",
      "tensor(0.2844, grad_fn=<DivBackward1>)\n",
      "tensor(0.5643, grad_fn=<DivBackward1>)\n",
      "tensor(0.2103, grad_fn=<DivBackward1>)\n",
      "tensor(0.4274, grad_fn=<DivBackward1>)\n",
      "tensor(0.2056, grad_fn=<DivBackward1>)\n",
      "tensor(0.2434, grad_fn=<DivBackward1>)\n",
      "tensor(0.6198, grad_fn=<DivBackward1>)\n",
      "tensor(0.2164, grad_fn=<DivBackward1>)\n",
      "tensor(0.2381, grad_fn=<DivBackward1>)\n",
      "tensor(0.1356, grad_fn=<DivBackward1>)\n",
      "tensor(0.5719, grad_fn=<DivBackward1>)\n",
      "tensor(0.2244, grad_fn=<DivBackward1>)\n",
      "tensor(0.5206, grad_fn=<DivBackward1>)\n",
      "tensor(0.1645, grad_fn=<DivBackward1>)\n",
      "tensor(0.2007, grad_fn=<DivBackward1>)\n",
      "tensor(0.2181, grad_fn=<DivBackward1>)\n",
      "tensor(0.1961, grad_fn=<DivBackward1>)\n",
      "tensor(0.0578, grad_fn=<DivBackward1>)\n",
      "tensor(0.4731, grad_fn=<DivBackward1>)\n",
      "tensor(0.6357, grad_fn=<DivBackward1>)\n",
      "tensor(0.2877, grad_fn=<DivBackward1>)\n",
      "tensor(0.0809, grad_fn=<DivBackward1>)\n",
      "tensor(0.2827, grad_fn=<DivBackward1>)\n",
      "tensor(0.4117, grad_fn=<DivBackward1>)\n",
      "tensor(0.3236, grad_fn=<DivBackward1>)\n",
      "tensor(0.1850, grad_fn=<DivBackward1>)\n",
      "tensor(0.2763, grad_fn=<DivBackward1>)\n",
      "tensor(0.2469, grad_fn=<DivBackward1>)\n",
      "tensor(0.2396, grad_fn=<DivBackward1>)\n",
      "tensor(0.1422, grad_fn=<DivBackward1>)\n",
      "tensor(0.7164, grad_fn=<DivBackward1>)\n",
      "tensor(1.0320, grad_fn=<DivBackward1>)\n",
      "tensor(0.5625, grad_fn=<DivBackward1>)\n",
      "tensor(0.1992, grad_fn=<DivBackward1>)\n",
      "tensor(0.6246, grad_fn=<DivBackward1>)\n",
      "tensor(0.1819, grad_fn=<DivBackward1>)\n",
      "tensor(0.0629, grad_fn=<DivBackward1>)\n",
      "tensor(0.6312, grad_fn=<DivBackward1>)\n",
      "tensor(0.0983, grad_fn=<DivBackward1>)\n",
      "tensor(0.2293, grad_fn=<DivBackward1>)\n",
      "tensor(0.1656, grad_fn=<DivBackward1>)\n",
      "tensor(0.5986, grad_fn=<DivBackward1>)\n",
      "tensor(0.1043, grad_fn=<DivBackward1>)\n",
      "tensor(0.6196, grad_fn=<DivBackward1>)\n",
      "tensor(0.3866, grad_fn=<DivBackward1>)\n",
      "tensor(0.0644, grad_fn=<DivBackward1>)\n",
      "tensor(0.1173, grad_fn=<DivBackward1>)\n",
      "tensor(0.5094, grad_fn=<DivBackward1>)\n",
      "tensor(0.1139, grad_fn=<DivBackward1>)\n",
      "tensor(0.0945, grad_fn=<DivBackward1>)\n",
      "tensor(0.5984, grad_fn=<DivBackward1>)\n",
      "tensor(0.4385, grad_fn=<DivBackward1>)\n",
      "tensor(0.2719, grad_fn=<DivBackward1>)\n",
      "tensor(0.1024, grad_fn=<DivBackward1>)\n",
      "tensor(0.2423, grad_fn=<DivBackward1>)\n",
      "tensor(0.1784, grad_fn=<DivBackward1>)\n",
      "tensor(0.2414, grad_fn=<DivBackward1>)\n",
      "tensor(0.4278, grad_fn=<DivBackward1>)\n",
      "tensor(0.4446, grad_fn=<DivBackward1>)\n",
      "tensor(1.0857, grad_fn=<DivBackward1>)\n",
      "tensor(0.6411, grad_fn=<DivBackward1>)\n",
      "tensor(0.2297, grad_fn=<DivBackward1>)\n",
      "tensor(0.2313, grad_fn=<DivBackward1>)\n",
      "tensor(0.2036, grad_fn=<DivBackward1>)\n",
      "tensor(0.2733, grad_fn=<DivBackward1>)\n",
      "tensor(0.1580, grad_fn=<DivBackward1>)\n",
      "tensor(0.2191, grad_fn=<DivBackward1>)\n",
      "tensor(0.6548, grad_fn=<DivBackward1>)\n",
      "tensor(0.2745, grad_fn=<DivBackward1>)\n",
      "tensor(0.1103, grad_fn=<DivBackward1>)\n",
      "tensor(0.2735, grad_fn=<DivBackward1>)\n",
      "tensor(0.5614, grad_fn=<DivBackward1>)\n",
      "tensor(0.2145, grad_fn=<DivBackward1>)\n",
      "tensor(0.3929, grad_fn=<DivBackward1>)\n",
      "tensor(0.1830, grad_fn=<DivBackward1>)\n",
      "tensor(0.2196, grad_fn=<DivBackward1>)\n",
      "tensor(0.6066, grad_fn=<DivBackward1>)\n",
      "tensor(0.2031, grad_fn=<DivBackward1>)\n",
      "tensor(0.2355, grad_fn=<DivBackward1>)\n",
      "tensor(0.1258, grad_fn=<DivBackward1>)\n",
      "tensor(0.5428, grad_fn=<DivBackward1>)\n",
      "tensor(0.2101, grad_fn=<DivBackward1>)\n",
      "tensor(0.5098, grad_fn=<DivBackward1>)\n",
      "tensor(0.1550, grad_fn=<DivBackward1>)\n",
      "tensor(0.1938, grad_fn=<DivBackward1>)\n",
      "tensor(0.2105, grad_fn=<DivBackward1>)\n",
      "tensor(0.1989, grad_fn=<DivBackward1>)\n",
      "tensor(0.0554, grad_fn=<DivBackward1>)\n",
      "tensor(0.4726, grad_fn=<DivBackward1>)\n",
      "tensor(0.5933, grad_fn=<DivBackward1>)\n",
      "tensor(0.2765, grad_fn=<DivBackward1>)\n",
      "tensor(0.0743, grad_fn=<DivBackward1>)\n",
      "tensor(0.2691, grad_fn=<DivBackward1>)\n",
      "tensor(0.3806, grad_fn=<DivBackward1>)\n",
      "tensor(0.3184, grad_fn=<DivBackward1>)\n",
      "tensor(0.1746, grad_fn=<DivBackward1>)\n",
      "tensor(0.2669, grad_fn=<DivBackward1>)\n",
      "tensor(0.2452, grad_fn=<DivBackward1>)\n",
      "tensor(0.2271, grad_fn=<DivBackward1>)\n",
      "tensor(0.1287, grad_fn=<DivBackward1>)\n",
      "tensor(0.7133, grad_fn=<DivBackward1>)\n",
      "tensor(1.0346, grad_fn=<DivBackward1>)\n",
      "tensor(0.5548, grad_fn=<DivBackward1>)\n",
      "tensor(0.1952, grad_fn=<DivBackward1>)\n",
      "tensor(0.6012, grad_fn=<DivBackward1>)\n",
      "tensor(0.1691, grad_fn=<DivBackward1>)\n",
      "tensor(0.0563, grad_fn=<DivBackward1>)\n",
      "tensor(0.5868, grad_fn=<DivBackward1>)\n",
      "tensor(0.0923, grad_fn=<DivBackward1>)\n",
      "tensor(0.2187, grad_fn=<DivBackward1>)\n",
      "tensor(0.1590, grad_fn=<DivBackward1>)\n",
      "tensor(0.5921, grad_fn=<DivBackward1>)\n",
      "tensor(0.0969, grad_fn=<DivBackward1>)\n",
      "tensor(0.5893, grad_fn=<DivBackward1>)\n",
      "tensor(0.3663, grad_fn=<DivBackward1>)\n",
      "tensor(0.0628, grad_fn=<DivBackward1>)\n",
      "tensor(0.1137, grad_fn=<DivBackward1>)\n",
      "tensor(0.4980, grad_fn=<DivBackward1>)\n",
      "tensor(0.1290, grad_fn=<DivBackward1>)\n",
      "tensor(0.0916, grad_fn=<DivBackward1>)\n",
      "tensor(0.6036, grad_fn=<DivBackward1>)\n",
      "tensor(0.4368, grad_fn=<DivBackward1>)\n",
      "tensor(0.2655, grad_fn=<DivBackward1>)\n",
      "tensor(0.0996, grad_fn=<DivBackward1>)\n",
      "tensor(0.2386, grad_fn=<DivBackward1>)\n",
      "tensor(0.1799, grad_fn=<DivBackward1>)\n",
      "tensor(0.2353, grad_fn=<DivBackward1>)\n",
      "tensor(0.3895, grad_fn=<DivBackward1>)\n",
      "tensor(0.4459, grad_fn=<DivBackward1>)\n",
      "tensor(1.0676, grad_fn=<DivBackward1>)\n",
      "tensor(0.6607, grad_fn=<DivBackward1>)\n",
      "tensor(0.2138, grad_fn=<DivBackward1>)\n",
      "tensor(0.2258, grad_fn=<DivBackward1>)\n",
      "tensor(0.1957, grad_fn=<DivBackward1>)\n",
      "tensor(0.2547, grad_fn=<DivBackward1>)\n",
      "tensor(0.1519, grad_fn=<DivBackward1>)\n",
      "tensor(0.2000, grad_fn=<DivBackward1>)\n",
      "tensor(0.6470, grad_fn=<DivBackward1>)\n",
      "tensor(0.2812, grad_fn=<DivBackward1>)\n",
      "tensor(0.1022, grad_fn=<DivBackward1>)\n",
      "tensor(0.2690, grad_fn=<DivBackward1>)\n",
      "tensor(0.5359, grad_fn=<DivBackward1>)\n",
      "tensor(0.2011, grad_fn=<DivBackward1>)\n",
      "tensor(0.3818, grad_fn=<DivBackward1>)\n",
      "tensor(0.1627, grad_fn=<DivBackward1>)\n",
      "tensor(0.2144, grad_fn=<DivBackward1>)\n",
      "tensor(0.5864, grad_fn=<DivBackward1>)\n",
      "tensor(0.1923, grad_fn=<DivBackward1>)\n",
      "tensor(0.2129, grad_fn=<DivBackward1>)\n",
      "tensor(0.1226, grad_fn=<DivBackward1>)\n",
      "tensor(0.5196, grad_fn=<DivBackward1>)\n",
      "tensor(0.2026, grad_fn=<DivBackward1>)\n",
      "tensor(0.4950, grad_fn=<DivBackward1>)\n",
      "tensor(0.1607, grad_fn=<DivBackward1>)\n",
      "tensor(0.1965, grad_fn=<DivBackward1>)\n",
      "tensor(0.2139, grad_fn=<DivBackward1>)\n",
      "tensor(0.1891, grad_fn=<DivBackward1>)\n",
      "tensor(0.0522, grad_fn=<DivBackward1>)\n",
      "tensor(0.4306, grad_fn=<DivBackward1>)\n",
      "tensor(0.5411, grad_fn=<DivBackward1>)\n",
      "tensor(0.2620, grad_fn=<DivBackward1>)\n",
      "tensor(0.0726, grad_fn=<DivBackward1>)\n",
      "tensor(0.2640, grad_fn=<DivBackward1>)\n",
      "tensor(0.3435, grad_fn=<DivBackward1>)\n",
      "tensor(0.2993, grad_fn=<DivBackward1>)\n",
      "tensor(0.1599, grad_fn=<DivBackward1>)\n",
      "tensor(0.2626, grad_fn=<DivBackward1>)\n",
      "tensor(0.2236, grad_fn=<DivBackward1>)\n",
      "tensor(0.2174, grad_fn=<DivBackward1>)\n",
      "tensor(0.1207, grad_fn=<DivBackward1>)\n",
      "tensor(0.7123, grad_fn=<DivBackward1>)\n",
      "tensor(1.0441, grad_fn=<DivBackward1>)\n",
      "tensor(0.5200, grad_fn=<DivBackward1>)\n",
      "tensor(0.2013, grad_fn=<DivBackward1>)\n",
      "tensor(0.5862, grad_fn=<DivBackward1>)\n",
      "tensor(0.1741, grad_fn=<DivBackward1>)\n",
      "tensor(0.0512, grad_fn=<DivBackward1>)\n",
      "tensor(0.5621, grad_fn=<DivBackward1>)\n",
      "tensor(0.0838, grad_fn=<DivBackward1>)\n",
      "tensor(0.2114, grad_fn=<DivBackward1>)\n",
      "tensor(0.1540, grad_fn=<DivBackward1>)\n",
      "tensor(0.5711, grad_fn=<DivBackward1>)\n",
      "tensor(0.0888, grad_fn=<DivBackward1>)\n",
      "tensor(0.5487, grad_fn=<DivBackward1>)\n",
      "tensor(0.3269, grad_fn=<DivBackward1>)\n",
      "tensor(0.0608, grad_fn=<DivBackward1>)\n",
      "tensor(0.1063, grad_fn=<DivBackward1>)\n",
      "tensor(0.4759, grad_fn=<DivBackward1>)\n",
      "tensor(0.1229, grad_fn=<DivBackward1>)\n",
      "tensor(0.0893, grad_fn=<DivBackward1>)\n",
      "tensor(0.6039, grad_fn=<DivBackward1>)\n",
      "tensor(0.4562, grad_fn=<DivBackward1>)\n",
      "tensor(0.2682, grad_fn=<DivBackward1>)\n",
      "tensor(0.0904, grad_fn=<DivBackward1>)\n",
      "tensor(0.2316, grad_fn=<DivBackward1>)\n",
      "tensor(0.1677, grad_fn=<DivBackward1>)\n",
      "tensor(0.2243, grad_fn=<DivBackward1>)\n",
      "tensor(0.3745, grad_fn=<DivBackward1>)\n",
      "tensor(0.4382, grad_fn=<DivBackward1>)\n",
      "tensor(1.0565, grad_fn=<DivBackward1>)\n",
      "tensor(0.6657, grad_fn=<DivBackward1>)\n",
      "tensor(0.2070, grad_fn=<DivBackward1>)\n",
      "tensor(0.2213, grad_fn=<DivBackward1>)\n",
      "tensor(0.1902, grad_fn=<DivBackward1>)\n",
      "tensor(0.2287, grad_fn=<DivBackward1>)\n",
      "tensor(0.1428, grad_fn=<DivBackward1>)\n",
      "tensor(0.1904, grad_fn=<DivBackward1>)\n",
      "tensor(0.6648, grad_fn=<DivBackward1>)\n",
      "tensor(0.2758, grad_fn=<DivBackward1>)\n",
      "tensor(0.0989, grad_fn=<DivBackward1>)\n",
      "tensor(0.2557, grad_fn=<DivBackward1>)\n",
      "tensor(0.5380, grad_fn=<DivBackward1>)\n",
      "tensor(0.1804, grad_fn=<DivBackward1>)\n",
      "tensor(0.3679, grad_fn=<DivBackward1>)\n",
      "tensor(0.1413, grad_fn=<DivBackward1>)\n",
      "tensor(0.1955, grad_fn=<DivBackward1>)\n",
      "tensor(0.5590, grad_fn=<DivBackward1>)\n",
      "tensor(0.2028, grad_fn=<DivBackward1>)\n",
      "tensor(0.2010, grad_fn=<DivBackward1>)\n",
      "tensor(0.1200, grad_fn=<DivBackward1>)\n",
      "tensor(0.4755, grad_fn=<DivBackward1>)\n",
      "tensor(0.1921, grad_fn=<DivBackward1>)\n",
      "tensor(0.4798, grad_fn=<DivBackward1>)\n",
      "tensor(0.1444, grad_fn=<DivBackward1>)\n",
      "tensor(0.1825, grad_fn=<DivBackward1>)\n",
      "tensor(0.1956, grad_fn=<DivBackward1>)\n",
      "tensor(0.1833, grad_fn=<DivBackward1>)\n",
      "tensor(0.0466, grad_fn=<DivBackward1>)\n",
      "tensor(0.4204, grad_fn=<DivBackward1>)\n",
      "tensor(0.5167, grad_fn=<DivBackward1>)\n",
      "tensor(0.2273, grad_fn=<DivBackward1>)\n",
      "tensor(0.0696, grad_fn=<DivBackward1>)\n",
      "tensor(0.2403, grad_fn=<DivBackward1>)\n",
      "tensor(0.3229, grad_fn=<DivBackward1>)\n",
      "tensor(0.2838, grad_fn=<DivBackward1>)\n",
      "tensor(0.1492, grad_fn=<DivBackward1>)\n",
      "tensor(0.2565, grad_fn=<DivBackward1>)\n",
      "tensor(0.2131, grad_fn=<DivBackward1>)\n",
      "tensor(0.2009, grad_fn=<DivBackward1>)\n",
      "tensor(0.1123, grad_fn=<DivBackward1>)\n",
      "tensor(0.6898, grad_fn=<DivBackward1>)\n",
      "tensor(1.0647, grad_fn=<DivBackward1>)\n",
      "tensor(0.4822, grad_fn=<DivBackward1>)\n",
      "tensor(0.2008, grad_fn=<DivBackward1>)\n",
      "tensor(0.5720, grad_fn=<DivBackward1>)\n",
      "tensor(0.1635, grad_fn=<DivBackward1>)\n",
      "tensor(0.0471, grad_fn=<DivBackward1>)\n",
      "tensor(0.4884, grad_fn=<DivBackward1>)\n",
      "tensor(0.0788, grad_fn=<DivBackward1>)\n",
      "tensor(0.2014, grad_fn=<DivBackward1>)\n",
      "tensor(0.1482, grad_fn=<DivBackward1>)\n",
      "tensor(0.5228, grad_fn=<DivBackward1>)\n",
      "tensor(0.0806, grad_fn=<DivBackward1>)\n",
      "tensor(0.5442, grad_fn=<DivBackward1>)\n",
      "tensor(0.3105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0540, grad_fn=<DivBackward1>)\n",
      "tensor(0.0960, grad_fn=<DivBackward1>)\n",
      "tensor(0.4621, grad_fn=<DivBackward1>)\n",
      "tensor(0.1112, grad_fn=<DivBackward1>)\n",
      "tensor(0.0843, grad_fn=<DivBackward1>)\n",
      "tensor(0.6202, grad_fn=<DivBackward1>)\n",
      "tensor(0.4569, grad_fn=<DivBackward1>)\n",
      "tensor(0.2728, grad_fn=<DivBackward1>)\n",
      "tensor(0.0800, grad_fn=<DivBackward1>)\n",
      "tensor(0.2192, grad_fn=<DivBackward1>)\n",
      "tensor(0.1634, grad_fn=<DivBackward1>)\n",
      "tensor(0.2145, grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, grad_fn=<DivBackward1>)\n",
      "tensor(0.4244, grad_fn=<DivBackward1>)\n",
      "tensor(1.0579, grad_fn=<DivBackward1>)\n",
      "tensor(0.6790, grad_fn=<DivBackward1>)\n",
      "tensor(0.2011, grad_fn=<DivBackward1>)\n",
      "tensor(0.2073, grad_fn=<DivBackward1>)\n",
      "tensor(0.1823, grad_fn=<DivBackward1>)\n",
      "tensor(0.2180, grad_fn=<DivBackward1>)\n",
      "tensor(0.1376, grad_fn=<DivBackward1>)\n",
      "tensor(0.1776, grad_fn=<DivBackward1>)\n",
      "tensor(0.6625, grad_fn=<DivBackward1>)\n",
      "tensor(0.2756, grad_fn=<DivBackward1>)\n",
      "tensor(0.0924, grad_fn=<DivBackward1>)\n",
      "tensor(0.2539, grad_fn=<DivBackward1>)\n",
      "tensor(0.5084, grad_fn=<DivBackward1>)\n",
      "tensor(0.1735, grad_fn=<DivBackward1>)\n",
      "tensor(0.3687, grad_fn=<DivBackward1>)\n",
      "tensor(0.1249, grad_fn=<DivBackward1>)\n",
      "tensor(0.1721, grad_fn=<DivBackward1>)\n",
      "tensor(0.5301, grad_fn=<DivBackward1>)\n",
      "tensor(0.1869, grad_fn=<DivBackward1>)\n",
      "tensor(0.1921, grad_fn=<DivBackward1>)\n",
      "tensor(0.1106, grad_fn=<DivBackward1>)\n",
      "tensor(0.4474, grad_fn=<DivBackward1>)\n",
      "tensor(0.1753, grad_fn=<DivBackward1>)\n",
      "tensor(0.4575, grad_fn=<DivBackward1>)\n",
      "tensor(0.1454, grad_fn=<DivBackward1>)\n",
      "tensor(0.1808, grad_fn=<DivBackward1>)\n",
      "tensor(0.2035, grad_fn=<DivBackward1>)\n",
      "tensor(0.1800, grad_fn=<DivBackward1>)\n",
      "tensor(0.0443, grad_fn=<DivBackward1>)\n",
      "tensor(0.3864, grad_fn=<DivBackward1>)\n",
      "tensor(0.5038, grad_fn=<DivBackward1>)\n",
      "tensor(0.2275, grad_fn=<DivBackward1>)\n",
      "tensor(0.0640, grad_fn=<DivBackward1>)\n",
      "tensor(0.2321, grad_fn=<DivBackward1>)\n",
      "tensor(0.3037, grad_fn=<DivBackward1>)\n",
      "tensor(0.2576, grad_fn=<DivBackward1>)\n",
      "tensor(0.1402, grad_fn=<DivBackward1>)\n",
      "tensor(0.2424, grad_fn=<DivBackward1>)\n",
      "tensor(0.1951, grad_fn=<DivBackward1>)\n",
      "tensor(0.1824, grad_fn=<DivBackward1>)\n",
      "tensor(0.1020, grad_fn=<DivBackward1>)\n",
      "tensor(0.6670, grad_fn=<DivBackward1>)\n",
      "tensor(1.0742, grad_fn=<DivBackward1>)\n",
      "tensor(0.4455, grad_fn=<DivBackward1>)\n",
      "tensor(0.2153, grad_fn=<DivBackward1>)\n",
      "tensor(0.5402, grad_fn=<DivBackward1>)\n",
      "tensor(0.1686, grad_fn=<DivBackward1>)\n",
      "tensor(0.0478, grad_fn=<DivBackward1>)\n",
      "tensor(0.4200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0753, grad_fn=<DivBackward1>)\n",
      "tensor(0.1937, grad_fn=<DivBackward1>)\n",
      "tensor(0.1392, grad_fn=<DivBackward1>)\n",
      "tensor(0.4724, grad_fn=<DivBackward1>)\n",
      "tensor(0.0762, grad_fn=<DivBackward1>)\n",
      "tensor(0.5358, grad_fn=<DivBackward1>)\n",
      "tensor(0.3060, grad_fn=<DivBackward1>)\n",
      "tensor(0.0527, grad_fn=<DivBackward1>)\n",
      "tensor(0.0931, grad_fn=<DivBackward1>)\n",
      "tensor(0.4289, grad_fn=<DivBackward1>)\n",
      "tensor(0.1144, grad_fn=<DivBackward1>)\n",
      "tensor(0.0826, grad_fn=<DivBackward1>)\n",
      "tensor(0.6246, grad_fn=<DivBackward1>)\n",
      "tensor(0.4774, grad_fn=<DivBackward1>)\n",
      "tensor(0.2616, grad_fn=<DivBackward1>)\n",
      "tensor(0.0754, grad_fn=<DivBackward1>)\n",
      "tensor(0.2227, grad_fn=<DivBackward1>)\n",
      "tensor(0.1628, grad_fn=<DivBackward1>)\n",
      "tensor(0.1992, grad_fn=<DivBackward1>)\n",
      "tensor(0.3251, grad_fn=<DivBackward1>)\n",
      "tensor(0.4195, grad_fn=<DivBackward1>)\n",
      "tensor(1.0235, grad_fn=<DivBackward1>)\n",
      "tensor(0.6903, grad_fn=<DivBackward1>)\n",
      "tensor(0.2158, grad_fn=<DivBackward1>)\n",
      "tensor(0.1940, grad_fn=<DivBackward1>)\n",
      "tensor(0.1834, grad_fn=<DivBackward1>)\n",
      "tensor(0.2013, grad_fn=<DivBackward1>)\n",
      "tensor(0.1380, grad_fn=<DivBackward1>)\n",
      "tensor(0.1752, grad_fn=<DivBackward1>)\n",
      "tensor(0.6613, grad_fn=<DivBackward1>)\n",
      "tensor(0.2823, grad_fn=<DivBackward1>)\n",
      "tensor(0.0809, grad_fn=<DivBackward1>)\n",
      "tensor(0.2522, grad_fn=<DivBackward1>)\n",
      "tensor(0.4812, grad_fn=<DivBackward1>)\n",
      "tensor(0.1651, grad_fn=<DivBackward1>)\n",
      "tensor(0.3484, grad_fn=<DivBackward1>)\n",
      "tensor(0.1059, grad_fn=<DivBackward1>)\n",
      "tensor(0.1691, grad_fn=<DivBackward1>)\n",
      "tensor(0.5093, grad_fn=<DivBackward1>)\n",
      "tensor(0.2001, grad_fn=<DivBackward1>)\n",
      "tensor(0.1783, grad_fn=<DivBackward1>)\n",
      "tensor(0.1106, grad_fn=<DivBackward1>)\n",
      "tensor(0.4108, grad_fn=<DivBackward1>)\n",
      "tensor(0.1595, grad_fn=<DivBackward1>)\n",
      "tensor(0.4406, grad_fn=<DivBackward1>)\n",
      "tensor(0.1292, grad_fn=<DivBackward1>)\n",
      "tensor(0.1806, grad_fn=<DivBackward1>)\n",
      "tensor(0.1906, grad_fn=<DivBackward1>)\n",
      "tensor(0.1673, grad_fn=<DivBackward1>)\n",
      "tensor(0.0396, grad_fn=<DivBackward1>)\n",
      "tensor(0.3609, grad_fn=<DivBackward1>)\n",
      "tensor(0.4700, grad_fn=<DivBackward1>)\n",
      "tensor(0.1965, grad_fn=<DivBackward1>)\n",
      "tensor(0.0616, grad_fn=<DivBackward1>)\n",
      "tensor(0.2165, grad_fn=<DivBackward1>)\n",
      "tensor(0.2859, grad_fn=<DivBackward1>)\n",
      "tensor(0.2674, grad_fn=<DivBackward1>)\n",
      "tensor(0.1301, grad_fn=<DivBackward1>)\n",
      "tensor(0.2418, grad_fn=<DivBackward1>)\n",
      "tensor(0.1946, grad_fn=<DivBackward1>)\n",
      "tensor(0.1642, grad_fn=<DivBackward1>)\n",
      "tensor(0.0949, grad_fn=<DivBackward1>)\n",
      "tensor(0.6527, grad_fn=<DivBackward1>)\n",
      "tensor(1.0694, grad_fn=<DivBackward1>)\n",
      "tensor(0.4264, grad_fn=<DivBackward1>)\n",
      "tensor(0.2019, grad_fn=<DivBackward1>)\n",
      "tensor(0.5201, grad_fn=<DivBackward1>)\n",
      "tensor(0.1507, grad_fn=<DivBackward1>)\n",
      "tensor(0.0426, grad_fn=<DivBackward1>)\n",
      "tensor(0.3750, grad_fn=<DivBackward1>)\n",
      "tensor(0.0707, grad_fn=<DivBackward1>)\n",
      "tensor(0.1845, grad_fn=<DivBackward1>)\n",
      "tensor(0.1393, grad_fn=<DivBackward1>)\n",
      "tensor(0.4949, grad_fn=<DivBackward1>)\n",
      "tensor(0.0700, grad_fn=<DivBackward1>)\n",
      "tensor(0.5140, grad_fn=<DivBackward1>)\n",
      "tensor(0.2708, grad_fn=<DivBackward1>)\n",
      "tensor(0.0438, grad_fn=<DivBackward1>)\n",
      "tensor(0.0819, grad_fn=<DivBackward1>)\n",
      "tensor(0.4007, grad_fn=<DivBackward1>)\n",
      "tensor(0.1082, grad_fn=<DivBackward1>)\n",
      "tensor(0.0829, grad_fn=<DivBackward1>)\n",
      "tensor(0.6195, grad_fn=<DivBackward1>)\n",
      "tensor(0.4775, grad_fn=<DivBackward1>)\n",
      "tensor(0.2548, grad_fn=<DivBackward1>)\n",
      "tensor(0.0713, grad_fn=<DivBackward1>)\n",
      "tensor(0.2141, grad_fn=<DivBackward1>)\n",
      "tensor(0.1631, grad_fn=<DivBackward1>)\n",
      "tensor(0.1881, grad_fn=<DivBackward1>)\n",
      "tensor(0.2947, grad_fn=<DivBackward1>)\n",
      "tensor(0.4276, grad_fn=<DivBackward1>)\n",
      "tensor(1.0417, grad_fn=<DivBackward1>)\n",
      "tensor(0.6713, grad_fn=<DivBackward1>)\n",
      "tensor(0.1909, grad_fn=<DivBackward1>)\n",
      "tensor(0.1770, grad_fn=<DivBackward1>)\n",
      "tensor(0.1674, grad_fn=<DivBackward1>)\n",
      "tensor(0.1804, grad_fn=<DivBackward1>)\n",
      "tensor(0.1331, grad_fn=<DivBackward1>)\n",
      "tensor(0.1659, grad_fn=<DivBackward1>)\n",
      "tensor(0.6653, grad_fn=<DivBackward1>)\n",
      "tensor(0.2734, grad_fn=<DivBackward1>)\n",
      "tensor(0.0808, grad_fn=<DivBackward1>)\n",
      "tensor(0.2361, grad_fn=<DivBackward1>)\n",
      "tensor(0.4725, grad_fn=<DivBackward1>)\n",
      "tensor(0.1613, grad_fn=<DivBackward1>)\n",
      "tensor(0.3508, grad_fn=<DivBackward1>)\n",
      "tensor(0.0864, grad_fn=<DivBackward1>)\n",
      "tensor(0.1383, grad_fn=<DivBackward1>)\n",
      "tensor(0.5249, grad_fn=<DivBackward1>)\n",
      "tensor(0.1742, grad_fn=<DivBackward1>)\n",
      "tensor(0.1654, grad_fn=<DivBackward1>)\n",
      "tensor(0.1008, grad_fn=<DivBackward1>)\n",
      "tensor(0.3751, grad_fn=<DivBackward1>)\n",
      "tensor(0.1377, grad_fn=<DivBackward1>)\n",
      "tensor(0.4250, grad_fn=<DivBackward1>)\n",
      "tensor(0.1259, grad_fn=<DivBackward1>)\n",
      "tensor(0.1841, grad_fn=<DivBackward1>)\n",
      "tensor(0.1831, grad_fn=<DivBackward1>)\n",
      "tensor(0.1602, grad_fn=<DivBackward1>)\n",
      "tensor(0.0373, grad_fn=<DivBackward1>)\n",
      "tensor(0.3396, grad_fn=<DivBackward1>)\n",
      "tensor(0.4369, grad_fn=<DivBackward1>)\n",
      "tensor(0.1763, grad_fn=<DivBackward1>)\n",
      "tensor(0.0552, grad_fn=<DivBackward1>)\n",
      "tensor(0.1887, grad_fn=<DivBackward1>)\n",
      "tensor(0.2463, grad_fn=<DivBackward1>)\n",
      "tensor(0.2454, grad_fn=<DivBackward1>)\n",
      "tensor(0.1195, grad_fn=<DivBackward1>)\n",
      "tensor(0.2281, grad_fn=<DivBackward1>)\n",
      "tensor(0.1811, grad_fn=<DivBackward1>)\n",
      "tensor(0.1495, grad_fn=<DivBackward1>)\n",
      "tensor(0.0837, grad_fn=<DivBackward1>)\n",
      "tensor(0.6419, grad_fn=<DivBackward1>)\n",
      "tensor(1.0692, grad_fn=<DivBackward1>)\n",
      "tensor(0.3634, grad_fn=<DivBackward1>)\n",
      "tensor(0.2280, grad_fn=<DivBackward1>)\n",
      "tensor(0.5118, grad_fn=<DivBackward1>)\n",
      "tensor(0.1637, grad_fn=<DivBackward1>)\n",
      "tensor(0.0409, grad_fn=<DivBackward1>)\n",
      "tensor(0.3063, grad_fn=<DivBackward1>)\n",
      "tensor(0.0695, grad_fn=<DivBackward1>)\n",
      "tensor(0.1718, grad_fn=<DivBackward1>)\n",
      "tensor(0.1273, grad_fn=<DivBackward1>)\n",
      "tensor(0.4307, grad_fn=<DivBackward1>)\n",
      "tensor(0.0620, grad_fn=<DivBackward1>)\n",
      "tensor(0.4925, grad_fn=<DivBackward1>)\n",
      "tensor(0.2352, grad_fn=<DivBackward1>)\n",
      "tensor(0.0438, grad_fn=<DivBackward1>)\n",
      "tensor(0.0761, grad_fn=<DivBackward1>)\n",
      "tensor(0.3868, grad_fn=<DivBackward1>)\n",
      "tensor(0.1039, grad_fn=<DivBackward1>)\n",
      "tensor(0.0827, grad_fn=<DivBackward1>)\n",
      "tensor(0.6361, grad_fn=<DivBackward1>)\n",
      "tensor(0.5065, grad_fn=<DivBackward1>)\n",
      "tensor(0.2621, grad_fn=<DivBackward1>)\n",
      "tensor(0.0634, grad_fn=<DivBackward1>)\n",
      "tensor(0.2135, grad_fn=<DivBackward1>)\n",
      "tensor(0.1597, grad_fn=<DivBackward1>)\n",
      "tensor(0.1663, grad_fn=<DivBackward1>)\n",
      "tensor(0.2591, grad_fn=<DivBackward1>)\n",
      "tensor(0.4134, grad_fn=<DivBackward1>)\n",
      "tensor(1.0154, grad_fn=<DivBackward1>)\n",
      "tensor(0.6730, grad_fn=<DivBackward1>)\n",
      "tensor(0.2004, grad_fn=<DivBackward1>)\n",
      "tensor(0.1559, grad_fn=<DivBackward1>)\n",
      "tensor(0.1578, grad_fn=<DivBackward1>)\n",
      "tensor(0.1605, grad_fn=<DivBackward1>)\n",
      "tensor(0.1312, grad_fn=<DivBackward1>)\n",
      "tensor(0.1616, grad_fn=<DivBackward1>)\n",
      "tensor(0.6740, grad_fn=<DivBackward1>)\n",
      "tensor(0.2618, grad_fn=<DivBackward1>)\n",
      "tensor(0.0736, grad_fn=<DivBackward1>)\n",
      "tensor(0.2418, grad_fn=<DivBackward1>)\n",
      "tensor(0.4506, grad_fn=<DivBackward1>)\n",
      "tensor(0.1671, grad_fn=<DivBackward1>)\n",
      "tensor(0.3069, grad_fn=<DivBackward1>)\n",
      "tensor(0.0783, grad_fn=<DivBackward1>)\n",
      "tensor(0.1345, grad_fn=<DivBackward1>)\n",
      "tensor(0.4804, grad_fn=<DivBackward1>)\n",
      "tensor(0.1803, grad_fn=<DivBackward1>)\n",
      "tensor(0.1487, grad_fn=<DivBackward1>)\n",
      "tensor(0.0992, grad_fn=<DivBackward1>)\n",
      "tensor(0.3255, grad_fn=<DivBackward1>)\n",
      "tensor(0.1403, grad_fn=<DivBackward1>)\n",
      "tensor(0.4305, grad_fn=<DivBackward1>)\n",
      "tensor(0.1163, grad_fn=<DivBackward1>)\n",
      "tensor(0.1650, grad_fn=<DivBackward1>)\n",
      "tensor(0.1783, grad_fn=<DivBackward1>)\n",
      "tensor(0.1678, grad_fn=<DivBackward1>)\n",
      "tensor(0.0315, grad_fn=<DivBackward1>)\n",
      "tensor(0.3274, grad_fn=<DivBackward1>)\n",
      "tensor(0.4295, grad_fn=<DivBackward1>)\n",
      "tensor(0.1713, grad_fn=<DivBackward1>)\n",
      "tensor(0.0504, grad_fn=<DivBackward1>)\n",
      "tensor(0.1842, grad_fn=<DivBackward1>)\n",
      "tensor(0.2194, grad_fn=<DivBackward1>)\n",
      "tensor(0.2544, grad_fn=<DivBackward1>)\n",
      "tensor(0.1079, grad_fn=<DivBackward1>)\n",
      "tensor(0.2187, grad_fn=<DivBackward1>)\n",
      "tensor(0.1542, grad_fn=<DivBackward1>)\n",
      "tensor(0.1371, grad_fn=<DivBackward1>)\n",
      "tensor(0.0787, grad_fn=<DivBackward1>)\n",
      "tensor(0.6296, grad_fn=<DivBackward1>)\n",
      "tensor(1.0739, grad_fn=<DivBackward1>)\n",
      "tensor(0.3446, grad_fn=<DivBackward1>)\n",
      "tensor(0.2252, grad_fn=<DivBackward1>)\n",
      "tensor(0.4927, grad_fn=<DivBackward1>)\n",
      "tensor(0.1448, grad_fn=<DivBackward1>)\n",
      "tensor(0.0380, grad_fn=<DivBackward1>)\n",
      "tensor(0.2709, grad_fn=<DivBackward1>)\n",
      "tensor(0.0685, grad_fn=<DivBackward1>)\n",
      "tensor(0.1714, grad_fn=<DivBackward1>)\n",
      "tensor(0.1282, grad_fn=<DivBackward1>)\n",
      "tensor(0.4094, grad_fn=<DivBackward1>)\n",
      "tensor(0.0543, grad_fn=<DivBackward1>)\n",
      "tensor(0.4435, grad_fn=<DivBackward1>)\n",
      "tensor(0.1976, grad_fn=<DivBackward1>)\n",
      "tensor(0.0400, grad_fn=<DivBackward1>)\n",
      "tensor(0.0630, grad_fn=<DivBackward1>)\n",
      "tensor(0.3727, grad_fn=<DivBackward1>)\n",
      "tensor(0.1125, grad_fn=<DivBackward1>)\n",
      "tensor(0.0681, grad_fn=<DivBackward1>)\n",
      "tensor(0.6354, grad_fn=<DivBackward1>)\n",
      "tensor(0.4966, grad_fn=<DivBackward1>)\n",
      "tensor(0.2760, grad_fn=<DivBackward1>)\n",
      "tensor(0.0569, grad_fn=<DivBackward1>)\n",
      "tensor(0.2051, grad_fn=<DivBackward1>)\n",
      "tensor(0.1518, grad_fn=<DivBackward1>)\n",
      "tensor(0.1540, grad_fn=<DivBackward1>)\n",
      "tensor(0.2293, grad_fn=<DivBackward1>)\n",
      "tensor(0.4230, grad_fn=<DivBackward1>)\n",
      "tensor(1.0429, grad_fn=<DivBackward1>)\n",
      "tensor(0.6678, grad_fn=<DivBackward1>)\n",
      "tensor(0.1707, grad_fn=<DivBackward1>)\n",
      "tensor(0.1419, grad_fn=<DivBackward1>)\n",
      "tensor(0.1515, grad_fn=<DivBackward1>)\n",
      "tensor(0.1432, grad_fn=<DivBackward1>)\n",
      "tensor(0.1152, grad_fn=<DivBackward1>)\n",
      "tensor(0.1466, grad_fn=<DivBackward1>)\n",
      "tensor(0.6809, grad_fn=<DivBackward1>)\n",
      "tensor(0.2700, grad_fn=<DivBackward1>)\n",
      "tensor(0.0664, grad_fn=<DivBackward1>)\n",
      "tensor(0.2328, grad_fn=<DivBackward1>)\n",
      "tensor(0.4480, grad_fn=<DivBackward1>)\n",
      "tensor(0.1461, grad_fn=<DivBackward1>)\n",
      "tensor(0.2992, grad_fn=<DivBackward1>)\n",
      "tensor(0.0683, grad_fn=<DivBackward1>)\n",
      "tensor(0.1289, grad_fn=<DivBackward1>)\n",
      "tensor(0.4715, grad_fn=<DivBackward1>)\n",
      "tensor(0.1731, grad_fn=<DivBackward1>)\n",
      "tensor(0.1182, grad_fn=<DivBackward1>)\n",
      "tensor(0.0891, grad_fn=<DivBackward1>)\n",
      "tensor(0.2996, grad_fn=<DivBackward1>)\n",
      "tensor(0.1386, grad_fn=<DivBackward1>)\n",
      "tensor(0.3957, grad_fn=<DivBackward1>)\n",
      "tensor(0.1074, grad_fn=<DivBackward1>)\n",
      "tensor(0.1776, grad_fn=<DivBackward1>)\n",
      "tensor(0.1568, grad_fn=<DivBackward1>)\n",
      "tensor(0.1514, grad_fn=<DivBackward1>)\n",
      "tensor(0.0295, grad_fn=<DivBackward1>)\n",
      "tensor(0.2945, grad_fn=<DivBackward1>)\n",
      "tensor(0.3861, grad_fn=<DivBackward1>)\n",
      "tensor(0.1577, grad_fn=<DivBackward1>)\n",
      "tensor(0.0482, grad_fn=<DivBackward1>)\n",
      "tensor(0.1655, grad_fn=<DivBackward1>)\n",
      "tensor(0.2092, grad_fn=<DivBackward1>)\n",
      "tensor(0.2409, grad_fn=<DivBackward1>)\n",
      "tensor(0.0917, grad_fn=<DivBackward1>)\n",
      "tensor(0.2136, grad_fn=<DivBackward1>)\n",
      "tensor(0.1432, grad_fn=<DivBackward1>)\n",
      "tensor(0.1239, grad_fn=<DivBackward1>)\n",
      "tensor(0.0731, grad_fn=<DivBackward1>)\n",
      "tensor(0.6098, grad_fn=<DivBackward1>)\n",
      "tensor(1.0908, grad_fn=<DivBackward1>)\n",
      "tensor(0.2926, grad_fn=<DivBackward1>)\n",
      "tensor(0.2323, grad_fn=<DivBackward1>)\n",
      "tensor(0.4616, grad_fn=<DivBackward1>)\n",
      "tensor(0.1449, grad_fn=<DivBackward1>)\n",
      "tensor(0.0348, grad_fn=<DivBackward1>)\n",
      "tensor(0.2350, grad_fn=<DivBackward1>)\n",
      "tensor(0.0706, grad_fn=<DivBackward1>)\n",
      "tensor(0.1538, grad_fn=<DivBackward1>)\n",
      "tensor(0.1193, grad_fn=<DivBackward1>)\n",
      "tensor(0.4149, grad_fn=<DivBackward1>)\n",
      "tensor(0.0505, grad_fn=<DivBackward1>)\n",
      "tensor(0.4177, grad_fn=<DivBackward1>)\n",
      "tensor(0.1943, grad_fn=<DivBackward1>)\n",
      "tensor(0.0371, grad_fn=<DivBackward1>)\n",
      "tensor(0.0579, grad_fn=<DivBackward1>)\n",
      "tensor(0.3631, grad_fn=<DivBackward1>)\n",
      "tensor(0.1145, grad_fn=<DivBackward1>)\n",
      "tensor(0.0701, grad_fn=<DivBackward1>)\n",
      "tensor(0.6600, grad_fn=<DivBackward1>)\n",
      "tensor(0.4945, grad_fn=<DivBackward1>)\n",
      "tensor(0.2820, grad_fn=<DivBackward1>)\n",
      "tensor(0.0508, grad_fn=<DivBackward1>)\n",
      "tensor(0.2028, grad_fn=<DivBackward1>)\n",
      "tensor(0.1426, grad_fn=<DivBackward1>)\n",
      "tensor(0.1356, grad_fn=<DivBackward1>)\n",
      "tensor(0.2272, grad_fn=<DivBackward1>)\n",
      "tensor(0.4016, grad_fn=<DivBackward1>)\n",
      "tensor(1.0142, grad_fn=<DivBackward1>)\n",
      "tensor(0.6829, grad_fn=<DivBackward1>)\n",
      "tensor(0.1750, grad_fn=<DivBackward1>)\n",
      "tensor(0.1264, grad_fn=<DivBackward1>)\n",
      "tensor(0.1420, grad_fn=<DivBackward1>)\n",
      "tensor(0.1268, grad_fn=<DivBackward1>)\n",
      "tensor(0.1117, grad_fn=<DivBackward1>)\n",
      "tensor(0.1470, grad_fn=<DivBackward1>)\n",
      "tensor(0.7001, grad_fn=<DivBackward1>)\n",
      "tensor(0.2548, grad_fn=<DivBackward1>)\n",
      "tensor(0.0597, grad_fn=<DivBackward1>)\n",
      "tensor(0.2454, grad_fn=<DivBackward1>)\n",
      "tensor(0.4085, grad_fn=<DivBackward1>)\n",
      "tensor(0.1561, grad_fn=<DivBackward1>)\n",
      "tensor(0.3067, grad_fn=<DivBackward1>)\n",
      "tensor(0.0612, grad_fn=<DivBackward1>)\n",
      "tensor(0.1069, grad_fn=<DivBackward1>)\n",
      "tensor(0.4549, grad_fn=<DivBackward1>)\n",
      "tensor(0.1606, grad_fn=<DivBackward1>)\n",
      "tensor(0.1121, grad_fn=<DivBackward1>)\n",
      "tensor(0.0771, grad_fn=<DivBackward1>)\n",
      "tensor(0.2672, grad_fn=<DivBackward1>)\n",
      "tensor(0.1101, grad_fn=<DivBackward1>)\n",
      "tensor(0.3575, grad_fn=<DivBackward1>)\n",
      "tensor(0.0890, grad_fn=<DivBackward1>)\n",
      "tensor(0.1700, grad_fn=<DivBackward1>)\n",
      "tensor(0.1550, grad_fn=<DivBackward1>)\n",
      "tensor(0.1495, grad_fn=<DivBackward1>)\n",
      "tensor(0.0278, grad_fn=<DivBackward1>)\n",
      "tensor(0.2650, grad_fn=<DivBackward1>)\n",
      "tensor(0.3415, grad_fn=<DivBackward1>)\n",
      "tensor(0.1286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0477, grad_fn=<DivBackward1>)\n",
      "tensor(0.1529, grad_fn=<DivBackward1>)\n",
      "tensor(0.1946, grad_fn=<DivBackward1>)\n",
      "tensor(0.2224, grad_fn=<DivBackward1>)\n",
      "tensor(0.0954, grad_fn=<DivBackward1>)\n",
      "tensor(0.2267, grad_fn=<DivBackward1>)\n",
      "tensor(0.1266, grad_fn=<DivBackward1>)\n",
      "tensor(0.1086, grad_fn=<DivBackward1>)\n",
      "tensor(0.0706, grad_fn=<DivBackward1>)\n",
      "tensor(0.5928, grad_fn=<DivBackward1>)\n",
      "tensor(1.0856, grad_fn=<DivBackward1>)\n",
      "tensor(0.2659, grad_fn=<DivBackward1>)\n",
      "tensor(0.2154, grad_fn=<DivBackward1>)\n",
      "tensor(0.4189, grad_fn=<DivBackward1>)\n",
      "tensor(0.1354, grad_fn=<DivBackward1>)\n",
      "tensor(0.0345, grad_fn=<DivBackward1>)\n",
      "tensor(0.2530, grad_fn=<DivBackward1>)\n",
      "tensor(0.0592, grad_fn=<DivBackward1>)\n",
      "tensor(0.1565, grad_fn=<DivBackward1>)\n",
      "tensor(0.1167, grad_fn=<DivBackward1>)\n",
      "tensor(0.4695, grad_fn=<DivBackward1>)\n",
      "tensor(0.0440, grad_fn=<DivBackward1>)\n",
      "tensor(0.3742, grad_fn=<DivBackward1>)\n",
      "tensor(0.1542, grad_fn=<DivBackward1>)\n",
      "tensor(0.0334, grad_fn=<DivBackward1>)\n",
      "tensor(0.0512, grad_fn=<DivBackward1>)\n",
      "tensor(0.3452, grad_fn=<DivBackward1>)\n",
      "tensor(0.1266, grad_fn=<DivBackward1>)\n",
      "tensor(0.0633, grad_fn=<DivBackward1>)\n",
      "tensor(0.6610, grad_fn=<DivBackward1>)\n",
      "tensor(0.4830, grad_fn=<DivBackward1>)\n",
      "tensor(0.2899, grad_fn=<DivBackward1>)\n",
      "tensor(0.0444, grad_fn=<DivBackward1>)\n",
      "tensor(0.1930, grad_fn=<DivBackward1>)\n",
      "tensor(0.1327, grad_fn=<DivBackward1>)\n",
      "tensor(0.1186, grad_fn=<DivBackward1>)\n",
      "tensor(0.1949, grad_fn=<DivBackward1>)\n",
      "tensor(0.3804, grad_fn=<DivBackward1>)\n",
      "tensor(1.0059, grad_fn=<DivBackward1>)\n",
      "tensor(0.6932, grad_fn=<DivBackward1>)\n",
      "tensor(0.1748, grad_fn=<DivBackward1>)\n",
      "tensor(0.1260, grad_fn=<DivBackward1>)\n",
      "tensor(0.1312, grad_fn=<DivBackward1>)\n",
      "tensor(0.1129, grad_fn=<DivBackward1>)\n",
      "tensor(0.0978, grad_fn=<DivBackward1>)\n",
      "tensor(0.1354, grad_fn=<DivBackward1>)\n",
      "tensor(0.7136, grad_fn=<DivBackward1>)\n",
      "tensor(0.2546, grad_fn=<DivBackward1>)\n",
      "tensor(0.0583, grad_fn=<DivBackward1>)\n",
      "tensor(0.2076, grad_fn=<DivBackward1>)\n",
      "tensor(0.3887, grad_fn=<DivBackward1>)\n",
      "tensor(0.1671, grad_fn=<DivBackward1>)\n",
      "tensor(0.2710, grad_fn=<DivBackward1>)\n",
      "tensor(0.0544, grad_fn=<DivBackward1>)\n",
      "tensor(0.0969, grad_fn=<DivBackward1>)\n",
      "tensor(0.4355, grad_fn=<DivBackward1>)\n",
      "tensor(0.1653, grad_fn=<DivBackward1>)\n",
      "tensor(0.1033, grad_fn=<DivBackward1>)\n",
      "tensor(0.0778, grad_fn=<DivBackward1>)\n",
      "tensor(0.2353, grad_fn=<DivBackward1>)\n",
      "tensor(0.1272, grad_fn=<DivBackward1>)\n",
      "tensor(0.3714, grad_fn=<DivBackward1>)\n",
      "tensor(0.0975, grad_fn=<DivBackward1>)\n",
      "tensor(0.1556, grad_fn=<DivBackward1>)\n",
      "tensor(0.1413, grad_fn=<DivBackward1>)\n",
      "tensor(0.1361, grad_fn=<DivBackward1>)\n",
      "tensor(0.0254, grad_fn=<DivBackward1>)\n",
      "tensor(0.2385, grad_fn=<DivBackward1>)\n",
      "tensor(0.3346, grad_fn=<DivBackward1>)\n",
      "tensor(0.1270, grad_fn=<DivBackward1>)\n",
      "tensor(0.0369, grad_fn=<DivBackward1>)\n",
      "tensor(0.1404, grad_fn=<DivBackward1>)\n",
      "tensor(0.1617, grad_fn=<DivBackward1>)\n",
      "tensor(0.2320, grad_fn=<DivBackward1>)\n",
      "tensor(0.0793, grad_fn=<DivBackward1>)\n",
      "tensor(0.2022, grad_fn=<DivBackward1>)\n",
      "tensor(0.1151, grad_fn=<DivBackward1>)\n",
      "tensor(0.1019, grad_fn=<DivBackward1>)\n",
      "tensor(0.0621, grad_fn=<DivBackward1>)\n",
      "tensor(0.5591, grad_fn=<DivBackward1>)\n",
      "tensor(1.0656, grad_fn=<DivBackward1>)\n",
      "tensor(0.2556, grad_fn=<DivBackward1>)\n",
      "tensor(0.2297, grad_fn=<DivBackward1>)\n",
      "tensor(0.3529, grad_fn=<DivBackward1>)\n",
      "tensor(0.1294, grad_fn=<DivBackward1>)\n",
      "tensor(0.0342, grad_fn=<DivBackward1>)\n",
      "tensor(0.2014, grad_fn=<DivBackward1>)\n",
      "tensor(0.0642, grad_fn=<DivBackward1>)\n",
      "tensor(0.1729, grad_fn=<DivBackward1>)\n",
      "tensor(0.1164, grad_fn=<DivBackward1>)\n",
      "tensor(0.4057, grad_fn=<DivBackward1>)\n",
      "tensor(0.0390, grad_fn=<DivBackward1>)\n",
      "tensor(0.3221, grad_fn=<DivBackward1>)\n",
      "tensor(0.1530, grad_fn=<DivBackward1>)\n",
      "tensor(0.0304, grad_fn=<DivBackward1>)\n",
      "tensor(0.0412, grad_fn=<DivBackward1>)\n",
      "tensor(0.3433, grad_fn=<DivBackward1>)\n",
      "tensor(0.1200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0519, grad_fn=<DivBackward1>)\n",
      "tensor(0.6888, grad_fn=<DivBackward1>)\n",
      "tensor(0.4694, grad_fn=<DivBackward1>)\n",
      "tensor(0.3065, grad_fn=<DivBackward1>)\n",
      "tensor(0.0433, grad_fn=<DivBackward1>)\n",
      "tensor(0.1848, grad_fn=<DivBackward1>)\n",
      "tensor(0.1421, grad_fn=<DivBackward1>)\n",
      "tensor(0.1099, grad_fn=<DivBackward1>)\n",
      "tensor(0.1574, grad_fn=<DivBackward1>)\n",
      "tensor(0.3601, grad_fn=<DivBackward1>)\n",
      "tensor(0.9849, grad_fn=<DivBackward1>)\n",
      "tensor(0.7062, grad_fn=<DivBackward1>)\n",
      "tensor(0.1693, grad_fn=<DivBackward1>)\n",
      "tensor(0.1104, grad_fn=<DivBackward1>)\n",
      "tensor(0.1208, grad_fn=<DivBackward1>)\n",
      "tensor(0.0925, grad_fn=<DivBackward1>)\n",
      "tensor(0.0988, grad_fn=<DivBackward1>)\n",
      "tensor(0.1298, grad_fn=<DivBackward1>)\n",
      "tensor(0.7311, grad_fn=<DivBackward1>)\n",
      "tensor(0.2625, grad_fn=<DivBackward1>)\n",
      "tensor(0.0567, grad_fn=<DivBackward1>)\n",
      "tensor(0.2082, grad_fn=<DivBackward1>)\n",
      "tensor(0.3595, grad_fn=<DivBackward1>)\n",
      "tensor(0.1697, grad_fn=<DivBackward1>)\n",
      "tensor(0.2599, grad_fn=<DivBackward1>)\n",
      "tensor(0.0497, grad_fn=<DivBackward1>)\n",
      "tensor(0.0926, grad_fn=<DivBackward1>)\n",
      "tensor(0.4187, grad_fn=<DivBackward1>)\n",
      "tensor(0.1378, grad_fn=<DivBackward1>)\n",
      "tensor(0.0983, grad_fn=<DivBackward1>)\n",
      "tensor(0.0725, grad_fn=<DivBackward1>)\n",
      "tensor(0.2187, grad_fn=<DivBackward1>)\n",
      "tensor(0.1233, grad_fn=<DivBackward1>)\n",
      "tensor(0.3515, grad_fn=<DivBackward1>)\n",
      "tensor(0.0885, grad_fn=<DivBackward1>)\n",
      "tensor(0.1656, grad_fn=<DivBackward1>)\n",
      "tensor(0.1318, grad_fn=<DivBackward1>)\n",
      "tensor(0.1380, grad_fn=<DivBackward1>)\n",
      "tensor(0.0248, grad_fn=<DivBackward1>)\n",
      "tensor(0.2140, grad_fn=<DivBackward1>)\n",
      "tensor(0.2783, grad_fn=<DivBackward1>)\n",
      "tensor(0.1112, grad_fn=<DivBackward1>)\n",
      "tensor(0.0368, grad_fn=<DivBackward1>)\n",
      "tensor(0.1342, grad_fn=<DivBackward1>)\n",
      "tensor(0.1638, grad_fn=<DivBackward1>)\n",
      "tensor(0.2144, grad_fn=<DivBackward1>)\n",
      "tensor(0.0717, grad_fn=<DivBackward1>)\n",
      "tensor(0.1998, grad_fn=<DivBackward1>)\n",
      "tensor(0.1058, grad_fn=<DivBackward1>)\n",
      "tensor(0.0931, grad_fn=<DivBackward1>)\n",
      "tensor(0.0554, grad_fn=<DivBackward1>)\n",
      "tensor(0.5202, grad_fn=<DivBackward1>)\n",
      "tensor(1.0505, grad_fn=<DivBackward1>)\n",
      "tensor(0.2811, grad_fn=<DivBackward1>)\n",
      "tensor(0.2091, grad_fn=<DivBackward1>)\n",
      "tensor(0.2974, grad_fn=<DivBackward1>)\n",
      "tensor(0.1217, grad_fn=<DivBackward1>)\n",
      "tensor(0.0291, grad_fn=<DivBackward1>)\n",
      "tensor(0.1782, grad_fn=<DivBackward1>)\n",
      "tensor(0.0630, grad_fn=<DivBackward1>)\n",
      "tensor(0.1577, grad_fn=<DivBackward1>)\n",
      "tensor(0.1071, grad_fn=<DivBackward1>)\n",
      "tensor(0.4104, grad_fn=<DivBackward1>)\n",
      "tensor(0.0353, grad_fn=<DivBackward1>)\n",
      "tensor(0.2871, grad_fn=<DivBackward1>)\n",
      "tensor(0.1513, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0376, grad_fn=<DivBackward1>)\n",
      "tensor(0.2994, grad_fn=<DivBackward1>)\n",
      "tensor(0.1228, grad_fn=<DivBackward1>)\n",
      "tensor(0.0533, grad_fn=<DivBackward1>)\n",
      "tensor(0.7149, grad_fn=<DivBackward1>)\n",
      "tensor(0.4947, grad_fn=<DivBackward1>)\n",
      "tensor(0.2877, grad_fn=<DivBackward1>)\n",
      "tensor(0.0395, grad_fn=<DivBackward1>)\n",
      "tensor(0.1761, grad_fn=<DivBackward1>)\n",
      "tensor(0.1224, grad_fn=<DivBackward1>)\n",
      "tensor(0.0963, grad_fn=<DivBackward1>)\n",
      "tensor(0.1577, grad_fn=<DivBackward1>)\n",
      "tensor(0.3729, grad_fn=<DivBackward1>)\n",
      "tensor(0.9868, grad_fn=<DivBackward1>)\n",
      "tensor(0.7185, grad_fn=<DivBackward1>)\n",
      "tensor(0.1629, grad_fn=<DivBackward1>)\n",
      "tensor(0.0990, grad_fn=<DivBackward1>)\n",
      "tensor(0.1075, grad_fn=<DivBackward1>)\n",
      "tensor(0.0838, grad_fn=<DivBackward1>)\n",
      "tensor(0.0911, grad_fn=<DivBackward1>)\n",
      "tensor(0.1181, grad_fn=<DivBackward1>)\n",
      "tensor(0.7415, grad_fn=<DivBackward1>)\n",
      "tensor(0.2524, grad_fn=<DivBackward1>)\n",
      "tensor(0.0501, grad_fn=<DivBackward1>)\n",
      "tensor(0.2047, grad_fn=<DivBackward1>)\n",
      "tensor(0.3425, grad_fn=<DivBackward1>)\n",
      "tensor(0.1673, grad_fn=<DivBackward1>)\n",
      "tensor(0.2707, grad_fn=<DivBackward1>)\n",
      "tensor(0.0458, grad_fn=<DivBackward1>)\n",
      "tensor(0.0918, grad_fn=<DivBackward1>)\n",
      "tensor(0.4240, grad_fn=<DivBackward1>)\n",
      "tensor(0.1344, grad_fn=<DivBackward1>)\n",
      "tensor(0.0985, grad_fn=<DivBackward1>)\n",
      "tensor(0.0627, grad_fn=<DivBackward1>)\n",
      "tensor(0.2072, grad_fn=<DivBackward1>)\n",
      "tensor(0.1020, grad_fn=<DivBackward1>)\n",
      "tensor(0.3016, grad_fn=<DivBackward1>)\n",
      "tensor(0.0782, grad_fn=<DivBackward1>)\n",
      "tensor(0.1415, grad_fn=<DivBackward1>)\n",
      "tensor(0.1184, grad_fn=<DivBackward1>)\n",
      "tensor(0.1097, grad_fn=<DivBackward1>)\n",
      "tensor(0.0227, grad_fn=<DivBackward1>)\n",
      "tensor(0.1960, grad_fn=<DivBackward1>)\n",
      "tensor(0.2646, grad_fn=<DivBackward1>)\n",
      "tensor(0.1049, grad_fn=<DivBackward1>)\n",
      "tensor(0.0313, grad_fn=<DivBackward1>)\n",
      "tensor(0.1202, grad_fn=<DivBackward1>)\n",
      "tensor(0.1273, grad_fn=<DivBackward1>)\n",
      "tensor(0.2292, grad_fn=<DivBackward1>)\n",
      "tensor(0.0697, grad_fn=<DivBackward1>)\n",
      "tensor(0.2027, grad_fn=<DivBackward1>)\n",
      "tensor(0.0943, grad_fn=<DivBackward1>)\n",
      "tensor(0.0799, grad_fn=<DivBackward1>)\n",
      "tensor(0.0573, grad_fn=<DivBackward1>)\n",
      "tensor(0.4673, grad_fn=<DivBackward1>)\n",
      "tensor(1.0383, grad_fn=<DivBackward1>)\n",
      "tensor(0.2370, grad_fn=<DivBackward1>)\n",
      "tensor(0.2062, grad_fn=<DivBackward1>)\n",
      "tensor(0.2646, grad_fn=<DivBackward1>)\n",
      "tensor(0.1109, grad_fn=<DivBackward1>)\n",
      "tensor(0.0273, grad_fn=<DivBackward1>)\n",
      "tensor(0.1949, grad_fn=<DivBackward1>)\n",
      "tensor(0.0496, grad_fn=<DivBackward1>)\n",
      "tensor(0.1619, grad_fn=<DivBackward1>)\n",
      "tensor(0.1037, grad_fn=<DivBackward1>)\n",
      "tensor(0.4155, grad_fn=<DivBackward1>)\n",
      "tensor(0.0315, grad_fn=<DivBackward1>)\n",
      "tensor(0.2379, grad_fn=<DivBackward1>)\n",
      "tensor(0.1253, grad_fn=<DivBackward1>)\n",
      "tensor(0.0203, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.3080, grad_fn=<DivBackward1>)\n",
      "tensor(0.1164, grad_fn=<DivBackward1>)\n",
      "tensor(0.0469, grad_fn=<DivBackward1>)\n",
      "tensor(0.7187, grad_fn=<DivBackward1>)\n",
      "tensor(0.4435, grad_fn=<DivBackward1>)\n",
      "tensor(0.2839, grad_fn=<DivBackward1>)\n",
      "tensor(0.0368, grad_fn=<DivBackward1>)\n",
      "tensor(0.1703, grad_fn=<DivBackward1>)\n",
      "tensor(0.1250, grad_fn=<DivBackward1>)\n",
      "tensor(0.0995, grad_fn=<DivBackward1>)\n",
      "tensor(0.1541, grad_fn=<DivBackward1>)\n",
      "tensor(0.3332, grad_fn=<DivBackward1>)\n",
      "tensor(0.9577, grad_fn=<DivBackward1>)\n",
      "tensor(0.7266, grad_fn=<DivBackward1>)\n",
      "tensor(0.1541, grad_fn=<DivBackward1>)\n",
      "tensor(0.0846, grad_fn=<DivBackward1>)\n",
      "tensor(0.0975, grad_fn=<DivBackward1>)\n",
      "tensor(0.0756, grad_fn=<DivBackward1>)\n",
      "tensor(0.0803, grad_fn=<DivBackward1>)\n",
      "tensor(0.1132, grad_fn=<DivBackward1>)\n",
      "tensor(0.7655, grad_fn=<DivBackward1>)\n",
      "tensor(0.2394, grad_fn=<DivBackward1>)\n",
      "tensor(0.0453, grad_fn=<DivBackward1>)\n",
      "tensor(0.1869, grad_fn=<DivBackward1>)\n",
      "tensor(0.3168, grad_fn=<DivBackward1>)\n",
      "tensor(0.1687, grad_fn=<DivBackward1>)\n",
      "tensor(0.2193, grad_fn=<DivBackward1>)\n",
      "tensor(0.0381, grad_fn=<DivBackward1>)\n",
      "tensor(0.0789, grad_fn=<DivBackward1>)\n",
      "tensor(0.4076, grad_fn=<DivBackward1>)\n",
      "tensor(0.1534, grad_fn=<DivBackward1>)\n",
      "tensor(0.0884, grad_fn=<DivBackward1>)\n",
      "tensor(0.0703, grad_fn=<DivBackward1>)\n",
      "tensor(0.1834, grad_fn=<DivBackward1>)\n",
      "tensor(0.1127, grad_fn=<DivBackward1>)\n",
      "tensor(0.3269, grad_fn=<DivBackward1>)\n",
      "tensor(0.0703, grad_fn=<DivBackward1>)\n",
      "tensor(0.1610, grad_fn=<DivBackward1>)\n",
      "tensor(0.1093, grad_fn=<DivBackward1>)\n",
      "tensor(0.1191, grad_fn=<DivBackward1>)\n",
      "tensor(0.0257, grad_fn=<DivBackward1>)\n",
      "tensor(0.1670, grad_fn=<DivBackward1>)\n",
      "tensor(0.2274, grad_fn=<DivBackward1>)\n",
      "tensor(0.0842, grad_fn=<DivBackward1>)\n",
      "tensor(0.0314, grad_fn=<DivBackward1>)\n",
      "tensor(0.1008, grad_fn=<DivBackward1>)\n",
      "tensor(0.1206, grad_fn=<DivBackward1>)\n",
      "tensor(0.2136, grad_fn=<DivBackward1>)\n",
      "tensor(0.0676, grad_fn=<DivBackward1>)\n",
      "tensor(0.1965, grad_fn=<DivBackward1>)\n",
      "tensor(0.0830, grad_fn=<DivBackward1>)\n",
      "tensor(0.0732, grad_fn=<DivBackward1>)\n",
      "tensor(0.0513, grad_fn=<DivBackward1>)\n",
      "tensor(0.4451, grad_fn=<DivBackward1>)\n",
      "tensor(1.0291, grad_fn=<DivBackward1>)\n",
      "tensor(0.2491, grad_fn=<DivBackward1>)\n",
      "tensor(0.2199, grad_fn=<DivBackward1>)\n",
      "tensor(0.2451, grad_fn=<DivBackward1>)\n",
      "tensor(0.1028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0233, grad_fn=<DivBackward1>)\n",
      "tensor(0.1315, grad_fn=<DivBackward1>)\n",
      "tensor(0.0590, grad_fn=<DivBackward1>)\n",
      "tensor(0.1488, grad_fn=<DivBackward1>)\n",
      "tensor(0.1012, grad_fn=<DivBackward1>)\n",
      "tensor(0.3918, grad_fn=<DivBackward1>)\n",
      "tensor(0.0280, grad_fn=<DivBackward1>)\n",
      "tensor(0.2336, grad_fn=<DivBackward1>)\n",
      "tensor(0.1255, grad_fn=<DivBackward1>)\n",
      "tensor(0.0171, grad_fn=<DivBackward1>)\n",
      "tensor(0.0312, grad_fn=<DivBackward1>)\n",
      "tensor(0.2783, grad_fn=<DivBackward1>)\n",
      "tensor(0.0977, grad_fn=<DivBackward1>)\n",
      "tensor(0.0434, grad_fn=<DivBackward1>)\n",
      "tensor(0.7173, grad_fn=<DivBackward1>)\n",
      "tensor(0.4586, grad_fn=<DivBackward1>)\n",
      "tensor(0.2838, grad_fn=<DivBackward1>)\n",
      "tensor(0.0293, grad_fn=<DivBackward1>)\n",
      "tensor(0.1917, grad_fn=<DivBackward1>)\n",
      "tensor(0.1100, grad_fn=<DivBackward1>)\n",
      "tensor(0.0858, grad_fn=<DivBackward1>)\n",
      "tensor(0.1373, grad_fn=<DivBackward1>)\n",
      "tensor(0.3383, grad_fn=<DivBackward1>)\n",
      "tensor(0.9459, grad_fn=<DivBackward1>)\n",
      "tensor(0.7278, grad_fn=<DivBackward1>)\n",
      "tensor(0.1542, grad_fn=<DivBackward1>)\n",
      "tensor(0.0786, grad_fn=<DivBackward1>)\n",
      "tensor(0.0965, grad_fn=<DivBackward1>)\n",
      "tensor(0.0720, grad_fn=<DivBackward1>)\n",
      "tensor(0.0812, grad_fn=<DivBackward1>)\n",
      "tensor(0.1111, grad_fn=<DivBackward1>)\n",
      "tensor(0.7819, grad_fn=<DivBackward1>)\n",
      "tensor(0.2226, grad_fn=<DivBackward1>)\n",
      "tensor(0.0408, grad_fn=<DivBackward1>)\n",
      "tensor(0.2375, grad_fn=<DivBackward1>)\n",
      "tensor(0.2787, grad_fn=<DivBackward1>)\n",
      "tensor(0.1645, grad_fn=<DivBackward1>)\n",
      "tensor(0.2552, grad_fn=<DivBackward1>)\n",
      "tensor(0.0361, grad_fn=<DivBackward1>)\n",
      "tensor(0.0717, grad_fn=<DivBackward1>)\n",
      "tensor(0.4125, grad_fn=<DivBackward1>)\n",
      "tensor(0.1509, grad_fn=<DivBackward1>)\n",
      "tensor(0.0862, grad_fn=<DivBackward1>)\n",
      "tensor(0.0670, grad_fn=<DivBackward1>)\n",
      "tensor(0.1776, grad_fn=<DivBackward1>)\n",
      "tensor(0.0857, grad_fn=<DivBackward1>)\n",
      "tensor(0.2495, grad_fn=<DivBackward1>)\n",
      "tensor(0.0654, grad_fn=<DivBackward1>)\n",
      "tensor(0.1292, grad_fn=<DivBackward1>)\n",
      "tensor(0.0899, grad_fn=<DivBackward1>)\n",
      "tensor(0.1098, grad_fn=<DivBackward1>)\n",
      "tensor(0.0217, grad_fn=<DivBackward1>)\n",
      "tensor(0.1486, grad_fn=<DivBackward1>)\n",
      "tensor(0.2083, grad_fn=<DivBackward1>)\n",
      "tensor(0.0827, grad_fn=<DivBackward1>)\n",
      "tensor(0.0265, grad_fn=<DivBackward1>)\n",
      "tensor(0.0993, grad_fn=<DivBackward1>)\n",
      "tensor(0.1065, grad_fn=<DivBackward1>)\n",
      "tensor(0.2281, grad_fn=<DivBackward1>)\n",
      "tensor(0.0621, grad_fn=<DivBackward1>)\n",
      "tensor(0.1897, grad_fn=<DivBackward1>)\n",
      "tensor(0.0650, grad_fn=<DivBackward1>)\n",
      "tensor(0.0625, grad_fn=<DivBackward1>)\n",
      "tensor(0.0541, grad_fn=<DivBackward1>)\n",
      "tensor(0.4246, grad_fn=<DivBackward1>)\n",
      "tensor(0.9781, grad_fn=<DivBackward1>)\n",
      "tensor(0.2358, grad_fn=<DivBackward1>)\n",
      "tensor(0.1505, grad_fn=<DivBackward1>)\n",
      "tensor(0.2329, grad_fn=<DivBackward1>)\n",
      "tensor(0.1019, grad_fn=<DivBackward1>)\n",
      "tensor(0.0229, grad_fn=<DivBackward1>)\n",
      "tensor(0.1553, grad_fn=<DivBackward1>)\n",
      "tensor(0.0517, grad_fn=<DivBackward1>)\n",
      "tensor(0.1571, grad_fn=<DivBackward1>)\n",
      "tensor(0.0919, grad_fn=<DivBackward1>)\n",
      "tensor(0.3577, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.2044, grad_fn=<DivBackward1>)\n",
      "tensor(0.1159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0164, grad_fn=<DivBackward1>)\n",
      "tensor(0.0287, grad_fn=<DivBackward1>)\n",
      "tensor(0.2558, grad_fn=<DivBackward1>)\n",
      "tensor(0.1062, grad_fn=<DivBackward1>)\n",
      "tensor(0.0343, grad_fn=<DivBackward1>)\n",
      "tensor(0.7350, grad_fn=<DivBackward1>)\n",
      "tensor(0.3852, grad_fn=<DivBackward1>)\n",
      "tensor(0.2979, grad_fn=<DivBackward1>)\n",
      "tensor(0.0273, grad_fn=<DivBackward1>)\n",
      "tensor(0.1865, grad_fn=<DivBackward1>)\n",
      "tensor(0.1159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0732, grad_fn=<DivBackward1>)\n",
      "tensor(0.1297, grad_fn=<DivBackward1>)\n",
      "tensor(0.2812, grad_fn=<DivBackward1>)\n",
      "tensor(0.9412, grad_fn=<DivBackward1>)\n",
      "tensor(0.7386, grad_fn=<DivBackward1>)\n",
      "tensor(0.1508, grad_fn=<DivBackward1>)\n",
      "tensor(0.0769, grad_fn=<DivBackward1>)\n",
      "tensor(0.0771, grad_fn=<DivBackward1>)\n",
      "tensor(0.0616, grad_fn=<DivBackward1>)\n",
      "tensor(0.0748, grad_fn=<DivBackward1>)\n",
      "tensor(0.1016, grad_fn=<DivBackward1>)\n",
      "tensor(0.7701, grad_fn=<DivBackward1>)\n",
      "tensor(0.2385, grad_fn=<DivBackward1>)\n",
      "tensor(0.0370, grad_fn=<DivBackward1>)\n",
      "tensor(0.1758, grad_fn=<DivBackward1>)\n",
      "tensor(0.2719, grad_fn=<DivBackward1>)\n",
      "tensor(0.1986, grad_fn=<DivBackward1>)\n",
      "tensor(0.1995, grad_fn=<DivBackward1>)\n",
      "tensor(0.0334, grad_fn=<DivBackward1>)\n",
      "tensor(0.0765, grad_fn=<DivBackward1>)\n",
      "tensor(0.4016, grad_fn=<DivBackward1>)\n",
      "tensor(0.1360, grad_fn=<DivBackward1>)\n",
      "tensor(0.0760, grad_fn=<DivBackward1>)\n",
      "tensor(0.0680, grad_fn=<DivBackward1>)\n",
      "tensor(0.1597, grad_fn=<DivBackward1>)\n",
      "tensor(0.0950, grad_fn=<DivBackward1>)\n",
      "tensor(0.2661, grad_fn=<DivBackward1>)\n",
      "tensor(0.0469, grad_fn=<DivBackward1>)\n",
      "tensor(0.1710, grad_fn=<DivBackward1>)\n",
      "tensor(0.0976, grad_fn=<DivBackward1>)\n",
      "tensor(0.1159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0242, grad_fn=<DivBackward1>)\n",
      "tensor(0.1256, grad_fn=<DivBackward1>)\n",
      "tensor(0.2150, grad_fn=<DivBackward1>)\n",
      "tensor(0.0757, grad_fn=<DivBackward1>)\n",
      "tensor(0.0254, grad_fn=<DivBackward1>)\n",
      "tensor(0.0815, grad_fn=<DivBackward1>)\n",
      "tensor(0.1046, grad_fn=<DivBackward1>)\n",
      "tensor(0.2038, grad_fn=<DivBackward1>)\n",
      "tensor(0.0546, grad_fn=<DivBackward1>)\n",
      "tensor(0.1748, grad_fn=<DivBackward1>)\n",
      "tensor(0.0567, grad_fn=<DivBackward1>)\n",
      "tensor(0.0584, grad_fn=<DivBackward1>)\n",
      "tensor(0.0476, grad_fn=<DivBackward1>)\n",
      "tensor(0.3802, grad_fn=<DivBackward1>)\n",
      "tensor(0.9147, grad_fn=<DivBackward1>)\n",
      "tensor(0.2083, grad_fn=<DivBackward1>)\n",
      "tensor(0.1900, grad_fn=<DivBackward1>)\n",
      "tensor(0.1959, grad_fn=<DivBackward1>)\n",
      "tensor(0.1001, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.1323, grad_fn=<DivBackward1>)\n",
      "tensor(0.0471, grad_fn=<DivBackward1>)\n",
      "tensor(0.1506, grad_fn=<DivBackward1>)\n",
      "tensor(0.0924, grad_fn=<DivBackward1>)\n",
      "tensor(0.3286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0215, grad_fn=<DivBackward1>)\n",
      "tensor(0.1899, grad_fn=<DivBackward1>)\n",
      "tensor(0.1130, grad_fn=<DivBackward1>)\n",
      "tensor(0.0132, grad_fn=<DivBackward1>)\n",
      "tensor(0.0277, grad_fn=<DivBackward1>)\n",
      "tensor(0.2407, grad_fn=<DivBackward1>)\n",
      "tensor(0.1044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0396, grad_fn=<DivBackward1>)\n",
      "tensor(0.7256, grad_fn=<DivBackward1>)\n",
      "tensor(0.4259, grad_fn=<DivBackward1>)\n",
      "tensor(0.2842, grad_fn=<DivBackward1>)\n",
      "tensor(0.0251, grad_fn=<DivBackward1>)\n",
      "tensor(0.1675, grad_fn=<DivBackward1>)\n",
      "tensor(0.1014, grad_fn=<DivBackward1>)\n",
      "tensor(0.0711, grad_fn=<DivBackward1>)\n",
      "tensor(0.1227, grad_fn=<DivBackward1>)\n",
      "tensor(0.2726, grad_fn=<DivBackward1>)\n",
      "tensor(0.9133, grad_fn=<DivBackward1>)\n",
      "tensor(0.7408, grad_fn=<DivBackward1>)\n",
      "tensor(0.1571, grad_fn=<DivBackward1>)\n",
      "tensor(0.0656, grad_fn=<DivBackward1>)\n",
      "tensor(0.0696, grad_fn=<DivBackward1>)\n",
      "tensor(0.0582, grad_fn=<DivBackward1>)\n",
      "tensor(0.0773, grad_fn=<DivBackward1>)\n",
      "tensor(0.1071, grad_fn=<DivBackward1>)\n",
      "tensor(0.8181, grad_fn=<DivBackward1>)\n",
      "tensor(0.2127, grad_fn=<DivBackward1>)\n",
      "tensor(0.0377, grad_fn=<DivBackward1>)\n",
      "tensor(0.1867, grad_fn=<DivBackward1>)\n",
      "tensor(0.2526, grad_fn=<DivBackward1>)\n",
      "tensor(0.1777, grad_fn=<DivBackward1>)\n",
      "tensor(0.2020, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0726, grad_fn=<DivBackward1>)\n",
      "tensor(0.3849, grad_fn=<DivBackward1>)\n",
      "tensor(0.1162, grad_fn=<DivBackward1>)\n",
      "tensor(0.0847, grad_fn=<DivBackward1>)\n",
      "tensor(0.0629, grad_fn=<DivBackward1>)\n",
      "tensor(0.1490, grad_fn=<DivBackward1>)\n",
      "tensor(0.0921, grad_fn=<DivBackward1>)\n",
      "tensor(0.2251, grad_fn=<DivBackward1>)\n",
      "tensor(0.0576, grad_fn=<DivBackward1>)\n",
      "tensor(0.1069, grad_fn=<DivBackward1>)\n",
      "tensor(0.0814, grad_fn=<DivBackward1>)\n",
      "tensor(0.1028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0236, grad_fn=<DivBackward1>)\n",
      "tensor(0.1223, grad_fn=<DivBackward1>)\n",
      "tensor(0.1883, grad_fn=<DivBackward1>)\n",
      "tensor(0.0563, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.0798, grad_fn=<DivBackward1>)\n",
      "tensor(0.0891, grad_fn=<DivBackward1>)\n",
      "tensor(0.2037, grad_fn=<DivBackward1>)\n",
      "tensor(0.0523, grad_fn=<DivBackward1>)\n",
      "tensor(0.1653, grad_fn=<DivBackward1>)\n",
      "tensor(0.0427, grad_fn=<DivBackward1>)\n",
      "tensor(0.0524, grad_fn=<DivBackward1>)\n",
      "tensor(0.0528, grad_fn=<DivBackward1>)\n",
      "tensor(0.3651, grad_fn=<DivBackward1>)\n",
      "tensor(0.8694, grad_fn=<DivBackward1>)\n",
      "tensor(0.1971, grad_fn=<DivBackward1>)\n",
      "tensor(0.1673, grad_fn=<DivBackward1>)\n",
      "tensor(0.1895, grad_fn=<DivBackward1>)\n",
      "tensor(0.1027, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.1360, grad_fn=<DivBackward1>)\n",
      "tensor(0.0414, grad_fn=<DivBackward1>)\n",
      "tensor(0.1431, grad_fn=<DivBackward1>)\n",
      "tensor(0.0875, grad_fn=<DivBackward1>)\n",
      "tensor(0.3180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0201, grad_fn=<DivBackward1>)\n",
      "tensor(0.1872, grad_fn=<DivBackward1>)\n",
      "tensor(0.1084, grad_fn=<DivBackward1>)\n",
      "tensor(0.0112, grad_fn=<DivBackward1>)\n",
      "tensor(0.0275, grad_fn=<DivBackward1>)\n",
      "tensor(0.2287, grad_fn=<DivBackward1>)\n",
      "tensor(0.1249, grad_fn=<DivBackward1>)\n",
      "tensor(0.0359, grad_fn=<DivBackward1>)\n",
      "tensor(0.7453, grad_fn=<DivBackward1>)\n",
      "tensor(0.3406, grad_fn=<DivBackward1>)\n",
      "tensor(0.2703, grad_fn=<DivBackward1>)\n",
      "tensor(0.0232, grad_fn=<DivBackward1>)\n",
      "tensor(0.1861, grad_fn=<DivBackward1>)\n",
      "tensor(0.1032, grad_fn=<DivBackward1>)\n",
      "tensor(0.0628, grad_fn=<DivBackward1>)\n",
      "tensor(0.1188, grad_fn=<DivBackward1>)\n",
      "tensor(0.2404, grad_fn=<DivBackward1>)\n",
      "tensor(0.9209, grad_fn=<DivBackward1>)\n",
      "tensor(0.7391, grad_fn=<DivBackward1>)\n",
      "tensor(0.1222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0713, grad_fn=<DivBackward1>)\n",
      "tensor(0.0673, grad_fn=<DivBackward1>)\n",
      "tensor(0.0582, grad_fn=<DivBackward1>)\n",
      "tensor(0.0682, grad_fn=<DivBackward1>)\n",
      "tensor(0.0981, grad_fn=<DivBackward1>)\n",
      "tensor(0.8106, grad_fn=<DivBackward1>)\n",
      "tensor(0.2297, grad_fn=<DivBackward1>)\n",
      "tensor(0.0296, grad_fn=<DivBackward1>)\n",
      "tensor(0.1748, grad_fn=<DivBackward1>)\n",
      "tensor(0.2379, grad_fn=<DivBackward1>)\n",
      "tensor(0.1890, grad_fn=<DivBackward1>)\n",
      "tensor(0.2119, grad_fn=<DivBackward1>)\n",
      "tensor(0.0276, grad_fn=<DivBackward1>)\n",
      "tensor(0.0706, grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, grad_fn=<DivBackward1>)\n",
      "tensor(0.1132, grad_fn=<DivBackward1>)\n",
      "tensor(0.0717, grad_fn=<DivBackward1>)\n",
      "tensor(0.0543, grad_fn=<DivBackward1>)\n",
      "tensor(0.1283, grad_fn=<DivBackward1>)\n",
      "tensor(0.0792, grad_fn=<DivBackward1>)\n",
      "tensor(0.2026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0442, grad_fn=<DivBackward1>)\n",
      "tensor(0.1442, grad_fn=<DivBackward1>)\n",
      "tensor(0.0777, grad_fn=<DivBackward1>)\n",
      "tensor(0.1026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0260, grad_fn=<DivBackward1>)\n",
      "tensor(0.0966, grad_fn=<DivBackward1>)\n",
      "tensor(0.1801, grad_fn=<DivBackward1>)\n",
      "tensor(0.0591, grad_fn=<DivBackward1>)\n",
      "tensor(0.0239, grad_fn=<DivBackward1>)\n",
      "tensor(0.0712, grad_fn=<DivBackward1>)\n",
      "tensor(0.0769, grad_fn=<DivBackward1>)\n",
      "tensor(0.1812, grad_fn=<DivBackward1>)\n",
      "tensor(0.0484, grad_fn=<DivBackward1>)\n",
      "tensor(0.1526, grad_fn=<DivBackward1>)\n",
      "tensor(0.0381, grad_fn=<DivBackward1>)\n",
      "tensor(0.0540, grad_fn=<DivBackward1>)\n",
      "tensor(0.0422, grad_fn=<DivBackward1>)\n",
      "tensor(0.2979, grad_fn=<DivBackward1>)\n",
      "tensor(0.8190, grad_fn=<DivBackward1>)\n",
      "tensor(0.1586, grad_fn=<DivBackward1>)\n",
      "tensor(0.1539, grad_fn=<DivBackward1>)\n",
      "tensor(0.1700, grad_fn=<DivBackward1>)\n",
      "tensor(0.0735, grad_fn=<DivBackward1>)\n",
      "tensor(0.0166, grad_fn=<DivBackward1>)\n",
      "tensor(0.1159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0373, grad_fn=<DivBackward1>)\n",
      "tensor(0.1419, grad_fn=<DivBackward1>)\n",
      "tensor(0.0876, grad_fn=<DivBackward1>)\n",
      "tensor(0.3265, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.1432, grad_fn=<DivBackward1>)\n",
      "tensor(0.0887, grad_fn=<DivBackward1>)\n",
      "tensor(0.0102, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.1889, grad_fn=<DivBackward1>)\n",
      "tensor(0.1242, grad_fn=<DivBackward1>)\n",
      "tensor(0.0336, grad_fn=<DivBackward1>)\n",
      "tensor(0.7566, grad_fn=<DivBackward1>)\n",
      "tensor(0.3112, grad_fn=<DivBackward1>)\n",
      "tensor(0.2493, grad_fn=<DivBackward1>)\n",
      "tensor(0.0220, grad_fn=<DivBackward1>)\n",
      "tensor(0.1543, grad_fn=<DivBackward1>)\n",
      "tensor(0.0996, grad_fn=<DivBackward1>)\n",
      "tensor(0.0603, grad_fn=<DivBackward1>)\n",
      "tensor(0.1142, grad_fn=<DivBackward1>)\n",
      "tensor(0.2309, grad_fn=<DivBackward1>)\n",
      "tensor(0.9093, grad_fn=<DivBackward1>)\n",
      "tensor(0.7565, grad_fn=<DivBackward1>)\n",
      "tensor(0.1214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0716, grad_fn=<DivBackward1>)\n",
      "tensor(0.0625, grad_fn=<DivBackward1>)\n",
      "tensor(0.0569, grad_fn=<DivBackward1>)\n",
      "tensor(0.0716, grad_fn=<DivBackward1>)\n",
      "tensor(0.0955, grad_fn=<DivBackward1>)\n",
      "tensor(0.8234, grad_fn=<DivBackward1>)\n",
      "tensor(0.2059, grad_fn=<DivBackward1>)\n",
      "tensor(0.0284, grad_fn=<DivBackward1>)\n",
      "tensor(0.1521, grad_fn=<DivBackward1>)\n",
      "tensor(0.2206, grad_fn=<DivBackward1>)\n",
      "tensor(0.2256, grad_fn=<DivBackward1>)\n",
      "tensor(0.1775, grad_fn=<DivBackward1>)\n",
      "tensor(0.0314, grad_fn=<DivBackward1>)\n",
      "tensor(0.0780, grad_fn=<DivBackward1>)\n",
      "tensor(0.3564, grad_fn=<DivBackward1>)\n",
      "tensor(0.0929, grad_fn=<DivBackward1>)\n",
      "tensor(0.0623, grad_fn=<DivBackward1>)\n",
      "tensor(0.0585, grad_fn=<DivBackward1>)\n",
      "tensor(0.1282, grad_fn=<DivBackward1>)\n",
      "tensor(0.0890, grad_fn=<DivBackward1>)\n",
      "tensor(0.1875, grad_fn=<DivBackward1>)\n",
      "tensor(0.0582, grad_fn=<DivBackward1>)\n",
      "tensor(0.1006, grad_fn=<DivBackward1>)\n",
      "tensor(0.0628, grad_fn=<DivBackward1>)\n",
      "tensor(0.0928, grad_fn=<DivBackward1>)\n",
      "tensor(0.0252, grad_fn=<DivBackward1>)\n",
      "tensor(0.0905, grad_fn=<DivBackward1>)\n",
      "tensor(0.1474, grad_fn=<DivBackward1>)\n",
      "tensor(0.0444, grad_fn=<DivBackward1>)\n",
      "tensor(0.0223, grad_fn=<DivBackward1>)\n",
      "tensor(0.0675, grad_fn=<DivBackward1>)\n",
      "tensor(0.0589, grad_fn=<DivBackward1>)\n",
      "tensor(0.1894, grad_fn=<DivBackward1>)\n",
      "tensor(0.0436, grad_fn=<DivBackward1>)\n",
      "tensor(0.1371, grad_fn=<DivBackward1>)\n",
      "tensor(0.0323, grad_fn=<DivBackward1>)\n",
      "tensor(0.0419, grad_fn=<DivBackward1>)\n",
      "tensor(0.0401, grad_fn=<DivBackward1>)\n",
      "tensor(0.2755, grad_fn=<DivBackward1>)\n",
      "tensor(0.7629, grad_fn=<DivBackward1>)\n",
      "tensor(0.1450, grad_fn=<DivBackward1>)\n",
      "tensor(0.1460, grad_fn=<DivBackward1>)\n",
      "tensor(0.1629, grad_fn=<DivBackward1>)\n",
      "tensor(0.0862, grad_fn=<DivBackward1>)\n",
      "tensor(0.0171, grad_fn=<DivBackward1>)\n",
      "tensor(0.1190, grad_fn=<DivBackward1>)\n",
      "tensor(0.0337, grad_fn=<DivBackward1>)\n",
      "tensor(0.1464, grad_fn=<DivBackward1>)\n",
      "tensor(0.0776, grad_fn=<DivBackward1>)\n",
      "tensor(0.3120, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.1285, grad_fn=<DivBackward1>)\n",
      "tensor(0.0916, grad_fn=<DivBackward1>)\n",
      "tensor(0.0091, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.1843, grad_fn=<DivBackward1>)\n",
      "tensor(0.0762, grad_fn=<DivBackward1>)\n",
      "tensor(0.0237, grad_fn=<DivBackward1>)\n",
      "tensor(0.7136, grad_fn=<DivBackward1>)\n",
      "tensor(0.2725, grad_fn=<DivBackward1>)\n",
      "tensor(0.2451, grad_fn=<DivBackward1>)\n",
      "tensor(0.0181, grad_fn=<DivBackward1>)\n",
      "tensor(0.1708, grad_fn=<DivBackward1>)\n",
      "tensor(0.0770, grad_fn=<DivBackward1>)\n",
      "tensor(0.0487, grad_fn=<DivBackward1>)\n",
      "tensor(0.1118, grad_fn=<DivBackward1>)\n",
      "tensor(0.2070, grad_fn=<DivBackward1>)\n",
      "tensor(0.8632, grad_fn=<DivBackward1>)\n",
      "tensor(0.7546, grad_fn=<DivBackward1>)\n",
      "tensor(0.1293, grad_fn=<DivBackward1>)\n",
      "tensor(0.0760, grad_fn=<DivBackward1>)\n",
      "tensor(0.0603, grad_fn=<DivBackward1>)\n",
      "tensor(0.0568, grad_fn=<DivBackward1>)\n",
      "tensor(0.0637, grad_fn=<DivBackward1>)\n",
      "tensor(0.0874, grad_fn=<DivBackward1>)\n",
      "tensor(0.8186, grad_fn=<DivBackward1>)\n",
      "tensor(0.2064, grad_fn=<DivBackward1>)\n",
      "tensor(0.0222, grad_fn=<DivBackward1>)\n",
      "tensor(0.1345, grad_fn=<DivBackward1>)\n",
      "tensor(0.2007, grad_fn=<DivBackward1>)\n",
      "tensor(0.2232, grad_fn=<DivBackward1>)\n",
      "tensor(0.1706, grad_fn=<DivBackward1>)\n",
      "tensor(0.0274, grad_fn=<DivBackward1>)\n",
      "tensor(0.0736, grad_fn=<DivBackward1>)\n",
      "tensor(0.3087, grad_fn=<DivBackward1>)\n",
      "tensor(0.0917, grad_fn=<DivBackward1>)\n",
      "tensor(0.0620, grad_fn=<DivBackward1>)\n",
      "tensor(0.0559, grad_fn=<DivBackward1>)\n",
      "tensor(0.1119, grad_fn=<DivBackward1>)\n",
      "tensor(0.0746, grad_fn=<DivBackward1>)\n",
      "tensor(0.1686, grad_fn=<DivBackward1>)\n",
      "tensor(0.0423, grad_fn=<DivBackward1>)\n",
      "tensor(0.1149, grad_fn=<DivBackward1>)\n",
      "tensor(0.0529, grad_fn=<DivBackward1>)\n",
      "tensor(0.0999, grad_fn=<DivBackward1>)\n",
      "tensor(0.0281, grad_fn=<DivBackward1>)\n",
      "tensor(0.0846, grad_fn=<DivBackward1>)\n",
      "tensor(0.1377, grad_fn=<DivBackward1>)\n",
      "tensor(0.0401, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.0652, grad_fn=<DivBackward1>)\n",
      "tensor(0.0582, grad_fn=<DivBackward1>)\n",
      "tensor(0.1829, grad_fn=<DivBackward1>)\n",
      "tensor(0.0378, grad_fn=<DivBackward1>)\n",
      "tensor(0.1360, grad_fn=<DivBackward1>)\n",
      "tensor(0.0300, grad_fn=<DivBackward1>)\n",
      "tensor(0.0414, grad_fn=<DivBackward1>)\n",
      "tensor(0.0385, grad_fn=<DivBackward1>)\n",
      "tensor(0.2298, grad_fn=<DivBackward1>)\n",
      "tensor(0.7161, grad_fn=<DivBackward1>)\n",
      "tensor(0.1336, grad_fn=<DivBackward1>)\n",
      "tensor(0.1480, grad_fn=<DivBackward1>)\n",
      "tensor(0.1418, grad_fn=<DivBackward1>)\n",
      "tensor(0.0696, grad_fn=<DivBackward1>)\n",
      "tensor(0.0134, grad_fn=<DivBackward1>)\n",
      "tensor(0.1026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.1331, grad_fn=<DivBackward1>)\n",
      "tensor(0.0652, grad_fn=<DivBackward1>)\n",
      "tensor(0.3775, grad_fn=<DivBackward1>)\n",
      "tensor(0.0153, grad_fn=<DivBackward1>)\n",
      "tensor(0.1193, grad_fn=<DivBackward1>)\n",
      "tensor(0.0817, grad_fn=<DivBackward1>)\n",
      "tensor(0.0074, grad_fn=<DivBackward1>)\n",
      "tensor(0.0226, grad_fn=<DivBackward1>)\n",
      "tensor(0.1670, grad_fn=<DivBackward1>)\n",
      "tensor(0.0865, grad_fn=<DivBackward1>)\n",
      "tensor(0.0234, grad_fn=<DivBackward1>)\n",
      "tensor(0.7219, grad_fn=<DivBackward1>)\n",
      "tensor(0.2562, grad_fn=<DivBackward1>)\n",
      "tensor(0.1915, grad_fn=<DivBackward1>)\n",
      "tensor(0.0186, grad_fn=<DivBackward1>)\n",
      "tensor(0.1562, grad_fn=<DivBackward1>)\n",
      "tensor(0.0692, grad_fn=<DivBackward1>)\n",
      "tensor(0.0471, grad_fn=<DivBackward1>)\n",
      "tensor(0.0987, grad_fn=<DivBackward1>)\n",
      "tensor(0.1722, grad_fn=<DivBackward1>)\n",
      "tensor(0.8502, grad_fn=<DivBackward1>)\n",
      "tensor(0.7566, grad_fn=<DivBackward1>)\n",
      "tensor(0.1133, grad_fn=<DivBackward1>)\n",
      "tensor(0.0559, grad_fn=<DivBackward1>)\n",
      "tensor(0.0571, grad_fn=<DivBackward1>)\n",
      "tensor(0.0533, grad_fn=<DivBackward1>)\n",
      "tensor(0.0571, grad_fn=<DivBackward1>)\n",
      "tensor(0.0790, grad_fn=<DivBackward1>)\n",
      "tensor(0.8533, grad_fn=<DivBackward1>)\n",
      "tensor(0.1913, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.1153, grad_fn=<DivBackward1>)\n",
      "tensor(0.1792, grad_fn=<DivBackward1>)\n",
      "tensor(0.2603, grad_fn=<DivBackward1>)\n",
      "tensor(0.1519, grad_fn=<DivBackward1>)\n",
      "tensor(0.0264, grad_fn=<DivBackward1>)\n",
      "tensor(0.0596, grad_fn=<DivBackward1>)\n",
      "tensor(0.3335, grad_fn=<DivBackward1>)\n",
      "tensor(0.0931, grad_fn=<DivBackward1>)\n",
      "tensor(0.0612, grad_fn=<DivBackward1>)\n",
      "tensor(0.0459, grad_fn=<DivBackward1>)\n",
      "tensor(0.1063, grad_fn=<DivBackward1>)\n",
      "tensor(0.0810, grad_fn=<DivBackward1>)\n",
      "tensor(0.1564, grad_fn=<DivBackward1>)\n",
      "tensor(0.0402, grad_fn=<DivBackward1>)\n",
      "tensor(0.1268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0532, grad_fn=<DivBackward1>)\n",
      "tensor(0.0861, grad_fn=<DivBackward1>)\n",
      "tensor(0.0266, grad_fn=<DivBackward1>)\n",
      "tensor(0.0797, grad_fn=<DivBackward1>)\n",
      "tensor(0.1291, grad_fn=<DivBackward1>)\n",
      "tensor(0.0447, grad_fn=<DivBackward1>)\n",
      "tensor(0.0232, grad_fn=<DivBackward1>)\n",
      "tensor(0.0553, grad_fn=<DivBackward1>)\n",
      "tensor(0.0531, grad_fn=<DivBackward1>)\n",
      "tensor(0.1723, grad_fn=<DivBackward1>)\n",
      "tensor(0.0395, grad_fn=<DivBackward1>)\n",
      "tensor(0.1215, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0395, grad_fn=<DivBackward1>)\n",
      "tensor(0.0357, grad_fn=<DivBackward1>)\n",
      "tensor(0.1941, grad_fn=<DivBackward1>)\n",
      "tensor(0.6651, grad_fn=<DivBackward1>)\n",
      "tensor(0.1524, grad_fn=<DivBackward1>)\n",
      "tensor(0.1830, grad_fn=<DivBackward1>)\n",
      "tensor(0.1323, grad_fn=<DivBackward1>)\n",
      "tensor(0.0798, grad_fn=<DivBackward1>)\n",
      "tensor(0.0125, grad_fn=<DivBackward1>)\n",
      "tensor(0.1012, grad_fn=<DivBackward1>)\n",
      "tensor(0.0255, grad_fn=<DivBackward1>)\n",
      "tensor(0.1313, grad_fn=<DivBackward1>)\n",
      "tensor(0.0709, grad_fn=<DivBackward1>)\n",
      "tensor(0.3233, grad_fn=<DivBackward1>)\n",
      "tensor(0.0132, grad_fn=<DivBackward1>)\n",
      "tensor(0.1393, grad_fn=<DivBackward1>)\n",
      "tensor(0.0625, grad_fn=<DivBackward1>)\n",
      "tensor(0.0064, grad_fn=<DivBackward1>)\n",
      "tensor(0.0192, grad_fn=<DivBackward1>)\n",
      "tensor(0.2174, grad_fn=<DivBackward1>)\n",
      "tensor(0.0561, grad_fn=<DivBackward1>)\n",
      "tensor(0.0255, grad_fn=<DivBackward1>)\n",
      "tensor(0.6683, grad_fn=<DivBackward1>)\n",
      "tensor(0.2555, grad_fn=<DivBackward1>)\n",
      "tensor(0.2051, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.1507, grad_fn=<DivBackward1>)\n",
      "tensor(0.0734, grad_fn=<DivBackward1>)\n",
      "tensor(0.0384, grad_fn=<DivBackward1>)\n",
      "tensor(0.0935, grad_fn=<DivBackward1>)\n",
      "tensor(0.1948, grad_fn=<DivBackward1>)\n",
      "tensor(0.8612, grad_fn=<DivBackward1>)\n",
      "tensor(0.7339, grad_fn=<DivBackward1>)\n",
      "tensor(0.1222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0517, grad_fn=<DivBackward1>)\n",
      "tensor(0.0480, grad_fn=<DivBackward1>)\n",
      "tensor(0.0535, grad_fn=<DivBackward1>)\n",
      "tensor(0.0591, grad_fn=<DivBackward1>)\n",
      "tensor(0.0846, grad_fn=<DivBackward1>)\n",
      "tensor(0.8646, grad_fn=<DivBackward1>)\n",
      "tensor(0.1950, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.1101, grad_fn=<DivBackward1>)\n",
      "tensor(0.1703, grad_fn=<DivBackward1>)\n",
      "tensor(0.2173, grad_fn=<DivBackward1>)\n",
      "tensor(0.1605, grad_fn=<DivBackward1>)\n",
      "tensor(0.0242, grad_fn=<DivBackward1>)\n",
      "tensor(0.0719, grad_fn=<DivBackward1>)\n",
      "tensor(0.2562, grad_fn=<DivBackward1>)\n",
      "tensor(0.0862, grad_fn=<DivBackward1>)\n",
      "tensor(0.0647, grad_fn=<DivBackward1>)\n",
      "tensor(0.0510, grad_fn=<DivBackward1>)\n",
      "tensor(0.1088, grad_fn=<DivBackward1>)\n",
      "tensor(0.0712, grad_fn=<DivBackward1>)\n",
      "tensor(0.1140, grad_fn=<DivBackward1>)\n",
      "tensor(0.0461, grad_fn=<DivBackward1>)\n",
      "tensor(0.0861, grad_fn=<DivBackward1>)\n",
      "tensor(0.0471, grad_fn=<DivBackward1>)\n",
      "tensor(0.0804, grad_fn=<DivBackward1>)\n",
      "tensor(0.0279, grad_fn=<DivBackward1>)\n",
      "tensor(0.0815, grad_fn=<DivBackward1>)\n",
      "tensor(0.1159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0361, grad_fn=<DivBackward1>)\n",
      "tensor(0.0219, grad_fn=<DivBackward1>)\n",
      "tensor(0.0565, grad_fn=<DivBackward1>)\n",
      "tensor(0.0507, grad_fn=<DivBackward1>)\n",
      "tensor(0.1682, grad_fn=<DivBackward1>)\n",
      "tensor(0.0366, grad_fn=<DivBackward1>)\n",
      "tensor(0.1263, grad_fn=<DivBackward1>)\n",
      "tensor(0.0214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0361, grad_fn=<DivBackward1>)\n",
      "tensor(0.0323, grad_fn=<DivBackward1>)\n",
      "tensor(0.1623, grad_fn=<DivBackward1>)\n",
      "tensor(0.6193, grad_fn=<DivBackward1>)\n",
      "tensor(0.1217, grad_fn=<DivBackward1>)\n",
      "tensor(0.1728, grad_fn=<DivBackward1>)\n",
      "tensor(0.1223, grad_fn=<DivBackward1>)\n",
      "tensor(0.0748, grad_fn=<DivBackward1>)\n",
      "tensor(0.0117, grad_fn=<DivBackward1>)\n",
      "tensor(0.0927, grad_fn=<DivBackward1>)\n",
      "tensor(0.0255, grad_fn=<DivBackward1>)\n",
      "tensor(0.1295, grad_fn=<DivBackward1>)\n",
      "tensor(0.0559, grad_fn=<DivBackward1>)\n",
      "tensor(0.4085, grad_fn=<DivBackward1>)\n",
      "tensor(0.0141, grad_fn=<DivBackward1>)\n",
      "tensor(0.0930, grad_fn=<DivBackward1>)\n",
      "tensor(0.0689, grad_fn=<DivBackward1>)\n",
      "tensor(0.0062, grad_fn=<DivBackward1>)\n",
      "tensor(0.0275, grad_fn=<DivBackward1>)\n",
      "tensor(0.1412, grad_fn=<DivBackward1>)\n",
      "tensor(0.1570, grad_fn=<DivBackward1>)\n",
      "tensor(0.0355, grad_fn=<DivBackward1>)\n",
      "tensor(0.7678, grad_fn=<DivBackward1>)\n",
      "tensor(0.1748, grad_fn=<DivBackward1>)\n",
      "tensor(0.1747, grad_fn=<DivBackward1>)\n",
      "tensor(0.0162, grad_fn=<DivBackward1>)\n",
      "tensor(0.2173, grad_fn=<DivBackward1>)\n",
      "tensor(0.0670, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.1046, grad_fn=<DivBackward1>)\n",
      "tensor(0.1372, grad_fn=<DivBackward1>)\n",
      "tensor(0.8148, grad_fn=<DivBackward1>)\n",
      "tensor(0.7711, grad_fn=<DivBackward1>)\n",
      "tensor(0.1028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0520, grad_fn=<DivBackward1>)\n",
      "tensor(0.0463, grad_fn=<DivBackward1>)\n",
      "tensor(0.0580, grad_fn=<DivBackward1>)\n",
      "tensor(0.0460, grad_fn=<DivBackward1>)\n",
      "tensor(0.0677, grad_fn=<DivBackward1>)\n",
      "tensor(0.8522, grad_fn=<DivBackward1>)\n",
      "tensor(0.1730, grad_fn=<DivBackward1>)\n",
      "tensor(0.0150, grad_fn=<DivBackward1>)\n",
      "tensor(0.1205, grad_fn=<DivBackward1>)\n",
      "tensor(0.1496, grad_fn=<DivBackward1>)\n",
      "tensor(0.2391, grad_fn=<DivBackward1>)\n",
      "tensor(0.1308, grad_fn=<DivBackward1>)\n",
      "tensor(0.0264, grad_fn=<DivBackward1>)\n",
      "tensor(0.0547, grad_fn=<DivBackward1>)\n",
      "tensor(0.3198, grad_fn=<DivBackward1>)\n",
      "tensor(0.0831, grad_fn=<DivBackward1>)\n",
      "tensor(0.0525, grad_fn=<DivBackward1>)\n",
      "tensor(0.0503, grad_fn=<DivBackward1>)\n",
      "tensor(0.0947, grad_fn=<DivBackward1>)\n",
      "tensor(0.0869, grad_fn=<DivBackward1>)\n",
      "tensor(0.1567, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.1384, grad_fn=<DivBackward1>)\n",
      "tensor(0.0474, grad_fn=<DivBackward1>)\n",
      "tensor(0.0801, grad_fn=<DivBackward1>)\n",
      "tensor(0.0275, grad_fn=<DivBackward1>)\n",
      "tensor(0.0729, grad_fn=<DivBackward1>)\n",
      "tensor(0.1114, grad_fn=<DivBackward1>)\n",
      "tensor(0.0416, grad_fn=<DivBackward1>)\n",
      "tensor(0.0188, grad_fn=<DivBackward1>)\n",
      "tensor(0.0533, grad_fn=<DivBackward1>)\n",
      "tensor(0.0443, grad_fn=<DivBackward1>)\n",
      "tensor(0.1600, grad_fn=<DivBackward1>)\n",
      "tensor(0.0361, grad_fn=<DivBackward1>)\n",
      "tensor(0.1133, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.0334, grad_fn=<DivBackward1>)\n",
      "tensor(0.0297, grad_fn=<DivBackward1>)\n",
      "tensor(0.1557, grad_fn=<DivBackward1>)\n",
      "tensor(0.5688, grad_fn=<DivBackward1>)\n",
      "tensor(0.1210, grad_fn=<DivBackward1>)\n",
      "tensor(0.1420, grad_fn=<DivBackward1>)\n",
      "tensor(0.1186, grad_fn=<DivBackward1>)\n",
      "tensor(0.0607, grad_fn=<DivBackward1>)\n",
      "tensor(0.0097, grad_fn=<DivBackward1>)\n",
      "tensor(0.0909, grad_fn=<DivBackward1>)\n",
      "tensor(0.0216, grad_fn=<DivBackward1>)\n",
      "tensor(0.1035, grad_fn=<DivBackward1>)\n",
      "tensor(0.0513, grad_fn=<DivBackward1>)\n",
      "tensor(0.3495, grad_fn=<DivBackward1>)\n",
      "tensor(0.0124, grad_fn=<DivBackward1>)\n",
      "tensor(0.0746, grad_fn=<DivBackward1>)\n",
      "tensor(0.0636, grad_fn=<DivBackward1>)\n",
      "tensor(0.0054, grad_fn=<DivBackward1>)\n",
      "tensor(0.0236, grad_fn=<DivBackward1>)\n",
      "tensor(0.1027, grad_fn=<DivBackward1>)\n",
      "tensor(0.1159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0257, grad_fn=<DivBackward1>)\n",
      "tensor(0.7219, grad_fn=<DivBackward1>)\n",
      "tensor(0.2069, grad_fn=<DivBackward1>)\n",
      "tensor(0.1463, grad_fn=<DivBackward1>)\n",
      "tensor(0.0137, grad_fn=<DivBackward1>)\n",
      "tensor(0.1824, grad_fn=<DivBackward1>)\n",
      "tensor(0.0553, grad_fn=<DivBackward1>)\n",
      "tensor(0.0362, grad_fn=<DivBackward1>)\n",
      "tensor(0.0967, grad_fn=<DivBackward1>)\n",
      "tensor(0.1514, grad_fn=<DivBackward1>)\n",
      "tensor(0.8298, grad_fn=<DivBackward1>)\n",
      "tensor(0.7854, grad_fn=<DivBackward1>)\n",
      "tensor(0.1102, grad_fn=<DivBackward1>)\n",
      "tensor(0.0442, grad_fn=<DivBackward1>)\n",
      "tensor(0.0472, grad_fn=<DivBackward1>)\n",
      "tensor(0.0513, grad_fn=<DivBackward1>)\n",
      "tensor(0.0475, grad_fn=<DivBackward1>)\n",
      "tensor(0.0669, grad_fn=<DivBackward1>)\n",
      "tensor(0.8657, grad_fn=<DivBackward1>)\n",
      "tensor(0.1683, grad_fn=<DivBackward1>)\n",
      "tensor(0.0142, grad_fn=<DivBackward1>)\n",
      "tensor(0.0965, grad_fn=<DivBackward1>)\n",
      "tensor(0.1391, grad_fn=<DivBackward1>)\n",
      "tensor(0.2932, grad_fn=<DivBackward1>)\n",
      "tensor(0.1044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0497, grad_fn=<DivBackward1>)\n",
      "tensor(0.3415, grad_fn=<DivBackward1>)\n",
      "tensor(0.0635, grad_fn=<DivBackward1>)\n",
      "tensor(0.0480, grad_fn=<DivBackward1>)\n",
      "tensor(0.0390, grad_fn=<DivBackward1>)\n",
      "tensor(0.0983, grad_fn=<DivBackward1>)\n",
      "tensor(0.1069, grad_fn=<DivBackward1>)\n",
      "tensor(0.1459, grad_fn=<DivBackward1>)\n",
      "tensor(0.0441, grad_fn=<DivBackward1>)\n",
      "tensor(0.1043, grad_fn=<DivBackward1>)\n",
      "tensor(0.0421, grad_fn=<DivBackward1>)\n",
      "tensor(0.0766, grad_fn=<DivBackward1>)\n",
      "tensor(0.0289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0703, grad_fn=<DivBackward1>)\n",
      "tensor(0.1060, grad_fn=<DivBackward1>)\n",
      "tensor(0.0366, grad_fn=<DivBackward1>)\n",
      "tensor(0.0190, grad_fn=<DivBackward1>)\n",
      "tensor(0.0491, grad_fn=<DivBackward1>)\n",
      "tensor(0.0376, grad_fn=<DivBackward1>)\n",
      "tensor(0.1580, grad_fn=<DivBackward1>)\n",
      "tensor(0.0339, grad_fn=<DivBackward1>)\n",
      "tensor(0.1105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0215, grad_fn=<DivBackward1>)\n",
      "tensor(0.0324, grad_fn=<DivBackward1>)\n",
      "tensor(0.0271, grad_fn=<DivBackward1>)\n",
      "tensor(0.1280, grad_fn=<DivBackward1>)\n",
      "tensor(0.5064, grad_fn=<DivBackward1>)\n",
      "tensor(0.1057, grad_fn=<DivBackward1>)\n",
      "tensor(0.1888, grad_fn=<DivBackward1>)\n",
      "tensor(0.1016, grad_fn=<DivBackward1>)\n",
      "tensor(0.0859, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.0829, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.1249, grad_fn=<DivBackward1>)\n",
      "tensor(0.0622, grad_fn=<DivBackward1>)\n",
      "tensor(0.2964, grad_fn=<DivBackward1>)\n",
      "tensor(0.0107, grad_fn=<DivBackward1>)\n",
      "tensor(0.1051, grad_fn=<DivBackward1>)\n",
      "tensor(0.0450, grad_fn=<DivBackward1>)\n",
      "tensor(0.0043, grad_fn=<DivBackward1>)\n",
      "tensor(0.0198, grad_fn=<DivBackward1>)\n",
      "tensor(0.1838, grad_fn=<DivBackward1>)\n",
      "tensor(0.0667, grad_fn=<DivBackward1>)\n",
      "tensor(0.0282, grad_fn=<DivBackward1>)\n",
      "tensor(0.6607, grad_fn=<DivBackward1>)\n",
      "tensor(0.2138, grad_fn=<DivBackward1>)\n",
      "tensor(0.1361, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.1690, grad_fn=<DivBackward1>)\n",
      "tensor(0.0563, grad_fn=<DivBackward1>)\n",
      "tensor(0.0354, grad_fn=<DivBackward1>)\n",
      "tensor(0.0953, grad_fn=<DivBackward1>)\n",
      "tensor(0.1383, grad_fn=<DivBackward1>)\n",
      "tensor(0.8414, grad_fn=<DivBackward1>)\n",
      "tensor(0.7396, grad_fn=<DivBackward1>)\n",
      "tensor(0.0815, grad_fn=<DivBackward1>)\n",
      "tensor(0.0476, grad_fn=<DivBackward1>)\n",
      "tensor(0.0387, grad_fn=<DivBackward1>)\n",
      "tensor(0.0555, grad_fn=<DivBackward1>)\n",
      "tensor(0.0475, grad_fn=<DivBackward1>)\n",
      "tensor(0.0716, grad_fn=<DivBackward1>)\n",
      "tensor(0.8799, grad_fn=<DivBackward1>)\n",
      "tensor(0.1655, grad_fn=<DivBackward1>)\n",
      "tensor(0.0135, grad_fn=<DivBackward1>)\n",
      "tensor(0.0696, grad_fn=<DivBackward1>)\n",
      "tensor(0.1560, grad_fn=<DivBackward1>)\n",
      "tensor(0.2927, grad_fn=<DivBackward1>)\n",
      "tensor(0.1053, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0566, grad_fn=<DivBackward1>)\n",
      "tensor(0.2701, grad_fn=<DivBackward1>)\n",
      "tensor(0.0650, grad_fn=<DivBackward1>)\n",
      "tensor(0.0584, grad_fn=<DivBackward1>)\n",
      "tensor(0.0333, grad_fn=<DivBackward1>)\n",
      "tensor(0.0962, grad_fn=<DivBackward1>)\n",
      "tensor(0.0983, grad_fn=<DivBackward1>)\n",
      "tensor(0.1225, grad_fn=<DivBackward1>)\n",
      "tensor(0.0384, grad_fn=<DivBackward1>)\n",
      "tensor(0.1034, grad_fn=<DivBackward1>)\n",
      "tensor(0.0418, grad_fn=<DivBackward1>)\n",
      "tensor(0.0739, grad_fn=<DivBackward1>)\n",
      "tensor(0.0330, grad_fn=<DivBackward1>)\n",
      "tensor(0.0792, grad_fn=<DivBackward1>)\n",
      "tensor(0.0962, grad_fn=<DivBackward1>)\n",
      "tensor(0.0357, grad_fn=<DivBackward1>)\n",
      "tensor(0.0184, grad_fn=<DivBackward1>)\n",
      "tensor(0.0464, grad_fn=<DivBackward1>)\n",
      "tensor(0.0451, grad_fn=<DivBackward1>)\n",
      "tensor(0.1489, grad_fn=<DivBackward1>)\n",
      "tensor(0.0358, grad_fn=<DivBackward1>)\n",
      "tensor(0.1196, grad_fn=<DivBackward1>)\n",
      "tensor(0.0190, grad_fn=<DivBackward1>)\n",
      "tensor(0.0329, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.1092, grad_fn=<DivBackward1>)\n",
      "tensor(0.4070, grad_fn=<DivBackward1>)\n",
      "tensor(0.0814, grad_fn=<DivBackward1>)\n",
      "tensor(0.1897, grad_fn=<DivBackward1>)\n",
      "tensor(0.0673, grad_fn=<DivBackward1>)\n",
      "tensor(0.0604, grad_fn=<DivBackward1>)\n",
      "tensor(0.0075, grad_fn=<DivBackward1>)\n",
      "tensor(0.0890, grad_fn=<DivBackward1>)\n",
      "tensor(0.0171, grad_fn=<DivBackward1>)\n",
      "tensor(0.1108, grad_fn=<DivBackward1>)\n",
      "tensor(0.0709, grad_fn=<DivBackward1>)\n",
      "tensor(0.4421, grad_fn=<DivBackward1>)\n",
      "tensor(0.0134, grad_fn=<DivBackward1>)\n",
      "tensor(0.0629, grad_fn=<DivBackward1>)\n",
      "tensor(0.0423, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0296, grad_fn=<DivBackward1>)\n",
      "tensor(0.0829, grad_fn=<DivBackward1>)\n",
      "tensor(0.1542, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.7732, grad_fn=<DivBackward1>)\n",
      "tensor(0.1329, grad_fn=<DivBackward1>)\n",
      "tensor(0.1093, grad_fn=<DivBackward1>)\n",
      "tensor(0.0094, grad_fn=<DivBackward1>)\n",
      "tensor(0.1783, grad_fn=<DivBackward1>)\n",
      "tensor(0.0423, grad_fn=<DivBackward1>)\n",
      "tensor(0.0361, grad_fn=<DivBackward1>)\n",
      "tensor(0.1311, grad_fn=<DivBackward1>)\n",
      "tensor(0.0943, grad_fn=<DivBackward1>)\n",
      "tensor(0.8210, grad_fn=<DivBackward1>)\n",
      "tensor(0.7430, grad_fn=<DivBackward1>)\n",
      "tensor(0.0799, grad_fn=<DivBackward1>)\n",
      "tensor(0.0421, grad_fn=<DivBackward1>)\n",
      "tensor(0.0349, grad_fn=<DivBackward1>)\n",
      "tensor(0.0604, grad_fn=<DivBackward1>)\n",
      "tensor(0.0359, grad_fn=<DivBackward1>)\n",
      "tensor(0.0564, grad_fn=<DivBackward1>)\n",
      "tensor(0.8778, grad_fn=<DivBackward1>)\n",
      "tensor(0.1128, grad_fn=<DivBackward1>)\n",
      "tensor(0.0112, grad_fn=<DivBackward1>)\n",
      "tensor(0.0887, grad_fn=<DivBackward1>)\n",
      "tensor(0.1288, grad_fn=<DivBackward1>)\n",
      "tensor(0.2835, grad_fn=<DivBackward1>)\n",
      "tensor(0.0858, grad_fn=<DivBackward1>)\n",
      "tensor(0.0249, grad_fn=<DivBackward1>)\n",
      "tensor(0.0484, grad_fn=<DivBackward1>)\n",
      "tensor(0.3166, grad_fn=<DivBackward1>)\n",
      "tensor(0.0502, grad_fn=<DivBackward1>)\n",
      "tensor(0.0722, grad_fn=<DivBackward1>)\n",
      "tensor(0.0357, grad_fn=<DivBackward1>)\n",
      "tensor(0.0884, grad_fn=<DivBackward1>)\n",
      "tensor(0.0688, grad_fn=<DivBackward1>)\n",
      "tensor(0.1155, grad_fn=<DivBackward1>)\n",
      "tensor(0.0347, grad_fn=<DivBackward1>)\n",
      "tensor(0.0830, grad_fn=<DivBackward1>)\n",
      "tensor(0.0383, grad_fn=<DivBackward1>)\n",
      "tensor(0.0511, grad_fn=<DivBackward1>)\n",
      "tensor(0.0286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0729, grad_fn=<DivBackward1>)\n",
      "tensor(0.1223, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0191, grad_fn=<DivBackward1>)\n",
      "tensor(0.0499, grad_fn=<DivBackward1>)\n",
      "tensor(0.0402, grad_fn=<DivBackward1>)\n",
      "tensor(0.1303, grad_fn=<DivBackward1>)\n",
      "tensor(0.0322, grad_fn=<DivBackward1>)\n",
      "tensor(0.0878, grad_fn=<DivBackward1>)\n",
      "tensor(0.0145, grad_fn=<DivBackward1>)\n",
      "tensor(0.0304, grad_fn=<DivBackward1>)\n",
      "tensor(0.0283, grad_fn=<DivBackward1>)\n",
      "tensor(0.1268, grad_fn=<DivBackward1>)\n",
      "tensor(0.3251, grad_fn=<DivBackward1>)\n",
      "tensor(0.1005, grad_fn=<DivBackward1>)\n",
      "tensor(0.2026, grad_fn=<DivBackward1>)\n",
      "tensor(0.1047, grad_fn=<DivBackward1>)\n",
      "tensor(0.0703, grad_fn=<DivBackward1>)\n",
      "tensor(0.0083, grad_fn=<DivBackward1>)\n",
      "tensor(0.0757, grad_fn=<DivBackward1>)\n",
      "tensor(0.0175, grad_fn=<DivBackward1>)\n",
      "tensor(0.1097, grad_fn=<DivBackward1>)\n",
      "tensor(0.0571, grad_fn=<DivBackward1>)\n",
      "tensor(0.4517, grad_fn=<DivBackward1>)\n",
      "tensor(0.0144, grad_fn=<DivBackward1>)\n",
      "tensor(0.0611, grad_fn=<DivBackward1>)\n",
      "tensor(0.0439, grad_fn=<DivBackward1>)\n",
      "tensor(0.0036, grad_fn=<DivBackward1>)\n",
      "tensor(0.0283, grad_fn=<DivBackward1>)\n",
      "tensor(0.0881, grad_fn=<DivBackward1>)\n",
      "tensor(0.1158, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.6858, grad_fn=<DivBackward1>)\n",
      "tensor(0.1632, grad_fn=<DivBackward1>)\n",
      "tensor(0.1031, grad_fn=<DivBackward1>)\n",
      "tensor(0.0092, grad_fn=<DivBackward1>)\n",
      "tensor(0.1882, grad_fn=<DivBackward1>)\n",
      "tensor(0.0440, grad_fn=<DivBackward1>)\n",
      "tensor(0.0273, grad_fn=<DivBackward1>)\n",
      "tensor(0.1195, grad_fn=<DivBackward1>)\n",
      "tensor(0.1274, grad_fn=<DivBackward1>)\n",
      "tensor(0.7948, grad_fn=<DivBackward1>)\n",
      "tensor(0.7613, grad_fn=<DivBackward1>)\n",
      "tensor(0.0806, grad_fn=<DivBackward1>)\n",
      "tensor(0.0506, grad_fn=<DivBackward1>)\n",
      "tensor(0.0341, grad_fn=<DivBackward1>)\n",
      "tensor(0.0541, grad_fn=<DivBackward1>)\n",
      "tensor(0.0390, grad_fn=<DivBackward1>)\n",
      "tensor(0.0642, grad_fn=<DivBackward1>)\n",
      "tensor(0.8868, grad_fn=<DivBackward1>)\n",
      "tensor(0.1528, grad_fn=<DivBackward1>)\n",
      "tensor(0.0109, grad_fn=<DivBackward1>)\n",
      "tensor(0.0656, grad_fn=<DivBackward1>)\n",
      "tensor(0.1147, grad_fn=<DivBackward1>)\n",
      "tensor(0.3598, grad_fn=<DivBackward1>)\n",
      "tensor(0.0912, grad_fn=<DivBackward1>)\n",
      "tensor(0.0292, grad_fn=<DivBackward1>)\n",
      "tensor(0.0570, grad_fn=<DivBackward1>)\n",
      "tensor(0.3376, grad_fn=<DivBackward1>)\n",
      "tensor(0.0610, grad_fn=<DivBackward1>)\n",
      "tensor(0.0571, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0969, grad_fn=<DivBackward1>)\n",
      "tensor(0.0805, grad_fn=<DivBackward1>)\n",
      "tensor(0.1296, grad_fn=<DivBackward1>)\n",
      "tensor(0.0235, grad_fn=<DivBackward1>)\n",
      "tensor(0.1218, grad_fn=<DivBackward1>)\n",
      "tensor(0.0350, grad_fn=<DivBackward1>)\n",
      "tensor(0.0573, grad_fn=<DivBackward1>)\n",
      "tensor(0.0330, grad_fn=<DivBackward1>)\n",
      "tensor(0.0777, grad_fn=<DivBackward1>)\n",
      "tensor(0.1052, grad_fn=<DivBackward1>)\n",
      "tensor(0.0356, grad_fn=<DivBackward1>)\n",
      "tensor(0.0207, grad_fn=<DivBackward1>)\n",
      "tensor(0.0425, grad_fn=<DivBackward1>)\n",
      "tensor(0.0412, grad_fn=<DivBackward1>)\n",
      "tensor(0.1205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0343, grad_fn=<DivBackward1>)\n",
      "tensor(0.0923, grad_fn=<DivBackward1>)\n",
      "tensor(0.0155, grad_fn=<DivBackward1>)\n",
      "tensor(0.0323, grad_fn=<DivBackward1>)\n",
      "tensor(0.0233, grad_fn=<DivBackward1>)\n",
      "tensor(0.0898, grad_fn=<DivBackward1>)\n",
      "tensor(0.2491, grad_fn=<DivBackward1>)\n",
      "tensor(0.0632, grad_fn=<DivBackward1>)\n",
      "tensor(0.1263, grad_fn=<DivBackward1>)\n",
      "tensor(0.0761, grad_fn=<DivBackward1>)\n",
      "tensor(0.0711, grad_fn=<DivBackward1>)\n",
      "tensor(0.0078, grad_fn=<DivBackward1>)\n",
      "tensor(0.0680, grad_fn=<DivBackward1>)\n",
      "tensor(0.0163, grad_fn=<DivBackward1>)\n",
      "tensor(0.0913, grad_fn=<DivBackward1>)\n",
      "tensor(0.0637, grad_fn=<DivBackward1>)\n",
      "tensor(0.3632, grad_fn=<DivBackward1>)\n",
      "tensor(0.0134, grad_fn=<DivBackward1>)\n",
      "tensor(0.0547, grad_fn=<DivBackward1>)\n",
      "tensor(0.0397, grad_fn=<DivBackward1>)\n",
      "tensor(0.0032, grad_fn=<DivBackward1>)\n",
      "tensor(0.0221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0835, grad_fn=<DivBackward1>)\n",
      "tensor(0.0845, grad_fn=<DivBackward1>)\n",
      "tensor(0.0196, grad_fn=<DivBackward1>)\n",
      "tensor(0.6666, grad_fn=<DivBackward1>)\n",
      "tensor(0.1406, grad_fn=<DivBackward1>)\n",
      "tensor(0.0852, grad_fn=<DivBackward1>)\n",
      "tensor(0.0092, grad_fn=<DivBackward1>)\n",
      "tensor(0.2011, grad_fn=<DivBackward1>)\n",
      "tensor(0.0358, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0879, grad_fn=<DivBackward1>)\n",
      "tensor(0.0901, grad_fn=<DivBackward1>)\n",
      "tensor(0.8262, grad_fn=<DivBackward1>)\n",
      "tensor(0.7692, grad_fn=<DivBackward1>)\n",
      "tensor(0.0752, grad_fn=<DivBackward1>)\n",
      "tensor(0.0602, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0498, grad_fn=<DivBackward1>)\n",
      "tensor(0.0351, grad_fn=<DivBackward1>)\n",
      "tensor(0.0535, grad_fn=<DivBackward1>)\n",
      "tensor(0.9220, grad_fn=<DivBackward1>)\n",
      "tensor(0.1241, grad_fn=<DivBackward1>)\n",
      "tensor(0.0093, grad_fn=<DivBackward1>)\n",
      "tensor(0.0472, grad_fn=<DivBackward1>)\n",
      "tensor(0.1130, grad_fn=<DivBackward1>)\n",
      "tensor(0.4165, grad_fn=<DivBackward1>)\n",
      "tensor(0.0755, grad_fn=<DivBackward1>)\n",
      "tensor(0.0286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0437, grad_fn=<DivBackward1>)\n",
      "tensor(0.3455, grad_fn=<DivBackward1>)\n",
      "tensor(0.0568, grad_fn=<DivBackward1>)\n",
      "tensor(0.0552, grad_fn=<DivBackward1>)\n",
      "tensor(0.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.0803, grad_fn=<DivBackward1>)\n",
      "tensor(0.0880, grad_fn=<DivBackward1>)\n",
      "tensor(0.1072, grad_fn=<DivBackward1>)\n",
      "tensor(0.0306, grad_fn=<DivBackward1>)\n",
      "tensor(0.0940, grad_fn=<DivBackward1>)\n",
      "tensor(0.0297, grad_fn=<DivBackward1>)\n",
      "tensor(0.0531, grad_fn=<DivBackward1>)\n",
      "tensor(0.0320, grad_fn=<DivBackward1>)\n",
      "tensor(0.0819, grad_fn=<DivBackward1>)\n",
      "tensor(0.0972, grad_fn=<DivBackward1>)\n",
      "tensor(0.0285, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.0465, grad_fn=<DivBackward1>)\n",
      "tensor(0.0356, grad_fn=<DivBackward1>)\n",
      "tensor(0.1242, grad_fn=<DivBackward1>)\n",
      "tensor(0.0344, grad_fn=<DivBackward1>)\n",
      "tensor(0.0906, grad_fn=<DivBackward1>)\n",
      "tensor(0.0138, grad_fn=<DivBackward1>)\n",
      "tensor(0.0290, grad_fn=<DivBackward1>)\n",
      "tensor(0.0247, grad_fn=<DivBackward1>)\n",
      "tensor(0.0797, grad_fn=<DivBackward1>)\n",
      "tensor(0.1508, grad_fn=<DivBackward1>)\n",
      "tensor(0.0893, grad_fn=<DivBackward1>)\n",
      "tensor(0.1407, grad_fn=<DivBackward1>)\n",
      "tensor(0.0708, grad_fn=<DivBackward1>)\n",
      "tensor(0.0614, grad_fn=<DivBackward1>)\n",
      "tensor(0.0073, grad_fn=<DivBackward1>)\n",
      "tensor(0.0490, grad_fn=<DivBackward1>)\n",
      "tensor(0.0169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0899, grad_fn=<DivBackward1>)\n",
      "tensor(0.0494, grad_fn=<DivBackward1>)\n",
      "tensor(0.4211, grad_fn=<DivBackward1>)\n",
      "tensor(0.0159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0559, grad_fn=<DivBackward1>)\n",
      "tensor(0.0430, grad_fn=<DivBackward1>)\n",
      "tensor(0.0031, grad_fn=<DivBackward1>)\n",
      "tensor(0.0224, grad_fn=<DivBackward1>)\n",
      "tensor(0.0904, grad_fn=<DivBackward1>)\n",
      "tensor(0.0765, grad_fn=<DivBackward1>)\n",
      "tensor(0.0211, grad_fn=<DivBackward1>)\n",
      "tensor(0.6378, grad_fn=<DivBackward1>)\n",
      "tensor(0.1568, grad_fn=<DivBackward1>)\n",
      "tensor(0.0840, grad_fn=<DivBackward1>)\n",
      "tensor(0.0082, grad_fn=<DivBackward1>)\n",
      "tensor(0.2089, grad_fn=<DivBackward1>)\n",
      "tensor(0.0449, grad_fn=<DivBackward1>)\n",
      "tensor(0.0211, grad_fn=<DivBackward1>)\n",
      "tensor(0.0778, grad_fn=<DivBackward1>)\n",
      "tensor(0.0953, grad_fn=<DivBackward1>)\n",
      "tensor(0.7913, grad_fn=<DivBackward1>)\n",
      "tensor(0.7828, grad_fn=<DivBackward1>)\n",
      "tensor(0.0737, grad_fn=<DivBackward1>)\n",
      "tensor(0.0466, grad_fn=<DivBackward1>)\n",
      "tensor(0.0281, grad_fn=<DivBackward1>)\n",
      "tensor(0.0463, grad_fn=<DivBackward1>)\n",
      "tensor(0.0331, grad_fn=<DivBackward1>)\n",
      "tensor(0.0504, grad_fn=<DivBackward1>)\n",
      "tensor(0.9060, grad_fn=<DivBackward1>)\n",
      "tensor(0.1314, grad_fn=<DivBackward1>)\n",
      "tensor(0.0084, grad_fn=<DivBackward1>)\n",
      "tensor(0.0576, grad_fn=<DivBackward1>)\n",
      "tensor(0.1101, grad_fn=<DivBackward1>)\n",
      "tensor(0.4472, grad_fn=<DivBackward1>)\n",
      "tensor(0.0781, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0383, grad_fn=<DivBackward1>)\n",
      "tensor(0.3865, grad_fn=<DivBackward1>)\n",
      "tensor(0.0601, grad_fn=<DivBackward1>)\n",
      "tensor(0.0614, grad_fn=<DivBackward1>)\n",
      "tensor(0.0285, grad_fn=<DivBackward1>)\n",
      "tensor(0.0741, grad_fn=<DivBackward1>)\n",
      "tensor(0.0679, grad_fn=<DivBackward1>)\n",
      "tensor(0.0984, grad_fn=<DivBackward1>)\n",
      "tensor(0.0200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0767, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0687, grad_fn=<DivBackward1>)\n",
      "tensor(0.0410, grad_fn=<DivBackward1>)\n",
      "tensor(0.0746, grad_fn=<DivBackward1>)\n",
      "tensor(0.0923, grad_fn=<DivBackward1>)\n",
      "tensor(0.0340, grad_fn=<DivBackward1>)\n",
      "tensor(0.0212, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.0366, grad_fn=<DivBackward1>)\n",
      "tensor(0.1116, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.0977, grad_fn=<DivBackward1>)\n",
      "tensor(0.0137, grad_fn=<DivBackward1>)\n",
      "tensor(0.0276, grad_fn=<DivBackward1>)\n",
      "tensor(0.0244, grad_fn=<DivBackward1>)\n",
      "tensor(0.0699, grad_fn=<DivBackward1>)\n",
      "tensor(0.1259, grad_fn=<DivBackward1>)\n",
      "tensor(0.0638, grad_fn=<DivBackward1>)\n",
      "tensor(0.0777, grad_fn=<DivBackward1>)\n",
      "tensor(0.0719, grad_fn=<DivBackward1>)\n",
      "tensor(0.0434, grad_fn=<DivBackward1>)\n",
      "tensor(0.0063, grad_fn=<DivBackward1>)\n",
      "tensor(0.0435, grad_fn=<DivBackward1>)\n",
      "tensor(0.0151, grad_fn=<DivBackward1>)\n",
      "tensor(0.0692, grad_fn=<DivBackward1>)\n",
      "tensor(0.0480, grad_fn=<DivBackward1>)\n",
      "tensor(0.4434, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0560, grad_fn=<DivBackward1>)\n",
      "tensor(0.0433, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0902, grad_fn=<DivBackward1>)\n",
      "tensor(0.0731, grad_fn=<DivBackward1>)\n",
      "tensor(0.0161, grad_fn=<DivBackward1>)\n",
      "tensor(0.6016, grad_fn=<DivBackward1>)\n",
      "tensor(0.1479, grad_fn=<DivBackward1>)\n",
      "tensor(0.0576, grad_fn=<DivBackward1>)\n",
      "tensor(0.0086, grad_fn=<DivBackward1>)\n",
      "tensor(0.1943, grad_fn=<DivBackward1>)\n",
      "tensor(0.0423, grad_fn=<DivBackward1>)\n",
      "tensor(0.0225, grad_fn=<DivBackward1>)\n",
      "tensor(0.0553, grad_fn=<DivBackward1>)\n",
      "tensor(0.0749, grad_fn=<DivBackward1>)\n",
      "tensor(0.8055, grad_fn=<DivBackward1>)\n",
      "tensor(0.7571, grad_fn=<DivBackward1>)\n",
      "tensor(0.0742, grad_fn=<DivBackward1>)\n",
      "tensor(0.0415, grad_fn=<DivBackward1>)\n",
      "tensor(0.0270, grad_fn=<DivBackward1>)\n",
      "tensor(0.0426, grad_fn=<DivBackward1>)\n",
      "tensor(0.0288, grad_fn=<DivBackward1>)\n",
      "tensor(0.0464, grad_fn=<DivBackward1>)\n",
      "tensor(0.9420, grad_fn=<DivBackward1>)\n",
      "tensor(0.1023, grad_fn=<DivBackward1>)\n",
      "tensor(0.0082, grad_fn=<DivBackward1>)\n",
      "tensor(0.0464, grad_fn=<DivBackward1>)\n",
      "tensor(0.1015, grad_fn=<DivBackward1>)\n",
      "tensor(0.4714, grad_fn=<DivBackward1>)\n",
      "tensor(0.0732, grad_fn=<DivBackward1>)\n",
      "tensor(0.0324, grad_fn=<DivBackward1>)\n",
      "tensor(0.0333, grad_fn=<DivBackward1>)\n",
      "tensor(0.3662, grad_fn=<DivBackward1>)\n",
      "tensor(0.0492, grad_fn=<DivBackward1>)\n",
      "tensor(0.0716, grad_fn=<DivBackward1>)\n",
      "tensor(0.0251, grad_fn=<DivBackward1>)\n",
      "tensor(0.0632, grad_fn=<DivBackward1>)\n",
      "tensor(0.0662, grad_fn=<DivBackward1>)\n",
      "tensor(0.0909, grad_fn=<DivBackward1>)\n",
      "tensor(0.0254, grad_fn=<DivBackward1>)\n",
      "tensor(0.0580, grad_fn=<DivBackward1>)\n",
      "tensor(0.0286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0708, grad_fn=<DivBackward1>)\n",
      "tensor(0.0446, grad_fn=<DivBackward1>)\n",
      "tensor(0.0740, grad_fn=<DivBackward1>)\n",
      "tensor(0.0740, grad_fn=<DivBackward1>)\n",
      "tensor(0.0284, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.0436, grad_fn=<DivBackward1>)\n",
      "tensor(0.0297, grad_fn=<DivBackward1>)\n",
      "tensor(0.0983, grad_fn=<DivBackward1>)\n",
      "tensor(0.0381, grad_fn=<DivBackward1>)\n",
      "tensor(0.0963, grad_fn=<DivBackward1>)\n",
      "tensor(0.0120, grad_fn=<DivBackward1>)\n",
      "tensor(0.0282, grad_fn=<DivBackward1>)\n",
      "tensor(0.0236, grad_fn=<DivBackward1>)\n",
      "tensor(0.0568, grad_fn=<DivBackward1>)\n",
      "tensor(0.1581, grad_fn=<DivBackward1>)\n",
      "tensor(0.0664, grad_fn=<DivBackward1>)\n",
      "tensor(0.1036, grad_fn=<DivBackward1>)\n",
      "tensor(0.0546, grad_fn=<DivBackward1>)\n",
      "tensor(0.0431, grad_fn=<DivBackward1>)\n",
      "tensor(0.0059, grad_fn=<DivBackward1>)\n",
      "tensor(0.0457, grad_fn=<DivBackward1>)\n",
      "tensor(0.0148, grad_fn=<DivBackward1>)\n",
      "tensor(0.0750, grad_fn=<DivBackward1>)\n",
      "tensor(0.0517, grad_fn=<DivBackward1>)\n",
      "tensor(0.5308, grad_fn=<DivBackward1>)\n",
      "tensor(0.0170, grad_fn=<DivBackward1>)\n",
      "tensor(0.0494, grad_fn=<DivBackward1>)\n",
      "tensor(0.0374, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0152, grad_fn=<DivBackward1>)\n",
      "tensor(0.0791, grad_fn=<DivBackward1>)\n",
      "tensor(0.1105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0176, grad_fn=<DivBackward1>)\n",
      "tensor(0.6320, grad_fn=<DivBackward1>)\n",
      "tensor(0.1164, grad_fn=<DivBackward1>)\n",
      "tensor(0.0569, grad_fn=<DivBackward1>)\n",
      "tensor(0.0071, grad_fn=<DivBackward1>)\n",
      "tensor(0.2159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0372, grad_fn=<DivBackward1>)\n",
      "tensor(0.0201, grad_fn=<DivBackward1>)\n",
      "tensor(0.0563, grad_fn=<DivBackward1>)\n",
      "tensor(0.0673, grad_fn=<DivBackward1>)\n",
      "tensor(0.7898, grad_fn=<DivBackward1>)\n",
      "tensor(0.7289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0535, grad_fn=<DivBackward1>)\n",
      "tensor(0.0388, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0488, grad_fn=<DivBackward1>)\n",
      "tensor(0.0258, grad_fn=<DivBackward1>)\n",
      "tensor(0.0414, grad_fn=<DivBackward1>)\n",
      "tensor(0.9202, grad_fn=<DivBackward1>)\n",
      "tensor(0.0923, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.0559, grad_fn=<DivBackward1>)\n",
      "tensor(0.0935, grad_fn=<DivBackward1>)\n",
      "tensor(0.4408, grad_fn=<DivBackward1>)\n",
      "tensor(0.0610, grad_fn=<DivBackward1>)\n",
      "tensor(0.0353, grad_fn=<DivBackward1>)\n",
      "tensor(0.0357, grad_fn=<DivBackward1>)\n",
      "tensor(0.3853, grad_fn=<DivBackward1>)\n",
      "tensor(0.0428, grad_fn=<DivBackward1>)\n",
      "tensor(0.0604, grad_fn=<DivBackward1>)\n",
      "tensor(0.0275, grad_fn=<DivBackward1>)\n",
      "tensor(0.0702, grad_fn=<DivBackward1>)\n",
      "tensor(0.0569, grad_fn=<DivBackward1>)\n",
      "tensor(0.0801, grad_fn=<DivBackward1>)\n",
      "tensor(0.0224, grad_fn=<DivBackward1>)\n",
      "tensor(0.0760, grad_fn=<DivBackward1>)\n",
      "tensor(0.0269, grad_fn=<DivBackward1>)\n",
      "tensor(0.0515, grad_fn=<DivBackward1>)\n",
      "tensor(0.0303, grad_fn=<DivBackward1>)\n",
      "tensor(0.0710, grad_fn=<DivBackward1>)\n",
      "tensor(0.1001, grad_fn=<DivBackward1>)\n",
      "tensor(0.0363, grad_fn=<DivBackward1>)\n",
      "tensor(0.0197, grad_fn=<DivBackward1>)\n",
      "tensor(0.0405, grad_fn=<DivBackward1>)\n",
      "tensor(0.0323, grad_fn=<DivBackward1>)\n",
      "tensor(0.0846, grad_fn=<DivBackward1>)\n",
      "tensor(0.0376, grad_fn=<DivBackward1>)\n",
      "tensor(0.0689, grad_fn=<DivBackward1>)\n",
      "tensor(0.0116, grad_fn=<DivBackward1>)\n",
      "tensor(0.0205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0248, grad_fn=<DivBackward1>)\n",
      "tensor(0.0598, grad_fn=<DivBackward1>)\n",
      "tensor(0.1279, grad_fn=<DivBackward1>)\n",
      "tensor(0.0710, grad_fn=<DivBackward1>)\n",
      "tensor(0.1008, grad_fn=<DivBackward1>)\n",
      "tensor(0.0659, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.0062, grad_fn=<DivBackward1>)\n",
      "tensor(0.0384, grad_fn=<DivBackward1>)\n",
      "tensor(0.0135, grad_fn=<DivBackward1>)\n",
      "tensor(0.0658, grad_fn=<DivBackward1>)\n",
      "tensor(0.0393, grad_fn=<DivBackward1>)\n",
      "tensor(0.5434, grad_fn=<DivBackward1>)\n",
      "tensor(0.0166, grad_fn=<DivBackward1>)\n",
      "tensor(0.0583, grad_fn=<DivBackward1>)\n",
      "tensor(0.0385, grad_fn=<DivBackward1>)\n",
      "tensor(0.0027, grad_fn=<DivBackward1>)\n",
      "tensor(0.0155, grad_fn=<DivBackward1>)\n",
      "tensor(0.0841, grad_fn=<DivBackward1>)\n",
      "tensor(0.0747, grad_fn=<DivBackward1>)\n",
      "tensor(0.0171, grad_fn=<DivBackward1>)\n",
      "tensor(0.6077, grad_fn=<DivBackward1>)\n",
      "tensor(0.1206, grad_fn=<DivBackward1>)\n",
      "tensor(0.0495, grad_fn=<DivBackward1>)\n",
      "tensor(0.0066, grad_fn=<DivBackward1>)\n",
      "tensor(0.1584, grad_fn=<DivBackward1>)\n",
      "tensor(0.0341, grad_fn=<DivBackward1>)\n",
      "tensor(0.0187, grad_fn=<DivBackward1>)\n",
      "tensor(0.0577, grad_fn=<DivBackward1>)\n",
      "tensor(0.0790, grad_fn=<DivBackward1>)\n",
      "tensor(0.7822, grad_fn=<DivBackward1>)\n",
      "tensor(0.7092, grad_fn=<DivBackward1>)\n",
      "tensor(0.0515, grad_fn=<DivBackward1>)\n",
      "tensor(0.0379, grad_fn=<DivBackward1>)\n",
      "tensor(0.0230, grad_fn=<DivBackward1>)\n",
      "tensor(0.0438, grad_fn=<DivBackward1>)\n",
      "tensor(0.0277, grad_fn=<DivBackward1>)\n",
      "tensor(0.0524, grad_fn=<DivBackward1>)\n",
      "tensor(0.9419, grad_fn=<DivBackward1>)\n",
      "tensor(0.0951, grad_fn=<DivBackward1>)\n",
      "tensor(0.0078, grad_fn=<DivBackward1>)\n",
      "tensor(0.0496, grad_fn=<DivBackward1>)\n",
      "tensor(0.0779, grad_fn=<DivBackward1>)\n",
      "tensor(0.5169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0820, grad_fn=<DivBackward1>)\n",
      "tensor(0.0379, grad_fn=<DivBackward1>)\n",
      "tensor(0.0318, grad_fn=<DivBackward1>)\n",
      "tensor(0.3249, grad_fn=<DivBackward1>)\n",
      "tensor(0.0580, grad_fn=<DivBackward1>)\n",
      "tensor(0.0692, grad_fn=<DivBackward1>)\n",
      "tensor(0.0226, grad_fn=<DivBackward1>)\n",
      "tensor(0.0592, grad_fn=<DivBackward1>)\n",
      "tensor(0.0566, grad_fn=<DivBackward1>)\n",
      "tensor(0.0789, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0657, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0463, grad_fn=<DivBackward1>)\n",
      "tensor(0.0315, grad_fn=<DivBackward1>)\n",
      "tensor(0.0762, grad_fn=<DivBackward1>)\n",
      "tensor(0.0748, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0257, grad_fn=<DivBackward1>)\n",
      "tensor(0.0374, grad_fn=<DivBackward1>)\n",
      "tensor(0.0290, grad_fn=<DivBackward1>)\n",
      "tensor(0.0849, grad_fn=<DivBackward1>)\n",
      "tensor(0.0402, grad_fn=<DivBackward1>)\n",
      "tensor(0.0761, grad_fn=<DivBackward1>)\n",
      "tensor(0.0118, grad_fn=<DivBackward1>)\n",
      "tensor(0.0237, grad_fn=<DivBackward1>)\n",
      "tensor(0.0226, grad_fn=<DivBackward1>)\n",
      "tensor(0.0524, grad_fn=<DivBackward1>)\n",
      "tensor(0.0831, grad_fn=<DivBackward1>)\n",
      "tensor(0.0648, grad_fn=<DivBackward1>)\n",
      "tensor(0.0670, grad_fn=<DivBackward1>)\n",
      "tensor(0.0566, grad_fn=<DivBackward1>)\n",
      "tensor(0.0388, grad_fn=<DivBackward1>)\n",
      "tensor(0.0057, grad_fn=<DivBackward1>)\n",
      "tensor(0.0366, grad_fn=<DivBackward1>)\n",
      "tensor(0.0136, grad_fn=<DivBackward1>)\n",
      "tensor(0.0587, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.5308, grad_fn=<DivBackward1>)\n",
      "tensor(0.0186, grad_fn=<DivBackward1>)\n",
      "tensor(0.0523, grad_fn=<DivBackward1>)\n",
      "tensor(0.0394, grad_fn=<DivBackward1>)\n",
      "tensor(0.0025, grad_fn=<DivBackward1>)\n",
      "tensor(0.0136, grad_fn=<DivBackward1>)\n",
      "tensor(0.0795, grad_fn=<DivBackward1>)\n",
      "tensor(0.0702, grad_fn=<DivBackward1>)\n",
      "tensor(0.0137, grad_fn=<DivBackward1>)\n",
      "tensor(0.5379, grad_fn=<DivBackward1>)\n",
      "tensor(0.1441, grad_fn=<DivBackward1>)\n",
      "tensor(0.0493, grad_fn=<DivBackward1>)\n",
      "tensor(0.0073, grad_fn=<DivBackward1>)\n",
      "tensor(0.2319, grad_fn=<DivBackward1>)\n",
      "tensor(0.0412, grad_fn=<DivBackward1>)\n",
      "tensor(0.0153, grad_fn=<DivBackward1>)\n",
      "tensor(0.0415, grad_fn=<DivBackward1>)\n",
      "tensor(0.0767, grad_fn=<DivBackward1>)\n",
      "tensor(0.7719, grad_fn=<DivBackward1>)\n",
      "tensor(0.7605, grad_fn=<DivBackward1>)\n",
      "tensor(0.0564, grad_fn=<DivBackward1>)\n",
      "tensor(0.0362, grad_fn=<DivBackward1>)\n",
      "tensor(0.0211, grad_fn=<DivBackward1>)\n",
      "tensor(0.0432, grad_fn=<DivBackward1>)\n",
      "tensor(0.0252, grad_fn=<DivBackward1>)\n",
      "tensor(0.0432, grad_fn=<DivBackward1>)\n",
      "tensor(0.9424, grad_fn=<DivBackward1>)\n",
      "tensor(0.0866, grad_fn=<DivBackward1>)\n",
      "tensor(0.0065, grad_fn=<DivBackward1>)\n",
      "tensor(0.0432, grad_fn=<DivBackward1>)\n",
      "tensor(0.0843, grad_fn=<DivBackward1>)\n",
      "tensor(0.5671, grad_fn=<DivBackward1>)\n",
      "tensor(0.0671, grad_fn=<DivBackward1>)\n",
      "tensor(0.0420, grad_fn=<DivBackward1>)\n",
      "tensor(0.0349, grad_fn=<DivBackward1>)\n",
      "tensor(0.3780, grad_fn=<DivBackward1>)\n",
      "tensor(0.0435, grad_fn=<DivBackward1>)\n",
      "tensor(0.0585, grad_fn=<DivBackward1>)\n",
      "tensor(0.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.0531, grad_fn=<DivBackward1>)\n",
      "tensor(0.0457, grad_fn=<DivBackward1>)\n",
      "tensor(0.0648, grad_fn=<DivBackward1>)\n",
      "tensor(0.0247, grad_fn=<DivBackward1>)\n",
      "tensor(0.0557, grad_fn=<DivBackward1>)\n",
      "tensor(0.0258, grad_fn=<DivBackward1>)\n",
      "tensor(0.0638, grad_fn=<DivBackward1>)\n",
      "tensor(0.0421, grad_fn=<DivBackward1>)\n",
      "tensor(0.0786, grad_fn=<DivBackward1>)\n",
      "tensor(0.0667, grad_fn=<DivBackward1>)\n",
      "tensor(0.0273, grad_fn=<DivBackward1>)\n",
      "tensor(0.0221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0371, grad_fn=<DivBackward1>)\n",
      "tensor(0.0226, grad_fn=<DivBackward1>)\n",
      "tensor(0.0640, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.0699, grad_fn=<DivBackward1>)\n",
      "tensor(0.0108, grad_fn=<DivBackward1>)\n",
      "tensor(0.0225, grad_fn=<DivBackward1>)\n",
      "tensor(0.0205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0478, grad_fn=<DivBackward1>)\n",
      "tensor(0.0980, grad_fn=<DivBackward1>)\n",
      "tensor(0.0600, grad_fn=<DivBackward1>)\n",
      "tensor(0.0810, grad_fn=<DivBackward1>)\n",
      "tensor(0.0475, grad_fn=<DivBackward1>)\n",
      "tensor(0.0365, grad_fn=<DivBackward1>)\n",
      "tensor(0.0053, grad_fn=<DivBackward1>)\n",
      "tensor(0.0353, grad_fn=<DivBackward1>)\n",
      "tensor(0.0133, grad_fn=<DivBackward1>)\n",
      "tensor(0.0652, grad_fn=<DivBackward1>)\n",
      "tensor(0.0363, grad_fn=<DivBackward1>)\n",
      "tensor(0.5603, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.0413, grad_fn=<DivBackward1>)\n",
      "tensor(0.0330, grad_fn=<DivBackward1>)\n",
      "tensor(0.0026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0138, grad_fn=<DivBackward1>)\n",
      "tensor(0.0700, grad_fn=<DivBackward1>)\n",
      "tensor(0.0896, grad_fn=<DivBackward1>)\n",
      "tensor(0.0147, grad_fn=<DivBackward1>)\n",
      "tensor(0.5630, grad_fn=<DivBackward1>)\n",
      "tensor(0.1030, grad_fn=<DivBackward1>)\n",
      "tensor(0.0482, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.2325, grad_fn=<DivBackward1>)\n",
      "tensor(0.0336, grad_fn=<DivBackward1>)\n",
      "tensor(0.0163, grad_fn=<DivBackward1>)\n",
      "tensor(0.0378, grad_fn=<DivBackward1>)\n",
      "tensor(0.0606, grad_fn=<DivBackward1>)\n",
      "tensor(0.7742, grad_fn=<DivBackward1>)\n",
      "tensor(0.7247, grad_fn=<DivBackward1>)\n",
      "tensor(0.0547, grad_fn=<DivBackward1>)\n",
      "tensor(0.0307, grad_fn=<DivBackward1>)\n",
      "tensor(0.0203, grad_fn=<DivBackward1>)\n",
      "tensor(0.0432, grad_fn=<DivBackward1>)\n",
      "tensor(0.0220, grad_fn=<DivBackward1>)\n",
      "tensor(0.0384, grad_fn=<DivBackward1>)\n",
      "tensor(0.9132, grad_fn=<DivBackward1>)\n",
      "tensor(0.0904, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.0453, grad_fn=<DivBackward1>)\n",
      "tensor(0.0843, grad_fn=<DivBackward1>)\n",
      "tensor(0.5912, grad_fn=<DivBackward1>)\n",
      "tensor(0.0599, grad_fn=<DivBackward1>)\n",
      "tensor(0.0406, grad_fn=<DivBackward1>)\n",
      "tensor(0.0354, grad_fn=<DivBackward1>)\n",
      "tensor(0.3720, grad_fn=<DivBackward1>)\n",
      "tensor(0.0400, grad_fn=<DivBackward1>)\n",
      "tensor(0.0453, grad_fn=<DivBackward1>)\n",
      "tensor(0.0284, grad_fn=<DivBackward1>)\n",
      "tensor(0.0539, grad_fn=<DivBackward1>)\n",
      "tensor(0.0478, grad_fn=<DivBackward1>)\n",
      "tensor(0.0740, grad_fn=<DivBackward1>)\n",
      "tensor(0.0278, grad_fn=<DivBackward1>)\n",
      "tensor(0.0549, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0466, grad_fn=<DivBackward1>)\n",
      "tensor(0.0279, grad_fn=<DivBackward1>)\n",
      "tensor(0.0774, grad_fn=<DivBackward1>)\n",
      "tensor(0.0717, grad_fn=<DivBackward1>)\n",
      "tensor(0.0283, grad_fn=<DivBackward1>)\n",
      "tensor(0.0225, grad_fn=<DivBackward1>)\n",
      "tensor(0.0394, grad_fn=<DivBackward1>)\n",
      "tensor(0.0212, grad_fn=<DivBackward1>)\n",
      "tensor(0.0601, grad_fn=<DivBackward1>)\n",
      "tensor(0.0388, grad_fn=<DivBackward1>)\n",
      "tensor(0.0581, grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.0219, grad_fn=<DivBackward1>)\n",
      "tensor(0.0492, grad_fn=<DivBackward1>)\n",
      "tensor(0.0761, grad_fn=<DivBackward1>)\n",
      "tensor(0.0694, grad_fn=<DivBackward1>)\n",
      "tensor(0.0705, grad_fn=<DivBackward1>)\n",
      "tensor(0.0458, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0051, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0141, grad_fn=<DivBackward1>)\n",
      "tensor(0.0572, grad_fn=<DivBackward1>)\n",
      "tensor(0.0327, grad_fn=<DivBackward1>)\n",
      "tensor(0.6177, grad_fn=<DivBackward1>)\n",
      "tensor(0.0201, grad_fn=<DivBackward1>)\n",
      "tensor(0.0504, grad_fn=<DivBackward1>)\n",
      "tensor(0.0312, grad_fn=<DivBackward1>)\n",
      "tensor(0.0025, grad_fn=<DivBackward1>)\n",
      "tensor(0.0120, grad_fn=<DivBackward1>)\n",
      "tensor(0.0828, grad_fn=<DivBackward1>)\n",
      "tensor(0.0658, grad_fn=<DivBackward1>)\n",
      "tensor(0.0135, grad_fn=<DivBackward1>)\n",
      "tensor(0.5166, grad_fn=<DivBackward1>)\n",
      "tensor(0.1284, grad_fn=<DivBackward1>)\n",
      "tensor(0.0421, grad_fn=<DivBackward1>)\n",
      "tensor(0.0065, grad_fn=<DivBackward1>)\n",
      "tensor(0.1953, grad_fn=<DivBackward1>)\n",
      "tensor(0.0318, grad_fn=<DivBackward1>)\n",
      "tensor(0.0131, grad_fn=<DivBackward1>)\n",
      "tensor(0.0387, grad_fn=<DivBackward1>)\n",
      "tensor(0.0776, grad_fn=<DivBackward1>)\n",
      "tensor(0.7556, grad_fn=<DivBackward1>)\n",
      "tensor(0.7247, grad_fn=<DivBackward1>)\n",
      "tensor(0.0424, grad_fn=<DivBackward1>)\n",
      "tensor(0.0338, grad_fn=<DivBackward1>)\n",
      "tensor(0.0170, grad_fn=<DivBackward1>)\n",
      "tensor(0.0402, grad_fn=<DivBackward1>)\n",
      "tensor(0.0248, grad_fn=<DivBackward1>)\n",
      "tensor(0.0548, grad_fn=<DivBackward1>)\n",
      "tensor(0.9573, grad_fn=<DivBackward1>)\n",
      "tensor(0.0772, grad_fn=<DivBackward1>)\n",
      "tensor(0.0059, grad_fn=<DivBackward1>)\n",
      "tensor(0.0419, grad_fn=<DivBackward1>)\n",
      "tensor(0.0764, grad_fn=<DivBackward1>)\n",
      "tensor(0.5235, grad_fn=<DivBackward1>)\n",
      "tensor(0.0757, grad_fn=<DivBackward1>)\n",
      "tensor(0.0481, grad_fn=<DivBackward1>)\n",
      "tensor(0.0423, grad_fn=<DivBackward1>)\n",
      "tensor(0.3289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0570, grad_fn=<DivBackward1>)\n",
      "tensor(0.0535, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.0448, grad_fn=<DivBackward1>)\n",
      "tensor(0.0444, grad_fn=<DivBackward1>)\n",
      "tensor(0.0862, grad_fn=<DivBackward1>)\n",
      "tensor(0.0211, grad_fn=<DivBackward1>)\n",
      "tensor(0.0534, grad_fn=<DivBackward1>)\n",
      "tensor(0.0212, grad_fn=<DivBackward1>)\n",
      "tensor(0.0458, grad_fn=<DivBackward1>)\n",
      "tensor(0.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.0991, grad_fn=<DivBackward1>)\n",
      "tensor(0.0573, grad_fn=<DivBackward1>)\n",
      "tensor(0.0252, grad_fn=<DivBackward1>)\n",
      "tensor(0.0241, grad_fn=<DivBackward1>)\n",
      "tensor(0.0381, grad_fn=<DivBackward1>)\n",
      "tensor(0.0261, grad_fn=<DivBackward1>)\n",
      "tensor(0.0618, grad_fn=<DivBackward1>)\n",
      "tensor(0.0439, grad_fn=<DivBackward1>)\n",
      "tensor(0.0677, grad_fn=<DivBackward1>)\n",
      "tensor(0.0099, grad_fn=<DivBackward1>)\n",
      "tensor(0.0221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0454, grad_fn=<DivBackward1>)\n",
      "tensor(0.0821, grad_fn=<DivBackward1>)\n",
      "tensor(0.0490, grad_fn=<DivBackward1>)\n",
      "tensor(0.0552, grad_fn=<DivBackward1>)\n",
      "tensor(0.0464, grad_fn=<DivBackward1>)\n",
      "tensor(0.0301, grad_fn=<DivBackward1>)\n",
      "tensor(0.0047, grad_fn=<DivBackward1>)\n",
      "tensor(0.0365, grad_fn=<DivBackward1>)\n",
      "tensor(0.0114, grad_fn=<DivBackward1>)\n",
      "tensor(0.0528, grad_fn=<DivBackward1>)\n",
      "tensor(0.0331, grad_fn=<DivBackward1>)\n",
      "tensor(0.5984, grad_fn=<DivBackward1>)\n",
      "tensor(0.0181, grad_fn=<DivBackward1>)\n",
      "tensor(0.0462, grad_fn=<DivBackward1>)\n",
      "tensor(0.0270, grad_fn=<DivBackward1>)\n",
      "tensor(0.0024, grad_fn=<DivBackward1>)\n",
      "tensor(0.0108, grad_fn=<DivBackward1>)\n",
      "tensor(0.0837, grad_fn=<DivBackward1>)\n",
      "tensor(0.0721, grad_fn=<DivBackward1>)\n",
      "tensor(0.0133, grad_fn=<DivBackward1>)\n",
      "tensor(0.4873, grad_fn=<DivBackward1>)\n",
      "tensor(0.1394, grad_fn=<DivBackward1>)\n",
      "tensor(0.0354, grad_fn=<DivBackward1>)\n",
      "tensor(0.0065, grad_fn=<DivBackward1>)\n",
      "tensor(0.2617, grad_fn=<DivBackward1>)\n",
      "tensor(0.0384, grad_fn=<DivBackward1>)\n",
      "tensor(0.0130, grad_fn=<DivBackward1>)\n",
      "tensor(0.0312, grad_fn=<DivBackward1>)\n",
      "tensor(0.0720, grad_fn=<DivBackward1>)\n",
      "tensor(0.7215, grad_fn=<DivBackward1>)\n",
      "tensor(0.7551, grad_fn=<DivBackward1>)\n",
      "tensor(0.0568, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0188, grad_fn=<DivBackward1>)\n",
      "tensor(0.0407, grad_fn=<DivBackward1>)\n",
      "tensor(0.0222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.9316, grad_fn=<DivBackward1>)\n",
      "tensor(0.0873, grad_fn=<DivBackward1>)\n",
      "tensor(0.0061, grad_fn=<DivBackward1>)\n",
      "tensor(0.0394, grad_fn=<DivBackward1>)\n",
      "tensor(0.0741, grad_fn=<DivBackward1>)\n",
      "tensor(0.6072, grad_fn=<DivBackward1>)\n",
      "tensor(0.0599, grad_fn=<DivBackward1>)\n",
      "tensor(0.0597, grad_fn=<DivBackward1>)\n",
      "tensor(0.0404, grad_fn=<DivBackward1>)\n",
      "tensor(0.3610, grad_fn=<DivBackward1>)\n",
      "tensor(0.0545, grad_fn=<DivBackward1>)\n",
      "tensor(0.0507, grad_fn=<DivBackward1>)\n",
      "tensor(0.0169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0571, grad_fn=<DivBackward1>)\n",
      "tensor(0.0364, grad_fn=<DivBackward1>)\n",
      "tensor(0.0579, grad_fn=<DivBackward1>)\n",
      "tensor(0.0229, grad_fn=<DivBackward1>)\n",
      "tensor(0.0657, grad_fn=<DivBackward1>)\n",
      "tensor(0.0224, grad_fn=<DivBackward1>)\n",
      "tensor(0.0561, grad_fn=<DivBackward1>)\n",
      "tensor(0.0258, grad_fn=<DivBackward1>)\n",
      "tensor(0.0958, grad_fn=<DivBackward1>)\n",
      "tensor(0.0606, grad_fn=<DivBackward1>)\n",
      "tensor(0.0309, grad_fn=<DivBackward1>)\n",
      "tensor(0.0176, grad_fn=<DivBackward1>)\n",
      "tensor(0.0346, grad_fn=<DivBackward1>)\n",
      "tensor(0.0242, grad_fn=<DivBackward1>)\n",
      "tensor(0.0605, grad_fn=<DivBackward1>)\n",
      "tensor(0.0413, grad_fn=<DivBackward1>)\n",
      "tensor(0.0612, grad_fn=<DivBackward1>)\n",
      "tensor(0.0103, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.0192, grad_fn=<DivBackward1>)\n",
      "tensor(0.0415, grad_fn=<DivBackward1>)\n",
      "tensor(0.0809, grad_fn=<DivBackward1>)\n",
      "tensor(0.0639, grad_fn=<DivBackward1>)\n",
      "tensor(0.0569, grad_fn=<DivBackward1>)\n",
      "tensor(0.0405, grad_fn=<DivBackward1>)\n",
      "tensor(0.0302, grad_fn=<DivBackward1>)\n",
      "tensor(0.0050, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0495, grad_fn=<DivBackward1>)\n",
      "tensor(0.0307, grad_fn=<DivBackward1>)\n",
      "tensor(0.6064, grad_fn=<DivBackward1>)\n",
      "tensor(0.0180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0419, grad_fn=<DivBackward1>)\n",
      "tensor(0.0278, grad_fn=<DivBackward1>)\n",
      "tensor(0.0024, grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, grad_fn=<DivBackward1>)\n",
      "tensor(0.0865, grad_fn=<DivBackward1>)\n",
      "tensor(0.0547, grad_fn=<DivBackward1>)\n",
      "tensor(0.0115, grad_fn=<DivBackward1>)\n",
      "tensor(0.3953, grad_fn=<DivBackward1>)\n",
      "tensor(0.1436, grad_fn=<DivBackward1>)\n",
      "tensor(0.0306, grad_fn=<DivBackward1>)\n",
      "tensor(0.0052, grad_fn=<DivBackward1>)\n",
      "tensor(0.2105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0363, grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, grad_fn=<DivBackward1>)\n",
      "tensor(0.0335, grad_fn=<DivBackward1>)\n",
      "tensor(0.0791, grad_fn=<DivBackward1>)\n",
      "tensor(0.7203, grad_fn=<DivBackward1>)\n",
      "tensor(0.7711, grad_fn=<DivBackward1>)\n",
      "tensor(0.0521, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0417, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.0349, grad_fn=<DivBackward1>)\n",
      "tensor(0.9326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0769, grad_fn=<DivBackward1>)\n",
      "tensor(0.0061, grad_fn=<DivBackward1>)\n",
      "tensor(0.0385, grad_fn=<DivBackward1>)\n",
      "tensor(0.0739, grad_fn=<DivBackward1>)\n",
      "tensor(0.6019, grad_fn=<DivBackward1>)\n",
      "tensor(0.0550, grad_fn=<DivBackward1>)\n",
      "tensor(0.0689, grad_fn=<DivBackward1>)\n",
      "tensor(0.0370, grad_fn=<DivBackward1>)\n",
      "tensor(0.3594, grad_fn=<DivBackward1>)\n",
      "tensor(0.0444, grad_fn=<DivBackward1>)\n",
      "tensor(0.0608, grad_fn=<DivBackward1>)\n",
      "tensor(0.0180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0494, grad_fn=<DivBackward1>)\n",
      "tensor(0.0378, grad_fn=<DivBackward1>)\n",
      "tensor(0.0717, grad_fn=<DivBackward1>)\n",
      "tensor(0.0256, grad_fn=<DivBackward1>)\n",
      "tensor(0.0628, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.0659, grad_fn=<DivBackward1>)\n",
      "tensor(0.0332, grad_fn=<DivBackward1>)\n",
      "tensor(0.1106, grad_fn=<DivBackward1>)\n",
      "tensor(0.0553, grad_fn=<DivBackward1>)\n",
      "tensor(0.0201, grad_fn=<DivBackward1>)\n",
      "tensor(0.0174, grad_fn=<DivBackward1>)\n",
      "tensor(0.0368, grad_fn=<DivBackward1>)\n",
      "tensor(0.0269, grad_fn=<DivBackward1>)\n",
      "tensor(0.0583, grad_fn=<DivBackward1>)\n",
      "tensor(0.0383, grad_fn=<DivBackward1>)\n",
      "tensor(0.0622, grad_fn=<DivBackward1>)\n",
      "tensor(0.0093, grad_fn=<DivBackward1>)\n",
      "tensor(0.0202, grad_fn=<DivBackward1>)\n",
      "tensor(0.0194, grad_fn=<DivBackward1>)\n",
      "tensor(0.0336, grad_fn=<DivBackward1>)\n",
      "tensor(0.0747, grad_fn=<DivBackward1>)\n",
      "tensor(0.0500, grad_fn=<DivBackward1>)\n",
      "tensor(0.0515, grad_fn=<DivBackward1>)\n",
      "tensor(0.0376, grad_fn=<DivBackward1>)\n",
      "tensor(0.0255, grad_fn=<DivBackward1>)\n",
      "tensor(0.0050, grad_fn=<DivBackward1>)\n",
      "tensor(0.0301, grad_fn=<DivBackward1>)\n",
      "tensor(0.0114, grad_fn=<DivBackward1>)\n",
      "tensor(0.0488, grad_fn=<DivBackward1>)\n",
      "tensor(0.0281, grad_fn=<DivBackward1>)\n",
      "tensor(0.5197, grad_fn=<DivBackward1>)\n",
      "tensor(0.0162, grad_fn=<DivBackward1>)\n",
      "tensor(0.0397, grad_fn=<DivBackward1>)\n",
      "tensor(0.0278, grad_fn=<DivBackward1>)\n",
      "tensor(0.0023, grad_fn=<DivBackward1>)\n",
      "tensor(0.0096, grad_fn=<DivBackward1>)\n",
      "tensor(0.0655, grad_fn=<DivBackward1>)\n",
      "tensor(0.0903, grad_fn=<DivBackward1>)\n",
      "tensor(0.0121, grad_fn=<DivBackward1>)\n",
      "tensor(0.4465, grad_fn=<DivBackward1>)\n",
      "tensor(0.1420, grad_fn=<DivBackward1>)\n",
      "tensor(0.0312, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.2573, grad_fn=<DivBackward1>)\n",
      "tensor(0.0345, grad_fn=<DivBackward1>)\n",
      "tensor(0.0113, grad_fn=<DivBackward1>)\n",
      "tensor(0.0315, grad_fn=<DivBackward1>)\n",
      "tensor(0.0680, grad_fn=<DivBackward1>)\n",
      "tensor(0.7025, grad_fn=<DivBackward1>)\n",
      "tensor(0.7666, grad_fn=<DivBackward1>)\n",
      "tensor(0.0586, grad_fn=<DivBackward1>)\n",
      "tensor(0.0222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0393, grad_fn=<DivBackward1>)\n",
      "tensor(0.0203, grad_fn=<DivBackward1>)\n",
      "tensor(0.0351, grad_fn=<DivBackward1>)\n",
      "tensor(0.9415, grad_fn=<DivBackward1>)\n",
      "tensor(0.0721, grad_fn=<DivBackward1>)\n",
      "tensor(0.0052, grad_fn=<DivBackward1>)\n",
      "tensor(0.0317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0706, grad_fn=<DivBackward1>)\n",
      "tensor(0.6221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0518, grad_fn=<DivBackward1>)\n",
      "tensor(0.0574, grad_fn=<DivBackward1>)\n",
      "tensor(0.0250, grad_fn=<DivBackward1>)\n",
      "tensor(0.4256, grad_fn=<DivBackward1>)\n",
      "tensor(0.0495, grad_fn=<DivBackward1>)\n",
      "tensor(0.0501, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.0480, grad_fn=<DivBackward1>)\n",
      "tensor(0.0415, grad_fn=<DivBackward1>)\n",
      "tensor(0.0966, grad_fn=<DivBackward1>)\n",
      "tensor(0.0289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0499, grad_fn=<DivBackward1>)\n",
      "tensor(0.0219, grad_fn=<DivBackward1>)\n",
      "tensor(0.0567, grad_fn=<DivBackward1>)\n",
      "tensor(0.0270, grad_fn=<DivBackward1>)\n",
      "tensor(0.1206, grad_fn=<DivBackward1>)\n",
      "tensor(0.0552, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.0222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0352, grad_fn=<DivBackward1>)\n",
      "tensor(0.0220, grad_fn=<DivBackward1>)\n",
      "tensor(0.0419, grad_fn=<DivBackward1>)\n",
      "tensor(0.0463, grad_fn=<DivBackward1>)\n",
      "tensor(0.0542, grad_fn=<DivBackward1>)\n",
      "tensor(0.0094, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.0190, grad_fn=<DivBackward1>)\n",
      "tensor(0.0355, grad_fn=<DivBackward1>)\n",
      "tensor(0.0706, grad_fn=<DivBackward1>)\n",
      "tensor(0.0613, grad_fn=<DivBackward1>)\n",
      "tensor(0.0537, grad_fn=<DivBackward1>)\n",
      "tensor(0.0429, grad_fn=<DivBackward1>)\n",
      "tensor(0.0208, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.0254, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.0437, grad_fn=<DivBackward1>)\n",
      "tensor(0.0244, grad_fn=<DivBackward1>)\n",
      "tensor(0.6250, grad_fn=<DivBackward1>)\n",
      "tensor(0.0179, grad_fn=<DivBackward1>)\n",
      "tensor(0.0457, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0024, grad_fn=<DivBackward1>)\n",
      "tensor(0.0095, grad_fn=<DivBackward1>)\n",
      "tensor(0.0694, grad_fn=<DivBackward1>)\n",
      "tensor(0.0568, grad_fn=<DivBackward1>)\n",
      "tensor(0.0124, grad_fn=<DivBackward1>)\n",
      "tensor(0.4293, grad_fn=<DivBackward1>)\n",
      "tensor(0.0909, grad_fn=<DivBackward1>)\n",
      "tensor(0.0409, grad_fn=<DivBackward1>)\n",
      "tensor(0.0049, grad_fn=<DivBackward1>)\n",
      "tensor(0.1697, grad_fn=<DivBackward1>)\n",
      "tensor(0.0256, grad_fn=<DivBackward1>)\n",
      "tensor(0.0100, grad_fn=<DivBackward1>)\n",
      "tensor(0.0344, grad_fn=<DivBackward1>)\n",
      "tensor(0.0573, grad_fn=<DivBackward1>)\n",
      "tensor(0.7156, grad_fn=<DivBackward1>)\n",
      "tensor(0.6357, grad_fn=<DivBackward1>)\n",
      "tensor(0.0318, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.0150, grad_fn=<DivBackward1>)\n",
      "tensor(0.0362, grad_fn=<DivBackward1>)\n",
      "tensor(0.0249, grad_fn=<DivBackward1>)\n",
      "tensor(0.0447, grad_fn=<DivBackward1>)\n",
      "tensor(0.9565, grad_fn=<DivBackward1>)\n",
      "tensor(0.0580, grad_fn=<DivBackward1>)\n",
      "tensor(0.0056, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0653, grad_fn=<DivBackward1>)\n",
      "tensor(0.6022, grad_fn=<DivBackward1>)\n",
      "tensor(0.0700, grad_fn=<DivBackward1>)\n",
      "tensor(0.0710, grad_fn=<DivBackward1>)\n",
      "tensor(0.0491, grad_fn=<DivBackward1>)\n",
      "tensor(0.3009, grad_fn=<DivBackward1>)\n",
      "tensor(0.0668, grad_fn=<DivBackward1>)\n",
      "tensor(0.0453, grad_fn=<DivBackward1>)\n",
      "tensor(0.0140, grad_fn=<DivBackward1>)\n",
      "tensor(0.0379, grad_fn=<DivBackward1>)\n",
      "tensor(0.0386, grad_fn=<DivBackward1>)\n",
      "tensor(0.0819, grad_fn=<DivBackward1>)\n",
      "tensor(0.0196, grad_fn=<DivBackward1>)\n",
      "tensor(0.0529, grad_fn=<DivBackward1>)\n",
      "tensor(0.0192, grad_fn=<DivBackward1>)\n",
      "tensor(0.0420, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.1124, grad_fn=<DivBackward1>)\n",
      "tensor(0.0480, grad_fn=<DivBackward1>)\n",
      "tensor(0.0204, grad_fn=<DivBackward1>)\n",
      "tensor(0.0242, grad_fn=<DivBackward1>)\n",
      "tensor(0.0355, grad_fn=<DivBackward1>)\n",
      "tensor(0.0201, grad_fn=<DivBackward1>)\n",
      "tensor(0.0393, grad_fn=<DivBackward1>)\n",
      "tensor(0.0604, grad_fn=<DivBackward1>)\n",
      "tensor(0.0531, grad_fn=<DivBackward1>)\n",
      "tensor(0.0090, grad_fn=<DivBackward1>)\n",
      "tensor(0.0167, grad_fn=<DivBackward1>)\n",
      "tensor(0.0198, grad_fn=<DivBackward1>)\n",
      "tensor(0.0329, grad_fn=<DivBackward1>)\n",
      "tensor(0.0669, grad_fn=<DivBackward1>)\n",
      "tensor(0.0403, grad_fn=<DivBackward1>)\n",
      "tensor(0.0480, grad_fn=<DivBackward1>)\n",
      "tensor(0.0427, grad_fn=<DivBackward1>)\n",
      "tensor(0.0219, grad_fn=<DivBackward1>)\n",
      "tensor(0.0048, grad_fn=<DivBackward1>)\n",
      "tensor(0.0290, grad_fn=<DivBackward1>)\n",
      "tensor(0.0102, grad_fn=<DivBackward1>)\n",
      "tensor(0.0421, grad_fn=<DivBackward1>)\n",
      "tensor(0.0271, grad_fn=<DivBackward1>)\n",
      "tensor(0.6546, grad_fn=<DivBackward1>)\n",
      "tensor(0.0260, grad_fn=<DivBackward1>)\n",
      "tensor(0.0346, grad_fn=<DivBackward1>)\n",
      "tensor(0.0162, grad_fn=<DivBackward1>)\n",
      "tensor(0.0025, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.1405, grad_fn=<DivBackward1>)\n",
      "tensor(0.0374, grad_fn=<DivBackward1>)\n",
      "tensor(0.0113, grad_fn=<DivBackward1>)\n",
      "tensor(0.3619, grad_fn=<DivBackward1>)\n",
      "tensor(0.0965, grad_fn=<DivBackward1>)\n",
      "tensor(0.0320, grad_fn=<DivBackward1>)\n",
      "tensor(0.0036, grad_fn=<DivBackward1>)\n",
      "tensor(0.1786, grad_fn=<DivBackward1>)\n",
      "tensor(0.0274, grad_fn=<DivBackward1>)\n",
      "tensor(0.0095, grad_fn=<DivBackward1>)\n",
      "tensor(0.0281, grad_fn=<DivBackward1>)\n",
      "tensor(0.0725, grad_fn=<DivBackward1>)\n",
      "tensor(0.6821, grad_fn=<DivBackward1>)\n",
      "tensor(0.6895, grad_fn=<DivBackward1>)\n",
      "tensor(0.0366, grad_fn=<DivBackward1>)\n",
      "tensor(0.0146, grad_fn=<DivBackward1>)\n",
      "tensor(0.0127, grad_fn=<DivBackward1>)\n",
      "tensor(0.0363, grad_fn=<DivBackward1>)\n",
      "tensor(0.0220, grad_fn=<DivBackward1>)\n",
      "tensor(0.0626, grad_fn=<DivBackward1>)\n",
      "tensor(0.9530, grad_fn=<DivBackward1>)\n",
      "tensor(0.0723, grad_fn=<DivBackward1>)\n",
      "tensor(0.0057, grad_fn=<DivBackward1>)\n",
      "tensor(0.0254, grad_fn=<DivBackward1>)\n",
      "tensor(0.0949, grad_fn=<DivBackward1>)\n",
      "tensor(0.5715, grad_fn=<DivBackward1>)\n",
      "tensor(0.0459, grad_fn=<DivBackward1>)\n",
      "tensor(0.0899, grad_fn=<DivBackward1>)\n",
      "tensor(0.0580, grad_fn=<DivBackward1>)\n",
      "tensor(0.3542, grad_fn=<DivBackward1>)\n",
      "tensor(0.0697, grad_fn=<DivBackward1>)\n",
      "tensor(0.0506, grad_fn=<DivBackward1>)\n",
      "tensor(0.0112, grad_fn=<DivBackward1>)\n",
      "tensor(0.0419, grad_fn=<DivBackward1>)\n",
      "tensor(0.0297, grad_fn=<DivBackward1>)\n",
      "tensor(0.0510, grad_fn=<DivBackward1>)\n",
      "tensor(0.0357, grad_fn=<DivBackward1>)\n",
      "tensor(0.0675, grad_fn=<DivBackward1>)\n",
      "tensor(0.0232, grad_fn=<DivBackward1>)\n",
      "tensor(0.0433, grad_fn=<DivBackward1>)\n",
      "tensor(0.0215, grad_fn=<DivBackward1>)\n",
      "tensor(0.1257, grad_fn=<DivBackward1>)\n",
      "tensor(0.0481, grad_fn=<DivBackward1>)\n",
      "tensor(0.0218, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0302, grad_fn=<DivBackward1>)\n",
      "tensor(0.0147, grad_fn=<DivBackward1>)\n",
      "tensor(0.0470, grad_fn=<DivBackward1>)\n",
      "tensor(0.0466, grad_fn=<DivBackward1>)\n",
      "tensor(0.0460, grad_fn=<DivBackward1>)\n",
      "tensor(0.0103, grad_fn=<DivBackward1>)\n",
      "tensor(0.0161, grad_fn=<DivBackward1>)\n",
      "tensor(0.0254, grad_fn=<DivBackward1>)\n",
      "tensor(0.0228, grad_fn=<DivBackward1>)\n",
      "tensor(0.0615, grad_fn=<DivBackward1>)\n",
      "tensor(0.0667, grad_fn=<DivBackward1>)\n",
      "tensor(0.0487, grad_fn=<DivBackward1>)\n",
      "tensor(0.0310, grad_fn=<DivBackward1>)\n",
      "tensor(0.0251, grad_fn=<DivBackward1>)\n",
      "tensor(0.0057, grad_fn=<DivBackward1>)\n",
      "tensor(0.0242, grad_fn=<DivBackward1>)\n",
      "tensor(0.0107, grad_fn=<DivBackward1>)\n",
      "tensor(0.0364, grad_fn=<DivBackward1>)\n",
      "tensor(0.0244, grad_fn=<DivBackward1>)\n",
      "tensor(0.4515, grad_fn=<DivBackward1>)\n",
      "tensor(0.0170, grad_fn=<DivBackward1>)\n",
      "tensor(0.0413, grad_fn=<DivBackward1>)\n",
      "tensor(0.0247, grad_fn=<DivBackward1>)\n",
      "tensor(0.0022, grad_fn=<DivBackward1>)\n",
      "tensor(0.0090, grad_fn=<DivBackward1>)\n",
      "tensor(0.0448, grad_fn=<DivBackward1>)\n",
      "tensor(0.1087, grad_fn=<DivBackward1>)\n",
      "tensor(0.0137, grad_fn=<DivBackward1>)\n",
      "tensor(0.5192, grad_fn=<DivBackward1>)\n",
      "tensor(0.0788, grad_fn=<DivBackward1>)\n",
      "tensor(0.0294, grad_fn=<DivBackward1>)\n",
      "tensor(0.0063, grad_fn=<DivBackward1>)\n",
      "tensor(0.3806, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0088, grad_fn=<DivBackward1>)\n",
      "tensor(0.0279, grad_fn=<DivBackward1>)\n",
      "tensor(0.0571, grad_fn=<DivBackward1>)\n",
      "tensor(0.6949, grad_fn=<DivBackward1>)\n",
      "tensor(0.6706, grad_fn=<DivBackward1>)\n",
      "tensor(0.0274, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.0125, grad_fn=<DivBackward1>)\n",
      "tensor(0.0402, grad_fn=<DivBackward1>)\n",
      "tensor(0.0182, grad_fn=<DivBackward1>)\n",
      "tensor(0.0505, grad_fn=<DivBackward1>)\n",
      "tensor(0.9432, grad_fn=<DivBackward1>)\n",
      "tensor(0.0501, grad_fn=<DivBackward1>)\n",
      "tensor(0.0041, grad_fn=<DivBackward1>)\n",
      "tensor(0.0288, grad_fn=<DivBackward1>)\n",
      "tensor(0.0697, grad_fn=<DivBackward1>)\n",
      "tensor(0.6156, grad_fn=<DivBackward1>)\n",
      "tensor(0.0699, grad_fn=<DivBackward1>)\n",
      "tensor(0.0762, grad_fn=<DivBackward1>)\n",
      "tensor(0.0177, grad_fn=<DivBackward1>)\n",
      "tensor(0.4837, grad_fn=<DivBackward1>)\n",
      "tensor(0.0325, grad_fn=<DivBackward1>)\n",
      "tensor(0.0687, grad_fn=<DivBackward1>)\n",
      "tensor(0.0180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0338, grad_fn=<DivBackward1>)\n",
      "tensor(0.0242, grad_fn=<DivBackward1>)\n",
      "tensor(0.1055, grad_fn=<DivBackward1>)\n",
      "tensor(0.0175, grad_fn=<DivBackward1>)\n",
      "tensor(0.0437, grad_fn=<DivBackward1>)\n",
      "tensor(0.0258, grad_fn=<DivBackward1>)\n",
      "tensor(0.0589, grad_fn=<DivBackward1>)\n",
      "tensor(0.0417, grad_fn=<DivBackward1>)\n",
      "tensor(0.0926, grad_fn=<DivBackward1>)\n",
      "tensor(0.0527, grad_fn=<DivBackward1>)\n",
      "tensor(0.0206, grad_fn=<DivBackward1>)\n",
      "tensor(0.0182, grad_fn=<DivBackward1>)\n",
      "tensor(0.0344, grad_fn=<DivBackward1>)\n",
      "tensor(0.0244, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.0422, grad_fn=<DivBackward1>)\n",
      "tensor(0.0540, grad_fn=<DivBackward1>)\n",
      "tensor(0.0090, grad_fn=<DivBackward1>)\n",
      "tensor(0.0198, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.0329, grad_fn=<DivBackward1>)\n",
      "tensor(0.0768, grad_fn=<DivBackward1>)\n",
      "tensor(0.0330, grad_fn=<DivBackward1>)\n",
      "tensor(0.0395, grad_fn=<DivBackward1>)\n",
      "tensor(0.0378, grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, grad_fn=<DivBackward1>)\n",
      "tensor(0.0049, grad_fn=<DivBackward1>)\n",
      "tensor(0.0303, grad_fn=<DivBackward1>)\n",
      "tensor(0.0113, grad_fn=<DivBackward1>)\n",
      "tensor(0.0442, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.5036, grad_fn=<DivBackward1>)\n",
      "tensor(0.0137, grad_fn=<DivBackward1>)\n",
      "tensor(0.0315, grad_fn=<DivBackward1>)\n",
      "tensor(0.0163, grad_fn=<DivBackward1>)\n",
      "tensor(0.0024, grad_fn=<DivBackward1>)\n",
      "tensor(0.0072, grad_fn=<DivBackward1>)\n",
      "tensor(0.0438, grad_fn=<DivBackward1>)\n",
      "tensor(0.0931, grad_fn=<DivBackward1>)\n",
      "tensor(0.0096, grad_fn=<DivBackward1>)\n",
      "tensor(0.4165, grad_fn=<DivBackward1>)\n",
      "tensor(0.1493, grad_fn=<DivBackward1>)\n",
      "tensor(0.0255, grad_fn=<DivBackward1>)\n",
      "tensor(0.0041, grad_fn=<DivBackward1>)\n",
      "tensor(0.1999, grad_fn=<DivBackward1>)\n",
      "tensor(0.0283, grad_fn=<DivBackward1>)\n",
      "tensor(0.0096, grad_fn=<DivBackward1>)\n",
      "tensor(0.0390, grad_fn=<DivBackward1>)\n",
      "tensor(0.0610, grad_fn=<DivBackward1>)\n",
      "tensor(0.6692, grad_fn=<DivBackward1>)\n",
      "tensor(0.6905, grad_fn=<DivBackward1>)\n",
      "tensor(0.0316, grad_fn=<DivBackward1>)\n",
      "tensor(0.0143, grad_fn=<DivBackward1>)\n",
      "tensor(0.0130, grad_fn=<DivBackward1>)\n",
      "tensor(0.0374, grad_fn=<DivBackward1>)\n",
      "tensor(0.0202, grad_fn=<DivBackward1>)\n",
      "tensor(0.0431, grad_fn=<DivBackward1>)\n",
      "tensor(0.9040, grad_fn=<DivBackward1>)\n",
      "tensor(0.0645, grad_fn=<DivBackward1>)\n",
      "tensor(0.0055, grad_fn=<DivBackward1>)\n",
      "tensor(0.0239, grad_fn=<DivBackward1>)\n",
      "tensor(0.0608, grad_fn=<DivBackward1>)\n",
      "tensor(0.6678, grad_fn=<DivBackward1>)\n",
      "tensor(0.0606, grad_fn=<DivBackward1>)\n",
      "tensor(0.1176, grad_fn=<DivBackward1>)\n",
      "tensor(0.0244, grad_fn=<DivBackward1>)\n",
      "tensor(0.4317, grad_fn=<DivBackward1>)\n",
      "tensor(0.0407, grad_fn=<DivBackward1>)\n",
      "tensor(0.0482, grad_fn=<DivBackward1>)\n",
      "tensor(0.0163, grad_fn=<DivBackward1>)\n",
      "tensor(0.0508, grad_fn=<DivBackward1>)\n",
      "tensor(0.0270, grad_fn=<DivBackward1>)\n",
      "tensor(0.0790, grad_fn=<DivBackward1>)\n",
      "tensor(0.0292, grad_fn=<DivBackward1>)\n",
      "tensor(0.0439, grad_fn=<DivBackward1>)\n",
      "tensor(0.0200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0469, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.1016, grad_fn=<DivBackward1>)\n",
      "tensor(0.0483, grad_fn=<DivBackward1>)\n",
      "tensor(0.0184, grad_fn=<DivBackward1>)\n",
      "tensor(0.0181, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0193, grad_fn=<DivBackward1>)\n",
      "tensor(0.0362, grad_fn=<DivBackward1>)\n",
      "tensor(0.0410, grad_fn=<DivBackward1>)\n",
      "tensor(0.0532, grad_fn=<DivBackward1>)\n",
      "tensor(0.0089, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.0165, grad_fn=<DivBackward1>)\n",
      "tensor(0.0363, grad_fn=<DivBackward1>)\n",
      "tensor(0.0703, grad_fn=<DivBackward1>)\n",
      "tensor(0.0316, grad_fn=<DivBackward1>)\n",
      "tensor(0.0376, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.0143, grad_fn=<DivBackward1>)\n",
      "tensor(0.0041, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.0116, grad_fn=<DivBackward1>)\n",
      "tensor(0.0384, grad_fn=<DivBackward1>)\n",
      "tensor(0.0227, grad_fn=<DivBackward1>)\n",
      "tensor(0.5775, grad_fn=<DivBackward1>)\n",
      "tensor(0.0239, grad_fn=<DivBackward1>)\n",
      "tensor(0.0307, grad_fn=<DivBackward1>)\n",
      "tensor(0.0189, grad_fn=<DivBackward1>)\n",
      "tensor(0.0025, grad_fn=<DivBackward1>)\n",
      "tensor(0.0060, grad_fn=<DivBackward1>)\n",
      "tensor(0.1021, grad_fn=<DivBackward1>)\n",
      "tensor(0.0342, grad_fn=<DivBackward1>)\n",
      "tensor(0.0074, grad_fn=<DivBackward1>)\n",
      "tensor(0.3559, grad_fn=<DivBackward1>)\n",
      "tensor(0.0749, grad_fn=<DivBackward1>)\n",
      "tensor(0.0365, grad_fn=<DivBackward1>)\n",
      "tensor(0.0041, grad_fn=<DivBackward1>)\n",
      "tensor(0.2030, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.0087, grad_fn=<DivBackward1>)\n",
      "tensor(0.0261, grad_fn=<DivBackward1>)\n",
      "tensor(0.0510, grad_fn=<DivBackward1>)\n",
      "tensor(0.6722, grad_fn=<DivBackward1>)\n",
      "tensor(0.5683, grad_fn=<DivBackward1>)\n",
      "tensor(0.0322, grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, grad_fn=<DivBackward1>)\n",
      "tensor(0.0132, grad_fn=<DivBackward1>)\n",
      "tensor(0.0348, grad_fn=<DivBackward1>)\n",
      "tensor(0.0218, grad_fn=<DivBackward1>)\n",
      "tensor(0.0373, grad_fn=<DivBackward1>)\n",
      "tensor(0.9330, grad_fn=<DivBackward1>)\n",
      "tensor(0.0541, grad_fn=<DivBackward1>)\n",
      "tensor(0.0053, grad_fn=<DivBackward1>)\n",
      "tensor(0.0188, grad_fn=<DivBackward1>)\n",
      "tensor(0.0677, grad_fn=<DivBackward1>)\n",
      "tensor(0.5806, grad_fn=<DivBackward1>)\n",
      "tensor(0.0528, grad_fn=<DivBackward1>)\n",
      "tensor(0.1137, grad_fn=<DivBackward1>)\n",
      "tensor(0.0384, grad_fn=<DivBackward1>)\n",
      "tensor(0.4478, grad_fn=<DivBackward1>)\n",
      "tensor(0.0693, grad_fn=<DivBackward1>)\n",
      "tensor(0.0412, grad_fn=<DivBackward1>)\n",
      "tensor(0.0113, grad_fn=<DivBackward1>)\n",
      "tensor(0.0453, grad_fn=<DivBackward1>)\n",
      "tensor(0.0316, grad_fn=<DivBackward1>)\n",
      "tensor(0.0593, grad_fn=<DivBackward1>)\n",
      "tensor(0.0265, grad_fn=<DivBackward1>)\n",
      "tensor(0.0792, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0599, grad_fn=<DivBackward1>)\n",
      "tensor(0.0217, grad_fn=<DivBackward1>)\n",
      "tensor(0.1320, grad_fn=<DivBackward1>)\n",
      "tensor(0.0452, grad_fn=<DivBackward1>)\n",
      "tensor(0.0187, grad_fn=<DivBackward1>)\n",
      "tensor(0.0254, grad_fn=<DivBackward1>)\n",
      "tensor(0.0295, grad_fn=<DivBackward1>)\n",
      "tensor(0.0204, grad_fn=<DivBackward1>)\n",
      "tensor(0.0341, grad_fn=<DivBackward1>)\n",
      "tensor(0.0526, grad_fn=<DivBackward1>)\n",
      "tensor(0.0412, grad_fn=<DivBackward1>)\n",
      "tensor(0.0100, grad_fn=<DivBackward1>)\n",
      "tensor(0.0139, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.0230, grad_fn=<DivBackward1>)\n",
      "tensor(0.0499, grad_fn=<DivBackward1>)\n",
      "tensor(0.0482, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0307, grad_fn=<DivBackward1>)\n",
      "tensor(0.0174, grad_fn=<DivBackward1>)\n",
      "tensor(0.0054, grad_fn=<DivBackward1>)\n",
      "tensor(0.0195, grad_fn=<DivBackward1>)\n",
      "tensor(0.0099, grad_fn=<DivBackward1>)\n",
      "tensor(0.0345, grad_fn=<DivBackward1>)\n",
      "tensor(0.0225, grad_fn=<DivBackward1>)\n",
      "tensor(0.5318, grad_fn=<DivBackward1>)\n",
      "tensor(0.0201, grad_fn=<DivBackward1>)\n",
      "tensor(0.0407, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.0023, grad_fn=<DivBackward1>)\n",
      "tensor(0.0070, grad_fn=<DivBackward1>)\n",
      "tensor(0.0412, grad_fn=<DivBackward1>)\n",
      "tensor(0.0701, grad_fn=<DivBackward1>)\n",
      "tensor(0.0088, grad_fn=<DivBackward1>)\n",
      "tensor(0.3507, grad_fn=<DivBackward1>)\n",
      "tensor(0.1050, grad_fn=<DivBackward1>)\n",
      "tensor(0.0298, grad_fn=<DivBackward1>)\n",
      "tensor(0.0045, grad_fn=<DivBackward1>)\n",
      "tensor(0.2560, grad_fn=<DivBackward1>)\n",
      "tensor(0.0259, grad_fn=<DivBackward1>)\n",
      "tensor(0.0081, grad_fn=<DivBackward1>)\n",
      "tensor(0.0286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0602, grad_fn=<DivBackward1>)\n",
      "tensor(0.6494, grad_fn=<DivBackward1>)\n",
      "tensor(0.6324, grad_fn=<DivBackward1>)\n",
      "tensor(0.0285, grad_fn=<DivBackward1>)\n",
      "tensor(0.0131, grad_fn=<DivBackward1>)\n",
      "tensor(0.0121, grad_fn=<DivBackward1>)\n",
      "tensor(0.0368, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.0455, grad_fn=<DivBackward1>)\n",
      "tensor(0.9765, grad_fn=<DivBackward1>)\n",
      "tensor(0.0538, grad_fn=<DivBackward1>)\n",
      "tensor(0.0039, grad_fn=<DivBackward1>)\n",
      "tensor(0.0215, grad_fn=<DivBackward1>)\n",
      "tensor(0.0639, grad_fn=<DivBackward1>)\n",
      "tensor(0.5729, grad_fn=<DivBackward1>)\n",
      "tensor(0.0738, grad_fn=<DivBackward1>)\n",
      "tensor(0.0735, grad_fn=<DivBackward1>)\n",
      "tensor(0.0160, grad_fn=<DivBackward1>)\n",
      "tensor(0.4121, grad_fn=<DivBackward1>)\n",
      "tensor(0.0550, grad_fn=<DivBackward1>)\n",
      "tensor(0.0613, grad_fn=<DivBackward1>)\n",
      "tensor(0.0115, grad_fn=<DivBackward1>)\n",
      "tensor(0.0330, grad_fn=<DivBackward1>)\n",
      "tensor(0.0325, grad_fn=<DivBackward1>)\n",
      "tensor(0.0874, grad_fn=<DivBackward1>)\n",
      "tensor(0.0201, grad_fn=<DivBackward1>)\n",
      "tensor(0.0357, grad_fn=<DivBackward1>)\n",
      "tensor(0.0204, grad_fn=<DivBackward1>)\n",
      "tensor(0.0822, grad_fn=<DivBackward1>)\n",
      "tensor(0.0333, grad_fn=<DivBackward1>)\n",
      "tensor(0.1223, grad_fn=<DivBackward1>)\n",
      "tensor(0.0481, grad_fn=<DivBackward1>)\n",
      "tensor(0.0159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0218, grad_fn=<DivBackward1>)\n",
      "tensor(0.0329, grad_fn=<DivBackward1>)\n",
      "tensor(0.0246, grad_fn=<DivBackward1>)\n",
      "tensor(0.0381, grad_fn=<DivBackward1>)\n",
      "tensor(0.0433, grad_fn=<DivBackward1>)\n",
      "tensor(0.0549, grad_fn=<DivBackward1>)\n",
      "tensor(0.0105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0166, grad_fn=<DivBackward1>)\n",
      "tensor(0.0164, grad_fn=<DivBackward1>)\n",
      "tensor(0.0266, grad_fn=<DivBackward1>)\n",
      "tensor(0.0614, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0265, grad_fn=<DivBackward1>)\n",
      "tensor(0.0337, grad_fn=<DivBackward1>)\n",
      "tensor(0.0141, grad_fn=<DivBackward1>)\n",
      "tensor(0.0046, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.0119, grad_fn=<DivBackward1>)\n",
      "tensor(0.0372, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.4649, grad_fn=<DivBackward1>)\n",
      "tensor(0.0229, grad_fn=<DivBackward1>)\n",
      "tensor(0.0229, grad_fn=<DivBackward1>)\n",
      "tensor(0.0156, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.0735, grad_fn=<DivBackward1>)\n",
      "tensor(0.0413, grad_fn=<DivBackward1>)\n",
      "tensor(0.0064, grad_fn=<DivBackward1>)\n",
      "tensor(0.3619, grad_fn=<DivBackward1>)\n",
      "tensor(0.0834, grad_fn=<DivBackward1>)\n",
      "tensor(0.0228, grad_fn=<DivBackward1>)\n",
      "tensor(0.0038, grad_fn=<DivBackward1>)\n",
      "tensor(0.2221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0245, grad_fn=<DivBackward1>)\n",
      "tensor(0.0090, grad_fn=<DivBackward1>)\n",
      "tensor(0.0286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0882, grad_fn=<DivBackward1>)\n",
      "tensor(0.6106, grad_fn=<DivBackward1>)\n",
      "tensor(0.6651, grad_fn=<DivBackward1>)\n",
      "tensor(0.0353, grad_fn=<DivBackward1>)\n",
      "tensor(0.0149, grad_fn=<DivBackward1>)\n",
      "tensor(0.0115, grad_fn=<DivBackward1>)\n",
      "tensor(0.0339, grad_fn=<DivBackward1>)\n",
      "tensor(0.0232, grad_fn=<DivBackward1>)\n",
      "tensor(0.0477, grad_fn=<DivBackward1>)\n",
      "tensor(0.9245, grad_fn=<DivBackward1>)\n",
      "tensor(0.0532, grad_fn=<DivBackward1>)\n",
      "tensor(0.0056, grad_fn=<DivBackward1>)\n",
      "tensor(0.0180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0609, grad_fn=<DivBackward1>)\n",
      "tensor(0.5477, grad_fn=<DivBackward1>)\n",
      "tensor(0.0546, grad_fn=<DivBackward1>)\n",
      "tensor(0.1160, grad_fn=<DivBackward1>)\n",
      "tensor(0.0331, grad_fn=<DivBackward1>)\n",
      "tensor(0.4148, grad_fn=<DivBackward1>)\n",
      "tensor(0.0812, grad_fn=<DivBackward1>)\n",
      "tensor(0.0461, grad_fn=<DivBackward1>)\n",
      "tensor(0.0077, grad_fn=<DivBackward1>)\n",
      "tensor(0.0292, grad_fn=<DivBackward1>)\n",
      "tensor(0.0221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0449, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0558, grad_fn=<DivBackward1>)\n",
      "tensor(0.0173, grad_fn=<DivBackward1>)\n",
      "tensor(0.0613, grad_fn=<DivBackward1>)\n",
      "tensor(0.0252, grad_fn=<DivBackward1>)\n",
      "tensor(0.1601, grad_fn=<DivBackward1>)\n",
      "tensor(0.0442, grad_fn=<DivBackward1>)\n",
      "tensor(0.0162, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.0247, grad_fn=<DivBackward1>)\n",
      "tensor(0.0139, grad_fn=<DivBackward1>)\n",
      "tensor(0.0264, grad_fn=<DivBackward1>)\n",
      "tensor(0.0487, grad_fn=<DivBackward1>)\n",
      "tensor(0.0414, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.0203, grad_fn=<DivBackward1>)\n",
      "tensor(0.0214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0498, grad_fn=<DivBackward1>)\n",
      "tensor(0.0472, grad_fn=<DivBackward1>)\n",
      "tensor(0.0306, grad_fn=<DivBackward1>)\n",
      "tensor(0.0343, grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, grad_fn=<DivBackward1>)\n",
      "tensor(0.0053, grad_fn=<DivBackward1>)\n",
      "tensor(0.0173, grad_fn=<DivBackward1>)\n",
      "tensor(0.0082, grad_fn=<DivBackward1>)\n",
      "tensor(0.0321, grad_fn=<DivBackward1>)\n",
      "tensor(0.0194, grad_fn=<DivBackward1>)\n",
      "tensor(0.4696, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.0422, grad_fn=<DivBackward1>)\n",
      "tensor(0.0217, grad_fn=<DivBackward1>)\n",
      "tensor(0.0024, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.0453, grad_fn=<DivBackward1>)\n",
      "tensor(0.0670, grad_fn=<DivBackward1>)\n",
      "tensor(0.0088, grad_fn=<DivBackward1>)\n",
      "tensor(0.3519, grad_fn=<DivBackward1>)\n",
      "tensor(0.0986, grad_fn=<DivBackward1>)\n",
      "tensor(0.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0041, grad_fn=<DivBackward1>)\n",
      "tensor(0.2462, grad_fn=<DivBackward1>)\n",
      "tensor(0.0226, grad_fn=<DivBackward1>)\n",
      "tensor(0.0075, grad_fn=<DivBackward1>)\n",
      "tensor(0.0323, grad_fn=<DivBackward1>)\n",
      "tensor(0.0728, grad_fn=<DivBackward1>)\n",
      "tensor(0.6338, grad_fn=<DivBackward1>)\n",
      "tensor(0.6554, grad_fn=<DivBackward1>)\n",
      "tensor(0.0297, grad_fn=<DivBackward1>)\n",
      "tensor(0.0131, grad_fn=<DivBackward1>)\n",
      "tensor(0.0119, grad_fn=<DivBackward1>)\n",
      "tensor(0.0364, grad_fn=<DivBackward1>)\n",
      "tensor(0.0215, grad_fn=<DivBackward1>)\n",
      "tensor(0.0352, grad_fn=<DivBackward1>)\n",
      "tensor(0.9107, grad_fn=<DivBackward1>)\n",
      "tensor(0.0383, grad_fn=<DivBackward1>)\n",
      "tensor(0.0039, grad_fn=<DivBackward1>)\n",
      "tensor(0.0218, grad_fn=<DivBackward1>)\n",
      "tensor(0.0492, grad_fn=<DivBackward1>)\n",
      "tensor(0.6387, grad_fn=<DivBackward1>)\n",
      "tensor(0.0608, grad_fn=<DivBackward1>)\n",
      "tensor(0.1606, grad_fn=<DivBackward1>)\n",
      "tensor(0.0227, grad_fn=<DivBackward1>)\n",
      "tensor(0.4074, grad_fn=<DivBackward1>)\n",
      "tensor(0.0707, grad_fn=<DivBackward1>)\n",
      "tensor(0.0616, grad_fn=<DivBackward1>)\n",
      "tensor(0.0095, grad_fn=<DivBackward1>)\n",
      "tensor(0.0331, grad_fn=<DivBackward1>)\n",
      "tensor(0.0229, grad_fn=<DivBackward1>)\n",
      "tensor(0.0618, grad_fn=<DivBackward1>)\n",
      "tensor(0.0214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0381, grad_fn=<DivBackward1>)\n",
      "tensor(0.0185, grad_fn=<DivBackward1>)\n",
      "tensor(0.0430, grad_fn=<DivBackward1>)\n",
      "tensor(0.0126, grad_fn=<DivBackward1>)\n",
      "tensor(0.0970, grad_fn=<DivBackward1>)\n",
      "tensor(0.0385, grad_fn=<DivBackward1>)\n",
      "tensor(0.0156, grad_fn=<DivBackward1>)\n",
      "tensor(0.0303, grad_fn=<DivBackward1>)\n",
      "tensor(0.0265, grad_fn=<DivBackward1>)\n",
      "tensor(0.0205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0255, grad_fn=<DivBackward1>)\n",
      "tensor(0.0511, grad_fn=<DivBackward1>)\n",
      "tensor(0.0443, grad_fn=<DivBackward1>)\n",
      "tensor(0.0079, grad_fn=<DivBackward1>)\n",
      "tensor(0.0124, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.0287, grad_fn=<DivBackward1>)\n",
      "tensor(0.0553, grad_fn=<DivBackward1>)\n",
      "tensor(0.0214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0336, grad_fn=<DivBackward1>)\n",
      "tensor(0.0148, grad_fn=<DivBackward1>)\n",
      "tensor(0.0035, grad_fn=<DivBackward1>)\n",
      "tensor(0.0244, grad_fn=<DivBackward1>)\n",
      "tensor(0.0086, grad_fn=<DivBackward1>)\n",
      "tensor(0.0386, grad_fn=<DivBackward1>)\n",
      "tensor(0.0190, grad_fn=<DivBackward1>)\n",
      "tensor(0.5693, grad_fn=<DivBackward1>)\n",
      "tensor(0.0225, grad_fn=<DivBackward1>)\n",
      "tensor(0.0228, grad_fn=<DivBackward1>)\n",
      "tensor(0.0126, grad_fn=<DivBackward1>)\n",
      "tensor(0.0027, grad_fn=<DivBackward1>)\n",
      "tensor(0.0054, grad_fn=<DivBackward1>)\n",
      "tensor(0.0936, grad_fn=<DivBackward1>)\n",
      "tensor(0.0307, grad_fn=<DivBackward1>)\n",
      "tensor(0.0062, grad_fn=<DivBackward1>)\n",
      "tensor(0.3010, grad_fn=<DivBackward1>)\n",
      "tensor(0.0885, grad_fn=<DivBackward1>)\n",
      "tensor(0.0194, grad_fn=<DivBackward1>)\n",
      "tensor(0.0030, grad_fn=<DivBackward1>)\n",
      "tensor(0.1412, grad_fn=<DivBackward1>)\n",
      "tensor(0.0246, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.0350, grad_fn=<DivBackward1>)\n",
      "tensor(0.0664, grad_fn=<DivBackward1>)\n",
      "tensor(0.5966, grad_fn=<DivBackward1>)\n",
      "tensor(0.6399, grad_fn=<DivBackward1>)\n",
      "tensor(0.0357, grad_fn=<DivBackward1>)\n",
      "tensor(0.0106, grad_fn=<DivBackward1>)\n",
      "tensor(0.0097, grad_fn=<DivBackward1>)\n",
      "tensor(0.0305, grad_fn=<DivBackward1>)\n",
      "tensor(0.0211, grad_fn=<DivBackward1>)\n",
      "tensor(0.0403, grad_fn=<DivBackward1>)\n",
      "tensor(0.9200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0480, grad_fn=<DivBackward1>)\n",
      "tensor(0.0065, grad_fn=<DivBackward1>)\n",
      "tensor(0.0173, grad_fn=<DivBackward1>)\n",
      "tensor(0.0685, grad_fn=<DivBackward1>)\n",
      "tensor(0.5977, grad_fn=<DivBackward1>)\n",
      "tensor(0.0463, grad_fn=<DivBackward1>)\n",
      "tensor(0.1413, grad_fn=<DivBackward1>)\n",
      "tensor(0.0330, grad_fn=<DivBackward1>)\n",
      "tensor(0.3561, grad_fn=<DivBackward1>)\n",
      "tensor(0.0787, grad_fn=<DivBackward1>)\n",
      "tensor(0.0488, grad_fn=<DivBackward1>)\n",
      "tensor(0.0102, grad_fn=<DivBackward1>)\n",
      "tensor(0.0387, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.0371, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.0478, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0499, grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, grad_fn=<DivBackward1>)\n",
      "tensor(0.1334, grad_fn=<DivBackward1>)\n",
      "tensor(0.0336, grad_fn=<DivBackward1>)\n",
      "tensor(0.0165, grad_fn=<DivBackward1>)\n",
      "tensor(0.0296, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0176, grad_fn=<DivBackward1>)\n",
      "tensor(0.0281, grad_fn=<DivBackward1>)\n",
      "tensor(0.0478, grad_fn=<DivBackward1>)\n",
      "tensor(0.0328, grad_fn=<DivBackward1>)\n",
      "tensor(0.0102, grad_fn=<DivBackward1>)\n",
      "tensor(0.0101, grad_fn=<DivBackward1>)\n",
      "tensor(0.0298, grad_fn=<DivBackward1>)\n",
      "tensor(0.0219, grad_fn=<DivBackward1>)\n",
      "tensor(0.0506, grad_fn=<DivBackward1>)\n",
      "tensor(0.0443, grad_fn=<DivBackward1>)\n",
      "tensor(0.0289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0324, grad_fn=<DivBackward1>)\n",
      "tensor(0.0184, grad_fn=<DivBackward1>)\n",
      "tensor(0.0040, grad_fn=<DivBackward1>)\n",
      "tensor(0.0184, grad_fn=<DivBackward1>)\n",
      "tensor(0.0078, grad_fn=<DivBackward1>)\n",
      "tensor(0.0301, grad_fn=<DivBackward1>)\n",
      "tensor(0.0174, grad_fn=<DivBackward1>)\n",
      "tensor(0.5473, grad_fn=<DivBackward1>)\n",
      "tensor(0.0204, grad_fn=<DivBackward1>)\n",
      "tensor(0.0361, grad_fn=<DivBackward1>)\n",
      "tensor(0.0169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0061, grad_fn=<DivBackward1>)\n",
      "tensor(0.0306, grad_fn=<DivBackward1>)\n",
      "tensor(0.0695, grad_fn=<DivBackward1>)\n",
      "tensor(0.0077, grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, grad_fn=<DivBackward1>)\n",
      "tensor(0.0900, grad_fn=<DivBackward1>)\n",
      "tensor(0.0263, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.2388, grad_fn=<DivBackward1>)\n",
      "tensor(0.0235, grad_fn=<DivBackward1>)\n",
      "tensor(0.0066, grad_fn=<DivBackward1>)\n",
      "tensor(0.0310, grad_fn=<DivBackward1>)\n",
      "tensor(0.0619, grad_fn=<DivBackward1>)\n",
      "tensor(0.5904, grad_fn=<DivBackward1>)\n",
      "tensor(0.6103, grad_fn=<DivBackward1>)\n",
      "tensor(0.0320, grad_fn=<DivBackward1>)\n",
      "tensor(0.0097, grad_fn=<DivBackward1>)\n",
      "tensor(0.0100, grad_fn=<DivBackward1>)\n",
      "tensor(0.0339, grad_fn=<DivBackward1>)\n",
      "tensor(0.0187, grad_fn=<DivBackward1>)\n",
      "tensor(0.0395, grad_fn=<DivBackward1>)\n",
      "tensor(0.9252, grad_fn=<DivBackward1>)\n",
      "tensor(0.0393, grad_fn=<DivBackward1>)\n",
      "tensor(0.0037, grad_fn=<DivBackward1>)\n",
      "tensor(0.0249, grad_fn=<DivBackward1>)\n",
      "tensor(0.0556, grad_fn=<DivBackward1>)\n",
      "tensor(0.6180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0693, grad_fn=<DivBackward1>)\n",
      "tensor(0.0855, grad_fn=<DivBackward1>)\n",
      "tensor(0.0148, grad_fn=<DivBackward1>)\n",
      "tensor(0.2959, grad_fn=<DivBackward1>)\n",
      "tensor(0.0767, grad_fn=<DivBackward1>)\n",
      "tensor(0.0751, grad_fn=<DivBackward1>)\n",
      "tensor(0.0118, grad_fn=<DivBackward1>)\n",
      "tensor(0.0306, grad_fn=<DivBackward1>)\n",
      "tensor(0.0249, grad_fn=<DivBackward1>)\n",
      "tensor(0.0646, grad_fn=<DivBackward1>)\n",
      "tensor(0.0140, grad_fn=<DivBackward1>)\n",
      "tensor(0.0364, grad_fn=<DivBackward1>)\n",
      "tensor(0.0194, grad_fn=<DivBackward1>)\n",
      "tensor(0.0476, grad_fn=<DivBackward1>)\n",
      "tensor(0.0161, grad_fn=<DivBackward1>)\n",
      "tensor(0.1037, grad_fn=<DivBackward1>)\n",
      "tensor(0.0382, grad_fn=<DivBackward1>)\n",
      "tensor(0.0159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0237, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.0255, grad_fn=<DivBackward1>)\n",
      "tensor(0.0417, grad_fn=<DivBackward1>)\n",
      "tensor(0.0429, grad_fn=<DivBackward1>)\n",
      "tensor(0.0091, grad_fn=<DivBackward1>)\n",
      "tensor(0.0144, grad_fn=<DivBackward1>)\n",
      "tensor(0.0207, grad_fn=<DivBackward1>)\n",
      "tensor(0.0371, grad_fn=<DivBackward1>)\n",
      "tensor(0.0474, grad_fn=<DivBackward1>)\n",
      "tensor(0.0300, grad_fn=<DivBackward1>)\n",
      "tensor(0.0279, grad_fn=<DivBackward1>)\n",
      "tensor(0.0374, grad_fn=<DivBackward1>)\n",
      "tensor(0.0128, grad_fn=<DivBackward1>)\n",
      "tensor(0.0029, grad_fn=<DivBackward1>)\n",
      "tensor(0.0235, grad_fn=<DivBackward1>)\n",
      "tensor(0.0093, grad_fn=<DivBackward1>)\n",
      "tensor(0.0354, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.5912, grad_fn=<DivBackward1>)\n",
      "tensor(0.0216, grad_fn=<DivBackward1>)\n",
      "tensor(0.0227, grad_fn=<DivBackward1>)\n",
      "tensor(0.0103, grad_fn=<DivBackward1>)\n",
      "tensor(0.0032, grad_fn=<DivBackward1>)\n",
      "tensor(0.0050, grad_fn=<DivBackward1>)\n",
      "tensor(0.0753, grad_fn=<DivBackward1>)\n",
      "tensor(0.0363, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.3057, grad_fn=<DivBackward1>)\n",
      "tensor(0.0648, grad_fn=<DivBackward1>)\n",
      "tensor(0.0329, grad_fn=<DivBackward1>)\n",
      "tensor(0.0035, grad_fn=<DivBackward1>)\n",
      "tensor(0.1554, grad_fn=<DivBackward1>)\n",
      "tensor(0.0208, grad_fn=<DivBackward1>)\n",
      "tensor(0.0070, grad_fn=<DivBackward1>)\n",
      "tensor(0.0316, grad_fn=<DivBackward1>)\n",
      "tensor(0.0717, grad_fn=<DivBackward1>)\n",
      "tensor(0.5549, grad_fn=<DivBackward1>)\n",
      "tensor(0.5860, grad_fn=<DivBackward1>)\n",
      "tensor(0.0417, grad_fn=<DivBackward1>)\n",
      "tensor(0.0086, grad_fn=<DivBackward1>)\n",
      "tensor(0.0086, grad_fn=<DivBackward1>)\n",
      "tensor(0.0298, grad_fn=<DivBackward1>)\n",
      "tensor(0.0233, grad_fn=<DivBackward1>)\n",
      "tensor(0.0477, grad_fn=<DivBackward1>)\n",
      "tensor(0.8745, grad_fn=<DivBackward1>)\n",
      "tensor(0.0434, grad_fn=<DivBackward1>)\n",
      "tensor(0.0063, grad_fn=<DivBackward1>)\n",
      "tensor(0.0207, grad_fn=<DivBackward1>)\n",
      "tensor(0.0559, grad_fn=<DivBackward1>)\n",
      "tensor(0.6819, grad_fn=<DivBackward1>)\n",
      "tensor(0.0429, grad_fn=<DivBackward1>)\n",
      "tensor(0.1687, grad_fn=<DivBackward1>)\n",
      "tensor(0.0577, grad_fn=<DivBackward1>)\n",
      "tensor(0.3345, grad_fn=<DivBackward1>)\n",
      "tensor(0.0525, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.0145, grad_fn=<DivBackward1>)\n",
      "tensor(0.0431, grad_fn=<DivBackward1>)\n",
      "tensor(0.0161, grad_fn=<DivBackward1>)\n",
      "tensor(0.0578, grad_fn=<DivBackward1>)\n",
      "tensor(0.0371, grad_fn=<DivBackward1>)\n",
      "tensor(0.0501, grad_fn=<DivBackward1>)\n",
      "tensor(0.0194, grad_fn=<DivBackward1>)\n",
      "tensor(0.0284, grad_fn=<DivBackward1>)\n",
      "tensor(0.0175, grad_fn=<DivBackward1>)\n",
      "tensor(0.1194, grad_fn=<DivBackward1>)\n",
      "tensor(0.0299, grad_fn=<DivBackward1>)\n",
      "tensor(0.0157, grad_fn=<DivBackward1>)\n",
      "tensor(0.0245, grad_fn=<DivBackward1>)\n",
      "tensor(0.0239, grad_fn=<DivBackward1>)\n",
      "tensor(0.0073, grad_fn=<DivBackward1>)\n",
      "tensor(0.0207, grad_fn=<DivBackward1>)\n",
      "tensor(0.0520, grad_fn=<DivBackward1>)\n",
      "tensor(0.0269, grad_fn=<DivBackward1>)\n",
      "tensor(0.0084, grad_fn=<DivBackward1>)\n",
      "tensor(0.0153, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0250, grad_fn=<DivBackward1>)\n",
      "tensor(0.0654, grad_fn=<DivBackward1>)\n",
      "tensor(0.0439, grad_fn=<DivBackward1>)\n",
      "tensor(0.0316, grad_fn=<DivBackward1>)\n",
      "tensor(0.0321, grad_fn=<DivBackward1>)\n",
      "tensor(0.0148, grad_fn=<DivBackward1>)\n",
      "tensor(0.0030, grad_fn=<DivBackward1>)\n",
      "tensor(0.0186, grad_fn=<DivBackward1>)\n",
      "tensor(0.0088, grad_fn=<DivBackward1>)\n",
      "tensor(0.0325, grad_fn=<DivBackward1>)\n",
      "tensor(0.0165, grad_fn=<DivBackward1>)\n",
      "tensor(0.4823, grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, grad_fn=<DivBackward1>)\n",
      "tensor(0.0446, grad_fn=<DivBackward1>)\n",
      "tensor(0.0139, grad_fn=<DivBackward1>)\n",
      "tensor(0.0026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0053, grad_fn=<DivBackward1>)\n",
      "tensor(0.0308, grad_fn=<DivBackward1>)\n",
      "tensor(0.0863, grad_fn=<DivBackward1>)\n",
      "tensor(0.0070, grad_fn=<DivBackward1>)\n",
      "tensor(0.3580, grad_fn=<DivBackward1>)\n",
      "tensor(0.1159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0235, grad_fn=<DivBackward1>)\n",
      "tensor(0.0036, grad_fn=<DivBackward1>)\n",
      "tensor(0.1724, grad_fn=<DivBackward1>)\n",
      "tensor(0.0216, grad_fn=<DivBackward1>)\n",
      "tensor(0.0065, grad_fn=<DivBackward1>)\n",
      "tensor(0.0401, grad_fn=<DivBackward1>)\n",
      "tensor(0.0605, grad_fn=<DivBackward1>)\n",
      "tensor(0.5360, grad_fn=<DivBackward1>)\n",
      "tensor(0.7152, grad_fn=<DivBackward1>)\n",
      "tensor(0.0331, grad_fn=<DivBackward1>)\n",
      "tensor(0.0097, grad_fn=<DivBackward1>)\n",
      "tensor(0.0082, grad_fn=<DivBackward1>)\n",
      "tensor(0.0287, grad_fn=<DivBackward1>)\n",
      "tensor(0.0244, grad_fn=<DivBackward1>)\n",
      "tensor(0.0359, grad_fn=<DivBackward1>)\n",
      "tensor(0.8391, grad_fn=<DivBackward1>)\n",
      "tensor(0.0424, grad_fn=<DivBackward1>)\n",
      "tensor(0.0056, grad_fn=<DivBackward1>)\n",
      "tensor(0.0215, grad_fn=<DivBackward1>)\n",
      "tensor(0.0516, grad_fn=<DivBackward1>)\n",
      "tensor(0.6987, grad_fn=<DivBackward1>)\n",
      "tensor(0.0570, grad_fn=<DivBackward1>)\n",
      "tensor(0.1297, grad_fn=<DivBackward1>)\n",
      "tensor(0.0147, grad_fn=<DivBackward1>)\n",
      "tensor(0.2611, grad_fn=<DivBackward1>)\n",
      "tensor(0.0512, grad_fn=<DivBackward1>)\n",
      "tensor(0.0763, grad_fn=<DivBackward1>)\n",
      "tensor(0.0182, grad_fn=<DivBackward1>)\n",
      "tensor(0.0330, grad_fn=<DivBackward1>)\n",
      "tensor(0.0179, grad_fn=<DivBackward1>)\n",
      "tensor(0.0628, grad_fn=<DivBackward1>)\n",
      "tensor(0.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.0810, grad_fn=<DivBackward1>)\n",
      "tensor(0.0291, grad_fn=<DivBackward1>)\n",
      "tensor(0.0914, grad_fn=<DivBackward1>)\n",
      "tensor(0.0428, grad_fn=<DivBackward1>)\n",
      "tensor(0.0135, grad_fn=<DivBackward1>)\n",
      "tensor(0.0241, grad_fn=<DivBackward1>)\n",
      "tensor(0.0297, grad_fn=<DivBackward1>)\n",
      "tensor(0.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0321, grad_fn=<DivBackward1>)\n",
      "tensor(0.0298, grad_fn=<DivBackward1>)\n",
      "tensor(0.0346, grad_fn=<DivBackward1>)\n",
      "tensor(0.0093, grad_fn=<DivBackward1>)\n",
      "tensor(0.0139, grad_fn=<DivBackward1>)\n",
      "tensor(0.0190, grad_fn=<DivBackward1>)\n",
      "tensor(0.0318, grad_fn=<DivBackward1>)\n",
      "tensor(0.0485, grad_fn=<DivBackward1>)\n",
      "tensor(0.0442, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0273, grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, grad_fn=<DivBackward1>)\n",
      "tensor(0.0031, grad_fn=<DivBackward1>)\n",
      "tensor(0.0162, grad_fn=<DivBackward1>)\n",
      "tensor(0.0074, grad_fn=<DivBackward1>)\n",
      "tensor(0.0293, grad_fn=<DivBackward1>)\n",
      "tensor(0.0171, grad_fn=<DivBackward1>)\n",
      "tensor(0.5177, grad_fn=<DivBackward1>)\n",
      "tensor(0.0170, grad_fn=<DivBackward1>)\n",
      "tensor(0.0386, grad_fn=<DivBackward1>)\n",
      "tensor(0.0121, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0051, grad_fn=<DivBackward1>)\n",
      "tensor(0.0329, grad_fn=<DivBackward1>)\n",
      "tensor(0.0777, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.2876, grad_fn=<DivBackward1>)\n",
      "tensor(0.1858, grad_fn=<DivBackward1>)\n",
      "tensor(0.0265, grad_fn=<DivBackward1>)\n",
      "tensor(0.0039, grad_fn=<DivBackward1>)\n",
      "tensor(0.1638, grad_fn=<DivBackward1>)\n",
      "tensor(0.0234, grad_fn=<DivBackward1>)\n",
      "tensor(0.0067, grad_fn=<DivBackward1>)\n",
      "tensor(0.0483, grad_fn=<DivBackward1>)\n",
      "tensor(0.0717, grad_fn=<DivBackward1>)\n",
      "tensor(0.4038, grad_fn=<DivBackward1>)\n",
      "tensor(0.7937, grad_fn=<DivBackward1>)\n",
      "tensor(0.0580, grad_fn=<DivBackward1>)\n",
      "tensor(0.0078, grad_fn=<DivBackward1>)\n",
      "tensor(0.0089, grad_fn=<DivBackward1>)\n",
      "tensor(0.0275, grad_fn=<DivBackward1>)\n",
      "tensor(0.0295, grad_fn=<DivBackward1>)\n",
      "tensor(0.0262, grad_fn=<DivBackward1>)\n",
      "tensor(0.8315, grad_fn=<DivBackward1>)\n",
      "tensor(0.0387, grad_fn=<DivBackward1>)\n",
      "tensor(0.0048, grad_fn=<DivBackward1>)\n",
      "tensor(0.0224, grad_fn=<DivBackward1>)\n",
      "tensor(0.0461, grad_fn=<DivBackward1>)\n",
      "tensor(0.7501, grad_fn=<DivBackward1>)\n",
      "tensor(0.0517, grad_fn=<DivBackward1>)\n",
      "tensor(0.1612, grad_fn=<DivBackward1>)\n",
      "tensor(0.0144, grad_fn=<DivBackward1>)\n",
      "tensor(0.2671, grad_fn=<DivBackward1>)\n",
      "tensor(0.0407, grad_fn=<DivBackward1>)\n",
      "tensor(0.0756, grad_fn=<DivBackward1>)\n",
      "tensor(0.0147, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0210, grad_fn=<DivBackward1>)\n",
      "tensor(0.0875, grad_fn=<DivBackward1>)\n",
      "tensor(0.0292, grad_fn=<DivBackward1>)\n",
      "tensor(0.0392, grad_fn=<DivBackward1>)\n",
      "tensor(0.0174, grad_fn=<DivBackward1>)\n",
      "tensor(0.0891, grad_fn=<DivBackward1>)\n",
      "tensor(0.0358, grad_fn=<DivBackward1>)\n",
      "tensor(0.1348, grad_fn=<DivBackward1>)\n",
      "tensor(0.0364, grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, grad_fn=<DivBackward1>)\n",
      "tensor(0.0175, grad_fn=<DivBackward1>)\n",
      "tensor(0.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0245, grad_fn=<DivBackward1>)\n",
      "tensor(0.0485, grad_fn=<DivBackward1>)\n",
      "tensor(0.0377, grad_fn=<DivBackward1>)\n",
      "tensor(0.0106, grad_fn=<DivBackward1>)\n",
      "tensor(0.0145, grad_fn=<DivBackward1>)\n",
      "tensor(0.0169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0264, grad_fn=<DivBackward1>)\n",
      "tensor(0.0482, grad_fn=<DivBackward1>)\n",
      "tensor(0.0308, grad_fn=<DivBackward1>)\n",
      "tensor(0.0301, grad_fn=<DivBackward1>)\n",
      "tensor(0.0281, grad_fn=<DivBackward1>)\n",
      "tensor(0.0103, grad_fn=<DivBackward1>)\n",
      "tensor(0.0026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0147, grad_fn=<DivBackward1>)\n",
      "tensor(0.0118, grad_fn=<DivBackward1>)\n",
      "tensor(0.0304, grad_fn=<DivBackward1>)\n",
      "tensor(0.0160, grad_fn=<DivBackward1>)\n",
      "tensor(0.4278, grad_fn=<DivBackward1>)\n",
      "tensor(0.0225, grad_fn=<DivBackward1>)\n",
      "tensor(0.0211, grad_fn=<DivBackward1>)\n",
      "tensor(0.0093, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0045, grad_fn=<DivBackward1>)\n",
      "tensor(0.0541, grad_fn=<DivBackward1>)\n",
      "tensor(0.0374, grad_fn=<DivBackward1>)\n",
      "tensor(0.0052, grad_fn=<DivBackward1>)\n",
      "tensor(0.2978, grad_fn=<DivBackward1>)\n",
      "tensor(0.0767, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.0030, grad_fn=<DivBackward1>)\n",
      "tensor(0.2519, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0060, grad_fn=<DivBackward1>)\n",
      "tensor(0.0512, grad_fn=<DivBackward1>)\n",
      "tensor(0.0562, grad_fn=<DivBackward1>)\n",
      "tensor(0.4038, grad_fn=<DivBackward1>)\n",
      "tensor(0.7084, grad_fn=<DivBackward1>)\n",
      "tensor(0.0298, grad_fn=<DivBackward1>)\n",
      "tensor(0.0100, grad_fn=<DivBackward1>)\n",
      "tensor(0.0080, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0230, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.8929, grad_fn=<DivBackward1>)\n",
      "tensor(0.0447, grad_fn=<DivBackward1>)\n",
      "tensor(0.0046, grad_fn=<DivBackward1>)\n",
      "tensor(0.0156, grad_fn=<DivBackward1>)\n",
      "tensor(0.0532, grad_fn=<DivBackward1>)\n",
      "tensor(0.5287, grad_fn=<DivBackward1>)\n",
      "tensor(0.0654, grad_fn=<DivBackward1>)\n",
      "tensor(0.0846, grad_fn=<DivBackward1>)\n",
      "tensor(0.0336, grad_fn=<DivBackward1>)\n",
      "tensor(0.3725, grad_fn=<DivBackward1>)\n",
      "tensor(0.0649, grad_fn=<DivBackward1>)\n",
      "tensor(0.0615, grad_fn=<DivBackward1>)\n",
      "tensor(0.0075, grad_fn=<DivBackward1>)\n",
      "tensor(0.0289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0175, grad_fn=<DivBackward1>)\n",
      "tensor(0.0831, grad_fn=<DivBackward1>)\n",
      "tensor(0.0221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0270, grad_fn=<DivBackward1>)\n",
      "tensor(0.0163, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.0146, grad_fn=<DivBackward1>)\n",
      "tensor(0.1231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0376, grad_fn=<DivBackward1>)\n",
      "tensor(0.0096, grad_fn=<DivBackward1>)\n",
      "tensor(0.0207, grad_fn=<DivBackward1>)\n",
      "tensor(0.0260, grad_fn=<DivBackward1>)\n",
      "tensor(0.0116, grad_fn=<DivBackward1>)\n",
      "tensor(0.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0299, grad_fn=<DivBackward1>)\n",
      "tensor(0.0313, grad_fn=<DivBackward1>)\n",
      "tensor(0.0105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.0248, grad_fn=<DivBackward1>)\n",
      "tensor(0.0309, grad_fn=<DivBackward1>)\n",
      "tensor(0.0465, grad_fn=<DivBackward1>)\n",
      "tensor(0.0426, grad_fn=<DivBackward1>)\n",
      "tensor(0.0331, grad_fn=<DivBackward1>)\n",
      "tensor(0.0296, grad_fn=<DivBackward1>)\n",
      "tensor(0.0105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0027, grad_fn=<DivBackward1>)\n",
      "tensor(0.0143, grad_fn=<DivBackward1>)\n",
      "tensor(0.0094, grad_fn=<DivBackward1>)\n",
      "tensor(0.0261, grad_fn=<DivBackward1>)\n",
      "tensor(0.0171, grad_fn=<DivBackward1>)\n",
      "tensor(0.4741, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0475, grad_fn=<DivBackward1>)\n",
      "tensor(0.0118, grad_fn=<DivBackward1>)\n",
      "tensor(0.0026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0046, grad_fn=<DivBackward1>)\n",
      "tensor(0.0402, grad_fn=<DivBackward1>)\n",
      "tensor(0.0756, grad_fn=<DivBackward1>)\n",
      "tensor(0.0066, grad_fn=<DivBackward1>)\n",
      "tensor(0.2663, grad_fn=<DivBackward1>)\n",
      "tensor(0.0927, grad_fn=<DivBackward1>)\n",
      "tensor(0.0229, grad_fn=<DivBackward1>)\n",
      "tensor(0.0029, grad_fn=<DivBackward1>)\n",
      "tensor(0.2320, grad_fn=<DivBackward1>)\n",
      "tensor(0.0173, grad_fn=<DivBackward1>)\n",
      "tensor(0.0055, grad_fn=<DivBackward1>)\n",
      "tensor(0.0354, grad_fn=<DivBackward1>)\n",
      "tensor(0.0405, grad_fn=<DivBackward1>)\n",
      "tensor(0.3110, grad_fn=<DivBackward1>)\n",
      "tensor(0.5633, grad_fn=<DivBackward1>)\n",
      "tensor(0.0413, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.0071, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0254, grad_fn=<DivBackward1>)\n",
      "tensor(0.0359, grad_fn=<DivBackward1>)\n",
      "tensor(0.8466, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.0049, grad_fn=<DivBackward1>)\n",
      "tensor(0.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0404, grad_fn=<DivBackward1>)\n",
      "tensor(0.6590, grad_fn=<DivBackward1>)\n",
      "tensor(0.0711, grad_fn=<DivBackward1>)\n",
      "tensor(0.0992, grad_fn=<DivBackward1>)\n",
      "tensor(0.0100, grad_fn=<DivBackward1>)\n",
      "tensor(0.3252, grad_fn=<DivBackward1>)\n",
      "tensor(0.0388, grad_fn=<DivBackward1>)\n",
      "tensor(0.1049, grad_fn=<DivBackward1>)\n",
      "tensor(0.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0376, grad_fn=<DivBackward1>)\n",
      "tensor(0.0252, grad_fn=<DivBackward1>)\n",
      "tensor(0.0791, grad_fn=<DivBackward1>)\n",
      "tensor(0.0187, grad_fn=<DivBackward1>)\n",
      "tensor(0.0280, grad_fn=<DivBackward1>)\n",
      "tensor(0.0184, grad_fn=<DivBackward1>)\n",
      "tensor(0.0280, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0952, grad_fn=<DivBackward1>)\n",
      "tensor(0.0341, grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, grad_fn=<DivBackward1>)\n",
      "tensor(0.0200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0264, grad_fn=<DivBackward1>)\n",
      "tensor(0.0166, grad_fn=<DivBackward1>)\n",
      "tensor(0.0212, grad_fn=<DivBackward1>)\n",
      "tensor(0.0283, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.0097, grad_fn=<DivBackward1>)\n",
      "tensor(0.0134, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0397, grad_fn=<DivBackward1>)\n",
      "tensor(0.0409, grad_fn=<DivBackward1>)\n",
      "tensor(0.0308, grad_fn=<DivBackward1>)\n",
      "tensor(0.0440, grad_fn=<DivBackward1>)\n",
      "tensor(0.0309, grad_fn=<DivBackward1>)\n",
      "tensor(0.0103, grad_fn=<DivBackward1>)\n",
      "tensor(0.0019, grad_fn=<DivBackward1>)\n",
      "tensor(0.0161, grad_fn=<DivBackward1>)\n",
      "tensor(0.0115, grad_fn=<DivBackward1>)\n",
      "tensor(0.0306, grad_fn=<DivBackward1>)\n",
      "tensor(0.0170, grad_fn=<DivBackward1>)\n",
      "tensor(0.5448, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.0077, grad_fn=<DivBackward1>)\n",
      "tensor(0.0027, grad_fn=<DivBackward1>)\n",
      "tensor(0.0049, grad_fn=<DivBackward1>)\n",
      "tensor(0.0265, grad_fn=<DivBackward1>)\n",
      "tensor(0.0632, grad_fn=<DivBackward1>)\n",
      "tensor(0.0059, grad_fn=<DivBackward1>)\n",
      "tensor(0.2444, grad_fn=<DivBackward1>)\n",
      "tensor(0.0852, grad_fn=<DivBackward1>)\n",
      "tensor(0.0204, grad_fn=<DivBackward1>)\n",
      "tensor(0.0032, grad_fn=<DivBackward1>)\n",
      "tensor(0.2144, grad_fn=<DivBackward1>)\n",
      "tensor(0.0176, grad_fn=<DivBackward1>)\n",
      "tensor(0.0049, grad_fn=<DivBackward1>)\n",
      "tensor(0.0633, grad_fn=<DivBackward1>)\n",
      "tensor(0.0510, grad_fn=<DivBackward1>)\n",
      "tensor(0.3286, grad_fn=<DivBackward1>)\n",
      "tensor(0.5574, grad_fn=<DivBackward1>)\n",
      "tensor(0.0545, grad_fn=<DivBackward1>)\n",
      "tensor(0.0054, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.0266, grad_fn=<DivBackward1>)\n",
      "tensor(0.0372, grad_fn=<DivBackward1>)\n",
      "tensor(0.8214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0395, grad_fn=<DivBackward1>)\n",
      "tensor(0.0043, grad_fn=<DivBackward1>)\n",
      "tensor(0.0138, grad_fn=<DivBackward1>)\n",
      "tensor(0.0427, grad_fn=<DivBackward1>)\n",
      "tensor(0.7125, grad_fn=<DivBackward1>)\n",
      "tensor(0.0514, grad_fn=<DivBackward1>)\n",
      "tensor(0.2794, grad_fn=<DivBackward1>)\n",
      "tensor(0.0181, grad_fn=<DivBackward1>)\n",
      "tensor(0.4240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0358, grad_fn=<DivBackward1>)\n",
      "tensor(0.0340, grad_fn=<DivBackward1>)\n",
      "tensor(0.0221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0464, grad_fn=<DivBackward1>)\n",
      "tensor(0.0162, grad_fn=<DivBackward1>)\n",
      "tensor(0.1301, grad_fn=<DivBackward1>)\n",
      "tensor(0.0504, grad_fn=<DivBackward1>)\n",
      "tensor(0.0352, grad_fn=<DivBackward1>)\n",
      "tensor(0.0198, grad_fn=<DivBackward1>)\n",
      "tensor(0.0431, grad_fn=<DivBackward1>)\n",
      "tensor(0.0064, grad_fn=<DivBackward1>)\n",
      "tensor(0.0870, grad_fn=<DivBackward1>)\n",
      "tensor(0.0336, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.0286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0308, grad_fn=<DivBackward1>)\n",
      "tensor(0.0146, grad_fn=<DivBackward1>)\n",
      "tensor(0.0171, grad_fn=<DivBackward1>)\n",
      "tensor(0.0581, grad_fn=<DivBackward1>)\n",
      "tensor(0.0549, grad_fn=<DivBackward1>)\n",
      "tensor(0.0095, grad_fn=<DivBackward1>)\n",
      "tensor(0.0143, grad_fn=<DivBackward1>)\n",
      "tensor(0.0137, grad_fn=<DivBackward1>)\n",
      "tensor(0.0332, grad_fn=<DivBackward1>)\n",
      "tensor(0.0438, grad_fn=<DivBackward1>)\n",
      "tensor(0.0314, grad_fn=<DivBackward1>)\n",
      "tensor(0.0366, grad_fn=<DivBackward1>)\n",
      "tensor(0.0315, grad_fn=<DivBackward1>)\n",
      "tensor(0.0077, grad_fn=<DivBackward1>)\n",
      "tensor(0.0018, grad_fn=<DivBackward1>)\n",
      "tensor(0.0155, grad_fn=<DivBackward1>)\n",
      "tensor(0.0108, grad_fn=<DivBackward1>)\n",
      "tensor(0.0273, grad_fn=<DivBackward1>)\n",
      "tensor(0.0166, grad_fn=<DivBackward1>)\n",
      "tensor(0.4109, grad_fn=<DivBackward1>)\n",
      "tensor(0.0193, grad_fn=<DivBackward1>)\n",
      "tensor(0.0176, grad_fn=<DivBackward1>)\n",
      "tensor(0.0055, grad_fn=<DivBackward1>)\n",
      "tensor(0.0032, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0526, grad_fn=<DivBackward1>)\n",
      "tensor(0.0367, grad_fn=<DivBackward1>)\n",
      "tensor(0.0046, grad_fn=<DivBackward1>)\n",
      "tensor(0.2206, grad_fn=<DivBackward1>)\n",
      "tensor(0.0922, grad_fn=<DivBackward1>)\n",
      "tensor(0.0143, grad_fn=<DivBackward1>)\n",
      "tensor(0.0027, grad_fn=<DivBackward1>)\n",
      "tensor(0.1554, grad_fn=<DivBackward1>)\n",
      "tensor(0.0165, grad_fn=<DivBackward1>)\n",
      "tensor(0.0048, grad_fn=<DivBackward1>)\n",
      "tensor(0.0640, grad_fn=<DivBackward1>)\n",
      "tensor(0.0503, grad_fn=<DivBackward1>)\n",
      "tensor(0.2441, grad_fn=<DivBackward1>)\n",
      "tensor(0.5610, grad_fn=<DivBackward1>)\n",
      "tensor(0.0296, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.0215, grad_fn=<DivBackward1>)\n",
      "tensor(0.0266, grad_fn=<DivBackward1>)\n",
      "tensor(0.0367, grad_fn=<DivBackward1>)\n",
      "tensor(0.8289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0391, grad_fn=<DivBackward1>)\n",
      "tensor(0.0067, grad_fn=<DivBackward1>)\n",
      "tensor(0.0165, grad_fn=<DivBackward1>)\n",
      "tensor(0.0476, grad_fn=<DivBackward1>)\n",
      "tensor(0.6169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0425, grad_fn=<DivBackward1>)\n",
      "tensor(0.1749, grad_fn=<DivBackward1>)\n",
      "tensor(0.0281, grad_fn=<DivBackward1>)\n",
      "tensor(0.3174, grad_fn=<DivBackward1>)\n",
      "tensor(0.0753, grad_fn=<DivBackward1>)\n",
      "tensor(0.0250, grad_fn=<DivBackward1>)\n",
      "tensor(0.0123, grad_fn=<DivBackward1>)\n",
      "tensor(0.0435, grad_fn=<DivBackward1>)\n",
      "tensor(0.0140, grad_fn=<DivBackward1>)\n",
      "tensor(0.0803, grad_fn=<DivBackward1>)\n",
      "tensor(0.0247, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.0400, grad_fn=<DivBackward1>)\n",
      "tensor(0.0190, grad_fn=<DivBackward1>)\n",
      "tensor(0.1045, grad_fn=<DivBackward1>)\n",
      "tensor(0.0352, grad_fn=<DivBackward1>)\n",
      "tensor(0.0101, grad_fn=<DivBackward1>)\n",
      "tensor(0.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.0269, grad_fn=<DivBackward1>)\n",
      "tensor(0.0148, grad_fn=<DivBackward1>)\n",
      "tensor(0.0214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0337, grad_fn=<DivBackward1>)\n",
      "tensor(0.0072, grad_fn=<DivBackward1>)\n",
      "tensor(0.0108, grad_fn=<DivBackward1>)\n",
      "tensor(0.0161, grad_fn=<DivBackward1>)\n",
      "tensor(0.0401, grad_fn=<DivBackward1>)\n",
      "tensor(0.0421, grad_fn=<DivBackward1>)\n",
      "tensor(0.0329, grad_fn=<DivBackward1>)\n",
      "tensor(0.0205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0229, grad_fn=<DivBackward1>)\n",
      "tensor(0.0103, grad_fn=<DivBackward1>)\n",
      "tensor(0.0020, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.0057, grad_fn=<DivBackward1>)\n",
      "tensor(0.0211, grad_fn=<DivBackward1>)\n",
      "tensor(0.0195, grad_fn=<DivBackward1>)\n",
      "tensor(0.5813, grad_fn=<DivBackward1>)\n",
      "tensor(0.0184, grad_fn=<DivBackward1>)\n",
      "tensor(0.0252, grad_fn=<DivBackward1>)\n",
      "tensor(0.0075, grad_fn=<DivBackward1>)\n",
      "tensor(0.0026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0048, grad_fn=<DivBackward1>)\n",
      "tensor(0.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.0592, grad_fn=<DivBackward1>)\n",
      "tensor(0.0065, grad_fn=<DivBackward1>)\n",
      "tensor(0.2407, grad_fn=<DivBackward1>)\n",
      "tensor(0.0784, grad_fn=<DivBackward1>)\n",
      "tensor(0.0258, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.2143, grad_fn=<DivBackward1>)\n",
      "tensor(0.0175, grad_fn=<DivBackward1>)\n",
      "tensor(0.0046, grad_fn=<DivBackward1>)\n",
      "tensor(0.0343, grad_fn=<DivBackward1>)\n",
      "tensor(0.0487, grad_fn=<DivBackward1>)\n",
      "tensor(0.1757, grad_fn=<DivBackward1>)\n",
      "tensor(0.5307, grad_fn=<DivBackward1>)\n",
      "tensor(0.0148, grad_fn=<DivBackward1>)\n",
      "tensor(0.0043, grad_fn=<DivBackward1>)\n",
      "tensor(0.0056, grad_fn=<DivBackward1>)\n",
      "tensor(0.0225, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0256, grad_fn=<DivBackward1>)\n",
      "tensor(0.7923, grad_fn=<DivBackward1>)\n",
      "tensor(0.0394, grad_fn=<DivBackward1>)\n",
      "tensor(0.0043, grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, grad_fn=<DivBackward1>)\n",
      "tensor(0.0320, grad_fn=<DivBackward1>)\n",
      "tensor(0.7302, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.2286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0153, grad_fn=<DivBackward1>)\n",
      "tensor(0.3366, grad_fn=<DivBackward1>)\n",
      "tensor(0.0311, grad_fn=<DivBackward1>)\n",
      "tensor(0.0539, grad_fn=<DivBackward1>)\n",
      "tensor(0.0229, grad_fn=<DivBackward1>)\n",
      "tensor(0.0384, grad_fn=<DivBackward1>)\n",
      "tensor(0.0173, grad_fn=<DivBackward1>)\n",
      "tensor(0.0856, grad_fn=<DivBackward1>)\n",
      "tensor(0.0298, grad_fn=<DivBackward1>)\n",
      "tensor(0.0345, grad_fn=<DivBackward1>)\n",
      "tensor(0.0192, grad_fn=<DivBackward1>)\n",
      "tensor(0.0350, grad_fn=<DivBackward1>)\n",
      "tensor(0.0085, grad_fn=<DivBackward1>)\n",
      "tensor(0.0844, grad_fn=<DivBackward1>)\n",
      "tensor(0.0336, grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, grad_fn=<DivBackward1>)\n",
      "tensor(0.0200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0264, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0201, grad_fn=<DivBackward1>)\n",
      "tensor(0.0376, grad_fn=<DivBackward1>)\n",
      "tensor(0.0432, grad_fn=<DivBackward1>)\n",
      "tensor(0.0067, grad_fn=<DivBackward1>)\n",
      "tensor(0.0102, grad_fn=<DivBackward1>)\n",
      "tensor(0.0136, grad_fn=<DivBackward1>)\n",
      "tensor(0.0277, grad_fn=<DivBackward1>)\n",
      "tensor(0.0393, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0276, grad_fn=<DivBackward1>)\n",
      "tensor(0.0245, grad_fn=<DivBackward1>)\n",
      "tensor(0.0090, grad_fn=<DivBackward1>)\n",
      "tensor(0.0020, grad_fn=<DivBackward1>)\n",
      "tensor(0.0147, grad_fn=<DivBackward1>)\n",
      "tensor(0.0072, grad_fn=<DivBackward1>)\n",
      "tensor(0.0245, grad_fn=<DivBackward1>)\n",
      "tensor(0.0153, grad_fn=<DivBackward1>)\n",
      "tensor(0.4385, grad_fn=<DivBackward1>)\n",
      "tensor(0.0140, grad_fn=<DivBackward1>)\n",
      "tensor(0.0181, grad_fn=<DivBackward1>)\n",
      "tensor(0.0056, grad_fn=<DivBackward1>)\n",
      "tensor(0.0027, grad_fn=<DivBackward1>)\n",
      "tensor(0.0046, grad_fn=<DivBackward1>)\n",
      "tensor(0.0208, grad_fn=<DivBackward1>)\n",
      "tensor(0.0608, grad_fn=<DivBackward1>)\n",
      "tensor(0.0050, grad_fn=<DivBackward1>)\n",
      "tensor(0.1754, grad_fn=<DivBackward1>)\n",
      "tensor(0.1213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0237, grad_fn=<DivBackward1>)\n",
      "tensor(0.0022, grad_fn=<DivBackward1>)\n",
      "tensor(0.1437, grad_fn=<DivBackward1>)\n",
      "tensor(0.0159, grad_fn=<DivBackward1>)\n",
      "tensor(0.0045, grad_fn=<DivBackward1>)\n",
      "tensor(0.0541, grad_fn=<DivBackward1>)\n",
      "tensor(0.0509, grad_fn=<DivBackward1>)\n",
      "tensor(0.1260, grad_fn=<DivBackward1>)\n",
      "tensor(0.5963, grad_fn=<DivBackward1>)\n",
      "tensor(0.0126, grad_fn=<DivBackward1>)\n",
      "tensor(0.0054, grad_fn=<DivBackward1>)\n",
      "tensor(0.0047, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.8283, grad_fn=<DivBackward1>)\n",
      "tensor(0.0360, grad_fn=<DivBackward1>)\n",
      "tensor(0.0047, grad_fn=<DivBackward1>)\n",
      "tensor(0.0119, grad_fn=<DivBackward1>)\n",
      "tensor(0.0345, grad_fn=<DivBackward1>)\n",
      "tensor(0.7386, grad_fn=<DivBackward1>)\n",
      "tensor(0.0299, grad_fn=<DivBackward1>)\n",
      "tensor(0.1976, grad_fn=<DivBackward1>)\n",
      "tensor(0.0078, grad_fn=<DivBackward1>)\n",
      "tensor(0.2327, grad_fn=<DivBackward1>)\n",
      "tensor(0.0882, grad_fn=<DivBackward1>)\n",
      "tensor(0.0290, grad_fn=<DivBackward1>)\n",
      "tensor(0.0184, grad_fn=<DivBackward1>)\n",
      "tensor(0.0383, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0734, grad_fn=<DivBackward1>)\n",
      "tensor(0.0319, grad_fn=<DivBackward1>)\n",
      "tensor(0.0262, grad_fn=<DivBackward1>)\n",
      "tensor(0.0181, grad_fn=<DivBackward1>)\n",
      "tensor(0.0414, grad_fn=<DivBackward1>)\n",
      "tensor(0.0160, grad_fn=<DivBackward1>)\n",
      "tensor(0.0932, grad_fn=<DivBackward1>)\n",
      "tensor(0.0383, grad_fn=<DivBackward1>)\n",
      "tensor(0.0094, grad_fn=<DivBackward1>)\n",
      "tensor(0.0242, grad_fn=<DivBackward1>)\n",
      "tensor(0.0264, grad_fn=<DivBackward1>)\n",
      "tensor(0.0163, grad_fn=<DivBackward1>)\n",
      "tensor(0.0142, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0328, grad_fn=<DivBackward1>)\n",
      "tensor(0.0061, grad_fn=<DivBackward1>)\n",
      "tensor(0.0127, grad_fn=<DivBackward1>)\n",
      "tensor(0.0130, grad_fn=<DivBackward1>)\n",
      "tensor(0.0337, grad_fn=<DivBackward1>)\n",
      "tensor(0.0343, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.0222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0087, grad_fn=<DivBackward1>)\n",
      "tensor(0.0017, grad_fn=<DivBackward1>)\n",
      "tensor(0.0160, grad_fn=<DivBackward1>)\n",
      "tensor(0.0062, grad_fn=<DivBackward1>)\n",
      "tensor(0.0253, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.4721, grad_fn=<DivBackward1>)\n",
      "tensor(0.0235, grad_fn=<DivBackward1>)\n",
      "tensor(0.0112, grad_fn=<DivBackward1>)\n",
      "tensor(0.0051, grad_fn=<DivBackward1>)\n",
      "tensor(0.0038, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0812, grad_fn=<DivBackward1>)\n",
      "tensor(0.0257, grad_fn=<DivBackward1>)\n",
      "tensor(0.0043, grad_fn=<DivBackward1>)\n",
      "tensor(0.2386, grad_fn=<DivBackward1>)\n",
      "tensor(0.0861, grad_fn=<DivBackward1>)\n",
      "tensor(0.0250, grad_fn=<DivBackward1>)\n",
      "tensor(0.0013, grad_fn=<DivBackward1>)\n",
      "tensor(0.1009, grad_fn=<DivBackward1>)\n",
      "tensor(0.0165, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0436, grad_fn=<DivBackward1>)\n",
      "tensor(0.0513, grad_fn=<DivBackward1>)\n",
      "tensor(0.1058, grad_fn=<DivBackward1>)\n",
      "tensor(0.4558, grad_fn=<DivBackward1>)\n",
      "tensor(0.0120, grad_fn=<DivBackward1>)\n",
      "tensor(0.0036, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0154, grad_fn=<DivBackward1>)\n",
      "tensor(0.0249, grad_fn=<DivBackward1>)\n",
      "tensor(0.0208, grad_fn=<DivBackward1>)\n",
      "tensor(0.7984, grad_fn=<DivBackward1>)\n",
      "tensor(0.0472, grad_fn=<DivBackward1>)\n",
      "tensor(0.0095, grad_fn=<DivBackward1>)\n",
      "tensor(0.0128, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.7010, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.1861, grad_fn=<DivBackward1>)\n",
      "tensor(0.0175, grad_fn=<DivBackward1>)\n",
      "tensor(0.1885, grad_fn=<DivBackward1>)\n",
      "tensor(0.1205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0212, grad_fn=<DivBackward1>)\n",
      "tensor(0.0078, grad_fn=<DivBackward1>)\n",
      "tensor(0.0245, grad_fn=<DivBackward1>)\n",
      "tensor(0.0221, grad_fn=<DivBackward1>)\n",
      "tensor(0.0882, grad_fn=<DivBackward1>)\n",
      "tensor(0.0218, grad_fn=<DivBackward1>)\n",
      "tensor(0.0227, grad_fn=<DivBackward1>)\n",
      "tensor(0.0203, grad_fn=<DivBackward1>)\n",
      "tensor(0.0353, grad_fn=<DivBackward1>)\n",
      "tensor(0.0106, grad_fn=<DivBackward1>)\n",
      "tensor(0.1100, grad_fn=<DivBackward1>)\n",
      "tensor(0.0312, grad_fn=<DivBackward1>)\n",
      "tensor(0.0092, grad_fn=<DivBackward1>)\n",
      "tensor(0.0283, grad_fn=<DivBackward1>)\n",
      "tensor(0.0257, grad_fn=<DivBackward1>)\n",
      "tensor(0.0119, grad_fn=<DivBackward1>)\n",
      "tensor(0.0099, grad_fn=<DivBackward1>)\n",
      "tensor(0.0354, grad_fn=<DivBackward1>)\n",
      "tensor(0.0286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0055, grad_fn=<DivBackward1>)\n",
      "tensor(0.0062, grad_fn=<DivBackward1>)\n",
      "tensor(0.0151, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.0306, grad_fn=<DivBackward1>)\n",
      "tensor(0.0286, grad_fn=<DivBackward1>)\n",
      "tensor(0.0205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0209, grad_fn=<DivBackward1>)\n",
      "tensor(0.0100, grad_fn=<DivBackward1>)\n",
      "tensor(0.0016, grad_fn=<DivBackward1>)\n",
      "tensor(0.0202, grad_fn=<DivBackward1>)\n",
      "tensor(0.0065, grad_fn=<DivBackward1>)\n",
      "tensor(0.0204, grad_fn=<DivBackward1>)\n",
      "tensor(0.0192, grad_fn=<DivBackward1>)\n",
      "tensor(0.6105, grad_fn=<DivBackward1>)\n",
      "tensor(0.0155, grad_fn=<DivBackward1>)\n",
      "tensor(0.0149, grad_fn=<DivBackward1>)\n",
      "tensor(0.0050, grad_fn=<DivBackward1>)\n",
      "tensor(0.0024, grad_fn=<DivBackward1>)\n",
      "tensor(0.0046, grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, grad_fn=<DivBackward1>)\n",
      "tensor(0.0701, grad_fn=<DivBackward1>)\n",
      "tensor(0.0039, grad_fn=<DivBackward1>)\n",
      "tensor(0.2165, grad_fn=<DivBackward1>)\n",
      "tensor(0.0507, grad_fn=<DivBackward1>)\n",
      "tensor(0.0297, grad_fn=<DivBackward1>)\n",
      "tensor(0.0017, grad_fn=<DivBackward1>)\n",
      "tensor(0.1928, grad_fn=<DivBackward1>)\n",
      "tensor(0.0190, grad_fn=<DivBackward1>)\n",
      "tensor(0.0039, grad_fn=<DivBackward1>)\n",
      "tensor(0.0267, grad_fn=<DivBackward1>)\n",
      "tensor(0.0444, grad_fn=<DivBackward1>)\n",
      "tensor(0.1415, grad_fn=<DivBackward1>)\n",
      "tensor(0.4547, grad_fn=<DivBackward1>)\n",
      "tensor(0.0089, grad_fn=<DivBackward1>)\n",
      "tensor(0.0025, grad_fn=<DivBackward1>)\n",
      "tensor(0.0043, grad_fn=<DivBackward1>)\n",
      "tensor(0.0204, grad_fn=<DivBackward1>)\n",
      "tensor(0.0127, grad_fn=<DivBackward1>)\n",
      "tensor(0.0245, grad_fn=<DivBackward1>)\n",
      "tensor(0.7725, grad_fn=<DivBackward1>)\n",
      "tensor(0.0289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0041, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.0338, grad_fn=<DivBackward1>)\n",
      "tensor(0.7093, grad_fn=<DivBackward1>)\n",
      "tensor(0.0425, grad_fn=<DivBackward1>)\n",
      "tensor(0.2068, grad_fn=<DivBackward1>)\n",
      "tensor(0.0072, grad_fn=<DivBackward1>)\n",
      "tensor(0.2457, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0509, grad_fn=<DivBackward1>)\n",
      "tensor(0.0327, grad_fn=<DivBackward1>)\n",
      "tensor(0.0193, grad_fn=<DivBackward1>)\n",
      "tensor(0.0270, grad_fn=<DivBackward1>)\n",
      "tensor(0.0638, grad_fn=<DivBackward1>)\n",
      "tensor(0.0649, grad_fn=<DivBackward1>)\n",
      "tensor(0.0576, grad_fn=<DivBackward1>)\n",
      "tensor(0.0162, grad_fn=<DivBackward1>)\n",
      "tensor(0.0617, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.1207, grad_fn=<DivBackward1>)\n",
      "tensor(0.0216, grad_fn=<DivBackward1>)\n",
      "tensor(0.0131, grad_fn=<DivBackward1>)\n",
      "tensor(0.0130, grad_fn=<DivBackward1>)\n",
      "tensor(0.0212, grad_fn=<DivBackward1>)\n",
      "tensor(0.0104, grad_fn=<DivBackward1>)\n",
      "tensor(0.0134, grad_fn=<DivBackward1>)\n",
      "tensor(0.0311, grad_fn=<DivBackward1>)\n",
      "tensor(0.0276, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.0139, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0640, grad_fn=<DivBackward1>)\n",
      "tensor(0.0169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0213, grad_fn=<DivBackward1>)\n",
      "tensor(0.0303, grad_fn=<DivBackward1>)\n",
      "tensor(0.0090, grad_fn=<DivBackward1>)\n",
      "tensor(0.0018, grad_fn=<DivBackward1>)\n",
      "tensor(0.0146, grad_fn=<DivBackward1>)\n",
      "tensor(0.0068, grad_fn=<DivBackward1>)\n",
      "tensor(0.0280, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.3955, grad_fn=<DivBackward1>)\n",
      "tensor(0.0196, grad_fn=<DivBackward1>)\n",
      "tensor(0.0091, grad_fn=<DivBackward1>)\n",
      "tensor(0.0032, grad_fn=<DivBackward1>)\n",
      "tensor(0.0029, grad_fn=<DivBackward1>)\n",
      "tensor(0.0052, grad_fn=<DivBackward1>)\n",
      "tensor(0.0335, grad_fn=<DivBackward1>)\n",
      "tensor(0.0326, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.2344, grad_fn=<DivBackward1>)\n",
      "tensor(0.0960, grad_fn=<DivBackward1>)\n",
      "tensor(0.0169, grad_fn=<DivBackward1>)\n",
      "tensor(0.0010, grad_fn=<DivBackward1>)\n",
      "tensor(0.0846, grad_fn=<DivBackward1>)\n",
      "tensor(0.0156, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0453, grad_fn=<DivBackward1>)\n",
      "tensor(0.0684, grad_fn=<DivBackward1>)\n",
      "tensor(0.0663, grad_fn=<DivBackward1>)\n",
      "tensor(0.4936, grad_fn=<DivBackward1>)\n",
      "tensor(0.0061, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.0045, grad_fn=<DivBackward1>)\n",
      "tensor(0.0163, grad_fn=<DivBackward1>)\n",
      "tensor(0.0208, grad_fn=<DivBackward1>)\n",
      "tensor(0.0358, grad_fn=<DivBackward1>)\n",
      "tensor(0.7935, grad_fn=<DivBackward1>)\n",
      "tensor(0.0351, grad_fn=<DivBackward1>)\n",
      "tensor(0.0082, grad_fn=<DivBackward1>)\n",
      "tensor(0.0087, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.5900, grad_fn=<DivBackward1>)\n",
      "tensor(0.0281, grad_fn=<DivBackward1>)\n",
      "tensor(0.2146, grad_fn=<DivBackward1>)\n",
      "tensor(0.0091, grad_fn=<DivBackward1>)\n",
      "tensor(0.1458, grad_fn=<DivBackward1>)\n",
      "tensor(0.3139, grad_fn=<DivBackward1>)\n",
      "tensor(0.0149, grad_fn=<DivBackward1>)\n",
      "tensor(0.0051, grad_fn=<DivBackward1>)\n",
      "tensor(0.0258, grad_fn=<DivBackward1>)\n",
      "tensor(0.4900, grad_fn=<DivBackward1>)\n",
      "tensor(0.9036, grad_fn=<DivBackward1>)\n",
      "tensor(1.9182, grad_fn=<DivBackward1>)\n",
      "tensor(0.1663, grad_fn=<DivBackward1>)\n",
      "tensor(0.0708, grad_fn=<DivBackward1>)\n",
      "tensor(0.0425, grad_fn=<DivBackward1>)\n",
      "tensor(0.0011, grad_fn=<DivBackward1>)\n",
      "tensor(0.1987, grad_fn=<DivBackward1>)\n",
      "tensor(0.0755, grad_fn=<DivBackward1>)\n",
      "tensor(0.0276, grad_fn=<DivBackward1>)\n",
      "tensor(0.0026, grad_fn=<DivBackward1>)\n",
      "tensor(0.0851, grad_fn=<DivBackward1>)\n",
      "tensor(0.0976, grad_fn=<DivBackward1>)\n",
      "tensor(0.0155, grad_fn=<DivBackward1>)\n",
      "tensor(0.1123, grad_fn=<DivBackward1>)\n",
      "tensor(0.0375, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.0255, grad_fn=<DivBackward1>)\n",
      "tensor(0.0339, grad_fn=<DivBackward1>)\n",
      "tensor(0.0247, grad_fn=<DivBackward1>)\n",
      "tensor(0.3294, grad_fn=<DivBackward1>)\n",
      "tensor(0.0477, grad_fn=<DivBackward1>)\n",
      "tensor(0.1371, grad_fn=<DivBackward1>)\n",
      "tensor(0.0604, grad_fn=<DivBackward1>)\n",
      "tensor(0.0454, grad_fn=<DivBackward1>)\n",
      "tensor(0.0071, grad_fn=<DivBackward1>)\n",
      "tensor(0.0519, grad_fn=<DivBackward1>)\n",
      "tensor(0.0101, grad_fn=<DivBackward1>)\n",
      "tensor(0.0419, grad_fn=<DivBackward1>)\n",
      "tensor(0.0152, grad_fn=<DivBackward1>)\n",
      "tensor(0.3038, grad_fn=<DivBackward1>)\n",
      "tensor(0.0057, grad_fn=<DivBackward1>)\n",
      "tensor(0.0421, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0029, grad_fn=<DivBackward1>)\n",
      "tensor(0.0063, grad_fn=<DivBackward1>)\n",
      "tensor(0.0774, grad_fn=<DivBackward1>)\n",
      "tensor(0.1170, grad_fn=<DivBackward1>)\n",
      "tensor(0.0058, grad_fn=<DivBackward1>)\n",
      "tensor(0.1876, grad_fn=<DivBackward1>)\n",
      "tensor(0.1527, grad_fn=<DivBackward1>)\n",
      "tensor(0.0510, grad_fn=<DivBackward1>)\n",
      "tensor(0.0025, grad_fn=<DivBackward1>)\n",
      "tensor(0.1862, grad_fn=<DivBackward1>)\n",
      "tensor(0.0529, grad_fn=<DivBackward1>)\n",
      "tensor(0.0085, grad_fn=<DivBackward1>)\n",
      "tensor(0.0939, grad_fn=<DivBackward1>)\n",
      "tensor(0.0338, grad_fn=<DivBackward1>)\n",
      "tensor(0.1152, grad_fn=<DivBackward1>)\n",
      "tensor(0.5735, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.0051, grad_fn=<DivBackward1>)\n",
      "tensor(0.0091, grad_fn=<DivBackward1>)\n",
      "tensor(0.0323, grad_fn=<DivBackward1>)\n",
      "tensor(0.0171, grad_fn=<DivBackward1>)\n",
      "tensor(0.0234, grad_fn=<DivBackward1>)\n",
      "tensor(0.7510, grad_fn=<DivBackward1>)\n",
      "tensor(0.0597, grad_fn=<DivBackward1>)\n",
      "tensor(0.0036, grad_fn=<DivBackward1>)\n",
      "tensor(0.0242, grad_fn=<DivBackward1>)\n",
      "tensor(0.0295, grad_fn=<DivBackward1>)\n",
      "tensor(0.4312, grad_fn=<DivBackward1>)\n",
      "tensor(0.0421, grad_fn=<DivBackward1>)\n",
      "tensor(0.2341, grad_fn=<DivBackward1>)\n",
      "tensor(0.0064, grad_fn=<DivBackward1>)\n",
      "tensor(0.1068, grad_fn=<DivBackward1>)\n",
      "tensor(0.0649, grad_fn=<DivBackward1>)\n",
      "tensor(0.0399, grad_fn=<DivBackward1>)\n",
      "tensor(0.0345, grad_fn=<DivBackward1>)\n",
      "tensor(0.0339, grad_fn=<DivBackward1>)\n",
      "tensor(0.0278, grad_fn=<DivBackward1>)\n",
      "tensor(0.0461, grad_fn=<DivBackward1>)\n",
      "tensor(0.0222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0155, grad_fn=<DivBackward1>)\n",
      "tensor(0.0212, grad_fn=<DivBackward1>)\n",
      "tensor(0.0203, grad_fn=<DivBackward1>)\n",
      "tensor(0.0065, grad_fn=<DivBackward1>)\n",
      "tensor(0.0918, grad_fn=<DivBackward1>)\n",
      "tensor(0.0520, grad_fn=<DivBackward1>)\n",
      "tensor(0.0078, grad_fn=<DivBackward1>)\n",
      "tensor(0.0140, grad_fn=<DivBackward1>)\n",
      "tensor(0.0367, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, grad_fn=<DivBackward1>)\n",
      "tensor(0.0200, grad_fn=<DivBackward1>)\n",
      "tensor(0.0048, grad_fn=<DivBackward1>)\n",
      "tensor(0.0084, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.0511, grad_fn=<DivBackward1>)\n",
      "tensor(0.0187, grad_fn=<DivBackward1>)\n",
      "tensor(0.0197, grad_fn=<DivBackward1>)\n",
      "tensor(0.0268, grad_fn=<DivBackward1>)\n",
      "tensor(0.0053, grad_fn=<DivBackward1>)\n",
      "tensor(0.0029, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0092, grad_fn=<DivBackward1>)\n",
      "tensor(0.0205, grad_fn=<DivBackward1>)\n",
      "tensor(0.0154, grad_fn=<DivBackward1>)\n",
      "tensor(0.4687, grad_fn=<DivBackward1>)\n",
      "tensor(0.0081, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.0031, grad_fn=<DivBackward1>)\n",
      "tensor(0.0020, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0434, grad_fn=<DivBackward1>)\n",
      "tensor(0.0535, grad_fn=<DivBackward1>)\n",
      "tensor(0.0059, grad_fn=<DivBackward1>)\n",
      "tensor(0.2480, grad_fn=<DivBackward1>)\n",
      "tensor(0.0581, grad_fn=<DivBackward1>)\n",
      "tensor(0.0549, grad_fn=<DivBackward1>)\n",
      "tensor(0.0017, grad_fn=<DivBackward1>)\n",
      "tensor(0.0815, grad_fn=<DivBackward1>)\n",
      "tensor(0.0243, grad_fn=<DivBackward1>)\n",
      "tensor(0.0093, grad_fn=<DivBackward1>)\n",
      "tensor(0.0398, grad_fn=<DivBackward1>)\n",
      "tensor(0.0796, grad_fn=<DivBackward1>)\n",
      "tensor(0.0778, grad_fn=<DivBackward1>)\n",
      "tensor(0.3813, grad_fn=<DivBackward1>)\n",
      "tensor(0.0074, grad_fn=<DivBackward1>)\n",
      "tensor(0.0019, grad_fn=<DivBackward1>)\n",
      "tensor(0.0052, grad_fn=<DivBackward1>)\n",
      "tensor(0.0176, grad_fn=<DivBackward1>)\n",
      "tensor(0.0236, grad_fn=<DivBackward1>)\n",
      "tensor(0.0251, grad_fn=<DivBackward1>)\n",
      "tensor(0.7687, grad_fn=<DivBackward1>)\n",
      "tensor(0.0388, grad_fn=<DivBackward1>)\n",
      "tensor(0.0102, grad_fn=<DivBackward1>)\n",
      "tensor(0.0073, grad_fn=<DivBackward1>)\n",
      "tensor(0.0396, grad_fn=<DivBackward1>)\n",
      "tensor(0.5542, grad_fn=<DivBackward1>)\n",
      "tensor(0.0280, grad_fn=<DivBackward1>)\n",
      "tensor(0.1830, grad_fn=<DivBackward1>)\n",
      "tensor(0.0160, grad_fn=<DivBackward1>)\n",
      "tensor(0.1160, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0415, grad_fn=<DivBackward1>)\n",
      "tensor(0.0734, grad_fn=<DivBackward1>)\n",
      "tensor(0.0122, grad_fn=<DivBackward1>)\n",
      "tensor(0.0234, grad_fn=<DivBackward1>)\n",
      "tensor(0.0546, grad_fn=<DivBackward1>)\n",
      "tensor(0.0382, grad_fn=<DivBackward1>)\n",
      "tensor(0.0147, grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, grad_fn=<DivBackward1>)\n",
      "tensor(0.0321, grad_fn=<DivBackward1>)\n",
      "tensor(0.0077, grad_fn=<DivBackward1>)\n",
      "tensor(0.0964, grad_fn=<DivBackward1>)\n",
      "tensor(0.0264, grad_fn=<DivBackward1>)\n",
      "tensor(0.0106, grad_fn=<DivBackward1>)\n",
      "tensor(0.0072, grad_fn=<DivBackward1>)\n",
      "tensor(0.0219, grad_fn=<DivBackward1>)\n",
      "tensor(0.0129, grad_fn=<DivBackward1>)\n",
      "tensor(0.0120, grad_fn=<DivBackward1>)\n",
      "tensor(0.0230, grad_fn=<DivBackward1>)\n",
      "tensor(0.0135, grad_fn=<DivBackward1>)\n",
      "tensor(0.0051, grad_fn=<DivBackward1>)\n",
      "tensor(0.0100, grad_fn=<DivBackward1>)\n",
      "tensor(0.0156, grad_fn=<DivBackward1>)\n",
      "tensor(0.0228, grad_fn=<DivBackward1>)\n",
      "tensor(0.0348, grad_fn=<DivBackward1>)\n",
      "tensor(0.0258, grad_fn=<DivBackward1>)\n",
      "tensor(0.0194, grad_fn=<DivBackward1>)\n",
      "tensor(0.0289, grad_fn=<DivBackward1>)\n",
      "tensor(0.0060, grad_fn=<DivBackward1>)\n",
      "tensor(0.0036, grad_fn=<DivBackward1>)\n",
      "tensor(0.0140, grad_fn=<DivBackward1>)\n",
      "tensor(0.0082, grad_fn=<DivBackward1>)\n",
      "tensor(0.0193, grad_fn=<DivBackward1>)\n",
      "tensor(0.0153, grad_fn=<DivBackward1>)\n",
      "tensor(0.4983, grad_fn=<DivBackward1>)\n",
      "tensor(0.0133, grad_fn=<DivBackward1>)\n",
      "tensor(0.0149, grad_fn=<DivBackward1>)\n",
      "tensor(0.0041, grad_fn=<DivBackward1>)\n",
      "tensor(0.0019, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0256, grad_fn=<DivBackward1>)\n",
      "tensor(0.0667, grad_fn=<DivBackward1>)\n",
      "tensor(0.0049, grad_fn=<DivBackward1>)\n",
      "tensor(0.2106, grad_fn=<DivBackward1>)\n",
      "tensor(0.0550, grad_fn=<DivBackward1>)\n",
      "tensor(0.0277, grad_fn=<DivBackward1>)\n",
      "tensor(0.0027, grad_fn=<DivBackward1>)\n",
      "tensor(0.1034, grad_fn=<DivBackward1>)\n",
      "tensor(0.0166, grad_fn=<DivBackward1>)\n",
      "tensor(0.0092, grad_fn=<DivBackward1>)\n",
      "tensor(0.0377, grad_fn=<DivBackward1>)\n",
      "tensor(0.0636, grad_fn=<DivBackward1>)\n",
      "tensor(0.0719, grad_fn=<DivBackward1>)\n",
      "tensor(0.3682, grad_fn=<DivBackward1>)\n",
      "tensor(0.0074, grad_fn=<DivBackward1>)\n",
      "tensor(0.0020, grad_fn=<DivBackward1>)\n",
      "tensor(0.0047, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0179, grad_fn=<DivBackward1>)\n",
      "tensor(0.0256, grad_fn=<DivBackward1>)\n",
      "tensor(0.7263, grad_fn=<DivBackward1>)\n",
      "tensor(0.0330, grad_fn=<DivBackward1>)\n",
      "tensor(0.0079, grad_fn=<DivBackward1>)\n",
      "tensor(0.0084, grad_fn=<DivBackward1>)\n",
      "tensor(0.0282, grad_fn=<DivBackward1>)\n",
      "tensor(0.6752, grad_fn=<DivBackward1>)\n",
      "tensor(0.0276, grad_fn=<DivBackward1>)\n",
      "tensor(0.2215, grad_fn=<DivBackward1>)\n",
      "tensor(0.0158, grad_fn=<DivBackward1>)\n",
      "tensor(0.2304, grad_fn=<DivBackward1>)\n",
      "tensor(0.0157, grad_fn=<DivBackward1>)\n",
      "tensor(0.0216, grad_fn=<DivBackward1>)\n",
      "tensor(0.0711, grad_fn=<DivBackward1>)\n",
      "tensor(0.0168, grad_fn=<DivBackward1>)\n",
      "tensor(0.0177, grad_fn=<DivBackward1>)\n",
      "tensor(0.0867, grad_fn=<DivBackward1>)\n",
      "tensor(0.0263, grad_fn=<DivBackward1>)\n",
      "tensor(0.0133, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0294, grad_fn=<DivBackward1>)\n",
      "tensor(0.0120, grad_fn=<DivBackward1>)\n",
      "tensor(0.0774, grad_fn=<DivBackward1>)\n",
      "tensor(0.0207, grad_fn=<DivBackward1>)\n",
      "tensor(0.0083, grad_fn=<DivBackward1>)\n",
      "tensor(0.0144, grad_fn=<DivBackward1>)\n",
      "tensor(0.0240, grad_fn=<DivBackward1>)\n",
      "tensor(0.0085, grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, grad_fn=<DivBackward1>)\n",
      "tensor(0.0338, grad_fn=<DivBackward1>)\n",
      "tensor(0.0214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0115, grad_fn=<DivBackward1>)\n",
      "tensor(0.0128, grad_fn=<DivBackward1>)\n",
      "tensor(0.0154, grad_fn=<DivBackward1>)\n",
      "tensor(0.0283, grad_fn=<DivBackward1>)\n",
      "tensor(0.0166, grad_fn=<DivBackward1>)\n",
      "tensor(0.0183, grad_fn=<DivBackward1>)\n",
      "tensor(0.0247, grad_fn=<DivBackward1>)\n",
      "tensor(0.0057, grad_fn=<DivBackward1>)\n",
      "tensor(0.0018, grad_fn=<DivBackward1>)\n",
      "tensor(0.0129, grad_fn=<DivBackward1>)\n",
      "tensor(0.0070, grad_fn=<DivBackward1>)\n",
      "tensor(0.0180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0121, grad_fn=<DivBackward1>)\n",
      "tensor(0.5961, grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, grad_fn=<DivBackward1>)\n",
      "tensor(0.0115, grad_fn=<DivBackward1>)\n",
      "tensor(0.0035, grad_fn=<DivBackward1>)\n",
      "tensor(0.0020, grad_fn=<DivBackward1>)\n",
      "tensor(0.0039, grad_fn=<DivBackward1>)\n",
      "tensor(0.0204, grad_fn=<DivBackward1>)\n",
      "tensor(0.0510, grad_fn=<DivBackward1>)\n",
      "tensor(0.0030, grad_fn=<DivBackward1>)\n",
      "tensor(0.1558, grad_fn=<DivBackward1>)\n",
      "tensor(0.0438, grad_fn=<DivBackward1>)\n",
      "tensor(0.0367, grad_fn=<DivBackward1>)\n",
      "tensor(0.0028, grad_fn=<DivBackward1>)\n",
      "tensor(0.1930, grad_fn=<DivBackward1>)\n",
      "tensor(0.0127, grad_fn=<DivBackward1>)\n",
      "tensor(0.0048, grad_fn=<DivBackward1>)\n",
      "tensor(0.0271, grad_fn=<DivBackward1>)\n",
      "tensor(0.0495, grad_fn=<DivBackward1>)\n",
      "tensor(0.0692, grad_fn=<DivBackward1>)\n",
      "tensor(0.4391, grad_fn=<DivBackward1>)\n",
      "tensor(0.0069, grad_fn=<DivBackward1>)\n",
      "tensor(0.0019, grad_fn=<DivBackward1>)\n",
      "tensor(0.0039, grad_fn=<DivBackward1>)\n",
      "tensor(0.0198, grad_fn=<DivBackward1>)\n",
      "tensor(0.0110, grad_fn=<DivBackward1>)\n",
      "tensor(0.0221, grad_fn=<DivBackward1>)\n",
      "tensor(0.7571, grad_fn=<DivBackward1>)\n",
      "tensor(0.0234, grad_fn=<DivBackward1>)\n",
      "tensor(0.0044, grad_fn=<DivBackward1>)\n",
      "tensor(0.0085, grad_fn=<DivBackward1>)\n",
      "tensor(0.0262, grad_fn=<DivBackward1>)\n",
      "tensor(0.6220, grad_fn=<DivBackward1>)\n",
      "tensor(0.0342, grad_fn=<DivBackward1>)\n",
      "tensor(0.1679, grad_fn=<DivBackward1>)\n",
      "tensor(0.0066, grad_fn=<DivBackward1>)\n",
      "tensor(0.2459, grad_fn=<DivBackward1>)\n",
      "tensor(0.0135, grad_fn=<DivBackward1>)\n",
      "tensor(0.0175, grad_fn=<DivBackward1>)\n",
      "tensor(0.0180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0380, grad_fn=<DivBackward1>)\n",
      "tensor(0.0347, grad_fn=<DivBackward1>)\n",
      "tensor(0.0815, grad_fn=<DivBackward1>)\n",
      "tensor(0.0199, grad_fn=<DivBackward1>)\n",
      "tensor(0.0068, grad_fn=<DivBackward1>)\n",
      "tensor(0.0180, grad_fn=<DivBackward1>)\n",
      "tensor(0.0504, grad_fn=<DivBackward1>)\n",
      "tensor(0.0074, grad_fn=<DivBackward1>)\n",
      "tensor(0.0898, grad_fn=<DivBackward1>)\n",
      "tensor(0.0214, grad_fn=<DivBackward1>)\n",
      "tensor(0.0080, grad_fn=<DivBackward1>)\n",
      "tensor(0.0113, grad_fn=<DivBackward1>)\n",
      "tensor(0.0231, grad_fn=<DivBackward1>)\n",
      "tensor(0.0164, grad_fn=<DivBackward1>)\n",
      "tensor(0.0152, grad_fn=<DivBackward1>)\n",
      "tensor(0.0222, grad_fn=<DivBackward1>)\n",
      "tensor(0.0223, grad_fn=<DivBackward1>)\n",
      "tensor(0.0046, grad_fn=<DivBackward1>)\n",
      "tensor(0.0102, grad_fn=<DivBackward1>)\n",
      "tensor(0.0135, grad_fn=<DivBackward1>)\n",
      "tensor(0.0280, grad_fn=<DivBackward1>)\n",
      "tensor(0.0282, grad_fn=<DivBackward1>)\n",
      "tensor(0.0173, grad_fn=<DivBackward1>)\n",
      "tensor(0.0140, grad_fn=<DivBackward1>)\n",
      "tensor(0.0217, grad_fn=<DivBackward1>)\n",
      "tensor(0.0063, grad_fn=<DivBackward1>)\n",
      "tensor(0.0019, grad_fn=<DivBackward1>)\n",
      "tensor(0.0119, grad_fn=<DivBackward1>)\n",
      "tensor(0.0075, grad_fn=<DivBackward1>)\n",
      "tensor(0.0162, grad_fn=<DivBackward1>)\n",
      "tensor(0.0153, grad_fn=<DivBackward1>)\n",
      "tensor(0.4478, grad_fn=<DivBackward1>)\n",
      "tensor(0.0131, grad_fn=<DivBackward1>)\n",
      "tensor(0.0121, grad_fn=<DivBackward1>)\n",
      "tensor(0.0032, grad_fn=<DivBackward1>)\n",
      "tensor(0.0023, grad_fn=<DivBackward1>)\n",
      "tensor(0.0045, grad_fn=<DivBackward1>)\n",
      "tensor(0.0187, grad_fn=<DivBackward1>)\n",
      "tensor(0.0505, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in train_loader:\n",
    "        # get the batch\n",
    "        X,y = data\n",
    "        # make the gradients zero so get ready for next pass else keep getting add\n",
    "        model.zero_grad()\n",
    "        output = model(X)\n",
    "\n",
    "        # depends if our data is one hot encoded \n",
    "        # print(output)\n",
    "        loss =error(output,y)\n",
    "\n",
    "        # calculate gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # update gradient\n",
    "        optimizer.step()\n",
    "        print(loss)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t_data in test_loader:\n",
    "        X_t,y_t = t_data\n",
    "        test_output = model(X_t)\n",
    "        for idx, i in enumerate(test_output):\n",
    "            res = torch.argmax(i)\n",
    "            ohe_res = np.zeros(shape = (1,3))[0]\n",
    "            ohe_res[res] = 1\n",
    "            labeled_out = ohe_train.inverse_transform(ohe_res.reshape(1,-1))\n",
    "            results.append(labeled_out[0][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [num_to_label[str(i)] for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tst = [num_to_label[str(i[0])] for i in ohe_train.inverse_transform(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.808358</td>\n",
       "      <td>0.801380</td>\n",
       "      <td>0.795910</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.803986</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.789533</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "H              0.928571  0.722222  0.812500  18.000000\n",
       "L              0.727273  0.941176  0.820513  17.000000\n",
       "M              0.769231  0.740741  0.754717  27.000000\n",
       "accuracy       0.790323  0.790323  0.790323   0.790323\n",
       "macro avg      0.808358  0.801380  0.795910  62.000000\n",
       "weighted avg   0.803986  0.790323  0.789533  62.000000"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_tst,results,output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy['Neural_Network'] = report_df['f1-score']['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies when ran without dropping the columns (with all the features, no feature selection )\n",
    "\n",
    "acc_wCol = {'naive_bayes': 0.6788015657934356,\n",
    " 'Decision_Tree': 0.7205962059620595,\n",
    " 'Random_forest': 0.7988557663354412,\n",
    " 'Logistic_regression': 0.7842818428184282,\n",
    " 'svm': 0.7842818428184282,\n",
    " 'Xgboost': 0.720385426076483,\n",
    " 'Neural_network':0.792683}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "acc = pd.DataFrame.from_dict(acc_wCol, orient=\"index\").reset_index()\n",
    "acc.columns = ['models','accuracy']\n",
    "ax = sn.barplot(x=\"models\", y=\"accuracy\", data=acc, ax=ax)\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies after dropping the columns, \n",
    "# saved here so need not to do train the model again \n",
    "# {'naive_bayes': 0.6814024390243902,\n",
    "#  'Decision_Tree': 0.720609756097561,\n",
    "#  'Random_forest': 0.8112195121951219,\n",
    "#  'Logistic_regression': 0.7620731707317073,\n",
    "#  'svm': 0.7967073170731708,\n",
    "#  'Xgboost': 0.7398170731707318,\n",
    "#  'Neural_Network': 0.7903225806451613}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes': 0.6814024390243902,\n",
       " 'Decision_Tree': 0.720609756097561,\n",
       " 'Random_forest': 0.8112195121951219,\n",
       " 'Logistic_regression': 0.7620731707317073,\n",
       " 'svm': 0.7967073170731708,\n",
       " 'Xgboost': 0.7398170731707318,\n",
       " 'Neural_Network': 0.7903225806451613}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "acc = pd.DataFrame.from_dict(accuracy, orient=\"index\").reset_index()\n",
    "acc.columns = ['models','accuracy']\n",
    "ax = sn.barplot(x=\"models\", y=\"accuracy\", data=acc, ax=ax)\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5188bc372fa413aa2565ae5d28228f50ad7b2c4ebb4a82c5900fd598adbb6408"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
