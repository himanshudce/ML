{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convert feature's string values into numbers to apply models\n",
    "# label_to_key = {}\n",
    "# key_to_label = {}\n",
    "# for i,label in enumerate(sorted(df['Class'].unique())):\n",
    "#     label_to_key[label] = i\n",
    "#     key_to_label[i]= label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0': 'H', '1': 'L', '2': 'M'}, {'H': 0, 'L': 1, 'M': 2})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the json to convert from num to lable\n",
    "with open('Data/processing_models/num_to_label.json') as json_file:\n",
    "    num_to_label = json.load(json_file)\n",
    "\n",
    "with open('Data/processing_models/label_to_num.json') as json_file:\n",
    "    label_to_num = json.load(json_file)\n",
    "\n",
    "num_to_label,label_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save trained model in pickle file\n",
    "def save_pkl_model(path,model):\n",
    "    pickle.dump(model, open(path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load trained model \n",
    "def load_pkl_model(path):\n",
    "    return pickle.load(open(path, 'rb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score, average='micro')\n",
    "kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "def get_best_estimator(classifier,grid_param):\n",
    "    gd_sr = GridSearchCV(estimator=classifier,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring=f1,\n",
    "                     cv=kf,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "    gd_sr.fit(X, y)  # X,y are recently updated values\n",
    "    print(gd_sr.cv_results_)\n",
    "    return gd_sr.best_score_,gd_sr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive Bays\n",
    "**using one hot encoded ,bxtransformed data** \n",
    "**and important features from above model** \n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "The biggest and only assumption is the assumption of conditional independence.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Gives high performance when the conditional independence assumption is satisfied.\n",
    "2. Easy to implement because only probabilities need to be calculated.\n",
    "3. Works well with high-dimensional data, such as text.\n",
    "4. Fast for real-time predictions.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. If conditional independence does not hold, then is performs poorly.\n",
    "2. Has the problem of Numerical Stability or Numerical Underflow because of the multiplication of several small digits.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading classifier \n",
    "classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading one hot encoded box transformed data \n",
    "df = pd.read_csv(\"Data/transformed/train_bx_ohe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Semester_S</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...         1.0          0.0            0.0   \n",
       "1                0.0  ...         0.0          0.0            0.0   \n",
       "2                0.0  ...         0.0          0.0            0.0   \n",
       "3                0.0  ...         0.0          1.0            0.0   \n",
       "4                0.0  ...         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Semester_S  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0         0.0           0.0                        1.0   \n",
       "1            0.0         1.0           1.0                        1.0   \n",
       "2            0.0         1.0           0.0                        0.0   \n",
       "3            0.0         0.0           1.0                        0.0   \n",
       "4            0.0         0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      H  \n",
       "1                            0.0                         0.0      M  \n",
       "2                            0.0                         0.0      L  \n",
       "3                            0.0                         1.0      M  \n",
       "4                            1.0                         1.0      H  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 61)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows(r) and columns(c)  (r,c)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_IT</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_IT  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...       0.0         1.0          0.0            0.0   \n",
       "1                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "2                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "3                0.0  ...       0.0         0.0          1.0            0.0   \n",
       "4                0.0  ...       1.0         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0           0.0                        1.0   \n",
       "1            0.0           1.0                        1.0   \n",
       "2            0.0           0.0                        0.0   \n",
       "3            0.0           1.0                        0.0   \n",
       "4            0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      H  \n",
       "1                            0.0                         0.0      M  \n",
       "2                            0.0                         0.0      L  \n",
       "3                            0.0                         1.0      M  \n",
       "4                            1.0                         1.0      H  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns with less importance\n",
    "df = func_dropCol(df,drop_col)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 56)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows(r) and columns(c) in (r,c) format\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>NationalITy_KW</th>\n",
       "      <th>NationalITy_Lybia</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_IT</th>\n",
       "      <th>Topic_Math</th>\n",
       "      <th>Topic_Quran</th>\n",
       "      <th>Topic_Science</th>\n",
       "      <th>Topic_Spanish</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>-0.046205</td>\n",
       "      <td>1.202617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.787987</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.738216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.330558</td>\n",
       "      <td>-0.819927</td>\n",
       "      <td>-0.262502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.580670</td>\n",
       "      <td>-1.642231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_M  \\\n",
       "0     0.283065          0.915333          -0.046205    1.202617       1.0   \n",
       "1    -0.248000          0.787987           0.814707    0.738216       1.0   \n",
       "2     0.283065          0.330558          -0.819927   -0.262502       1.0   \n",
       "3     0.532940          0.744635           0.580670    0.000635       0.0   \n",
       "4     0.760956          0.998122           0.580670   -1.642231       0.0   \n",
       "\n",
       "   NationalITy_Iran  NationalITy_Iraq  NationalITy_Jordan  NationalITy_KW  \\\n",
       "0               0.0               0.0                 0.0             1.0   \n",
       "1               0.0               0.0                 1.0             0.0   \n",
       "2               0.0               0.0                 1.0             0.0   \n",
       "3               0.0               0.0                 0.0             1.0   \n",
       "4               0.0               0.0                 0.0             1.0   \n",
       "\n",
       "   NationalITy_Lybia  ...  Topic_IT  Topic_Math  Topic_Quran  Topic_Science  \\\n",
       "0                0.0  ...       0.0         1.0          0.0            0.0   \n",
       "1                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "2                0.0  ...       0.0         0.0          0.0            0.0   \n",
       "3                0.0  ...       0.0         0.0          1.0            0.0   \n",
       "4                0.0  ...       1.0         0.0          0.0            0.0   \n",
       "\n",
       "   Topic_Spanish  Relation_Mum  ParentAnsweringSurvey_Yes  \\\n",
       "0            0.0           0.0                        1.0   \n",
       "1            0.0           1.0                        1.0   \n",
       "2            0.0           0.0                        0.0   \n",
       "3            0.0           1.0                        0.0   \n",
       "4            0.0           1.0                        1.0   \n",
       "\n",
       "   ParentschoolSatisfaction_Good  StudentAbsenceDays_Under-7  Class  \n",
       "0                            1.0                         1.0      0  \n",
       "1                            0.0                         0.0      2  \n",
       "2                            0.0                         0.0      1  \n",
       "3                            0.0                         1.0      2  \n",
       "4                            1.0                         1.0      0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting Class feature values from str to number\n",
    "df.Class = df.Class.apply(lambda x :label_to_key[x]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting input and target features\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting range of hyperparameters for grid search\n",
    "\n",
    "#var_smoothingfloat, default=1e-9\n",
    "##Portion of the largest variance of all features that is added to variances for calculation stability.\n",
    "grid_param = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00876031, 0.00881386, 0.00826206, 0.00971742, 0.00983529,\n",
      "       0.01131358, 0.01027265, 0.00843439, 0.00800385, 0.00817327]), 'std_fit_time': array([0.00074173, 0.00136862, 0.00069116, 0.00117807, 0.0002093 ,\n",
      "       0.00260817, 0.00088436, 0.00115897, 0.00040926, 0.00064247]), 'mean_score_time': array([0.00708809, 0.00935249, 0.01788301, 0.01014581, 0.00857315,\n",
      "       0.01696582, 0.00899801, 0.00796442, 0.00791278, 0.0067944 ]), 'std_score_time': array([0.00014036, 0.00245686, 0.01534815, 0.00222232, 0.00065444,\n",
      "       0.01454021, 0.00141593, 0.00093647, 0.00173351, 0.00121823]), 'param_var_smoothing': masked_array(data=[1.0, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07,\n",
      "                   1e-08, 1e-09],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'var_smoothing': 1.0}, {'var_smoothing': 0.1}, {'var_smoothing': 0.01}, {'var_smoothing': 0.001}, {'var_smoothing': 0.0001}, {'var_smoothing': 1e-05}, {'var_smoothing': 1e-06}, {'var_smoothing': 1e-07}, {'var_smoothing': 1e-08}, {'var_smoothing': 1e-09}], 'split0_test_score': array([0.70731707, 0.70731707, 0.70731707, 0.6097561 , 0.58536585,\n",
      "       0.52439024, 0.51219512, 0.51219512, 0.52439024, 0.52439024]), 'split1_test_score': array([0.64634146, 0.64634146, 0.56097561, 0.56097561, 0.48780488,\n",
      "       0.43902439, 0.37804878, 0.3902439 , 0.3902439 , 0.36585366]), 'split2_test_score': array([0.70731707, 0.70731707, 0.6097561 , 0.56097561, 0.52439024,\n",
      "       0.52439024, 0.51219512, 0.5       , 0.5       , 0.5       ]), 'split3_test_score': array([0.60493827, 0.64197531, 0.61728395, 0.54320988, 0.45679012,\n",
      "       0.45679012, 0.39506173, 0.37037037, 0.38271605, 0.38271605]), 'split4_test_score': array([0.7037037 , 0.7037037 , 0.56790123, 0.48148148, 0.45679012,\n",
      "       0.45679012, 0.44444444, 0.44444444, 0.43209877, 0.43209877]), 'mean_test_score': array([0.67392352, 0.68133092, 0.61264679, 0.55127974, 0.50222824,\n",
      "       0.48027702, 0.44838904, 0.44345077, 0.44588979, 0.44101174]), 'std_test_score': array([0.04156165, 0.03041127, 0.05227695, 0.04133866, 0.04845678,\n",
      "       0.03659782, 0.05647928, 0.05673853, 0.05721506, 0.06254303]), 'rank_test_score': array([ 2,  1,  3,  4,  5,  6,  7,  9,  8, 10])}\n"
     ]
    }
   ],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6813309244203553 GaussianNB(var_smoothing=0.1)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GaussianNB' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-21f288c5bfbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GaussianNB' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "best_random.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/naive_bayes.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. algorithms with Normalized and one hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  (408, 61)\n",
      "shape after removing columns  (408, 56)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/transformed/train_mms_ohe.csv\")\n",
    "print(\"shape \" , df.shape)\n",
    "df = func_dropCol(df,drop_col)\n",
    "\n",
    "print(\"shape after removing columns \", df.shape)\n",
    "df.Class = df.Class.apply(lambda x :label_to_key[x]) # mapping \n",
    "df.head()\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Decision Trees \n",
    "**Assumptions of algorithm** :\n",
    "\n",
    "1. Initially, whole training data is considered as root.\n",
    "2. Records are distributed recursively on the basis of the attribute value.\n",
    "\n",
    "**Pros** :\n",
    "\n",
    "1. Compared to other algorithms, data preparation requires less time.\n",
    "2. Doesn’t require data to be normalized.\n",
    "3. Missing values, to an extent, don’t affect its performance much.\n",
    "4. Is very intuitive as can be explained as if-else conditions.\n",
    "\n",
    "**Cons**:\n",
    "\n",
    "1. Needs a lot of time to train the model.\n",
    "2. A small change in data can cause a considerably large change in the Decision Tree structure.\n",
    "3. Comparatively expensive to train.\n",
    "4. Not good for regression tasks.\n",
    "\n",
    "https://www.kdnuggets.com/2021/02/machine-learning-assumptions.html \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    'max_depth': [2, 3, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7376994881059922 DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=10,\n",
      "                       random_state=0)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/decision_tree.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimatorsint, default=100\n",
    "###The number of trees in the forest.\n",
    "\n",
    "#criterion{“gini”, “entropy”}, default=”gini”\n",
    "###The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n",
    "\n",
    "#bootstrapbool, default=True\n",
    "###Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html \n",
    "grid_param = {\n",
    "    'n_estimators': [int(x) for x in range(200,2000,200)],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8062631737428486 RandomForestClassifier(bootstrap=False, n_estimators=1200, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/random_forest.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param =  {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 3),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "270 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.2965673         nan 0.40948509 0.43875339\n",
      " 0.43875339 0.43875339 0.43875339 0.43875339        nan        nan\n",
      "        nan        nan        nan 0.73279133 0.72550437        nan\n",
      " 0.73766938 0.75486299        nan        nan 0.2965673         nan\n",
      " 0.40948509 0.43875339 0.43875339 0.43875339 0.43875339 0.43875339\n",
      "        nan        nan        nan        nan        nan 0.72794339\n",
      " 0.72550437        nan 0.7303523  0.73526046        nan        nan\n",
      " 0.73279133        nan 0.77199639 0.76458898 0.76458898 0.7229449\n",
      " 0.76458898 0.76458898        nan        nan        nan        nan\n",
      "        nan 0.73279133 0.72550437        nan 0.73766938 0.75486299\n",
      "        nan        nan 0.73279133        nan 0.77199639 0.76458898\n",
      " 0.76458898 0.7229449  0.76458898 0.76458898        nan        nan\n",
      "        nan        nan        nan 0.72794339 0.72550437        nan\n",
      " 0.7303523  0.73526046        nan        nan 0.71321891        nan\n",
      " 0.75486299 0.72300512 0.73038241 0.71568805 0.73766938 0.75486299\n",
      "        nan        nan        nan        nan        nan 0.73279133\n",
      " 0.72550437        nan 0.73766938 0.75486299        nan        nan\n",
      " 0.71321891        nan 0.73526046 0.73038241 0.73038241 0.71568805\n",
      " 0.7303523  0.73526046        nan        nan        nan        nan\n",
      "        nan 0.72794339 0.72550437        nan 0.7303523  0.73526046]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ProBook\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7719963866305328 LogisticRegression(penalty='l1', random_state=0, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/logistic_regression.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 SVM\n",
    "**Assumptions:**\n",
    "\n",
    "It assumes data is independent and identically distributed.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Works really well on high dimensional data.\n",
    "2. Memory efficient.\n",
    "3. Effective in cases where the number of dimensions is greater than the number of samples.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. Not suitable for large datasets.\n",
    "2. Doesn’t work well when the dataset has noise, i.e., the target classes are overlapping.\n",
    "3. Slow to train.\n",
    "4. No probabilistic explanation for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = { 'C':[0.1,1,100,1000],\n",
    "'kernel':['rbf','poly','sigmoid','linear'],\n",
    "'degree':[1,5,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7769346582354713 SVC(C=1, degree=1, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/svm.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 XGBOOST\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "It may have an assumption that encoded integer value for each variable has ordinal relation.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Can work in parallell.\n",
    "2. Can handle missing values.\n",
    "3. No need for scaling or normalizing data.\n",
    "4. Fast to interpret.\n",
    "5. Great execution speed.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. Can easily overfit if parameters are not tuned properly.\n",
    "2. Hard to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cross validation\n",
    "grid_param  = {\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [1,2],\n",
    "    'min_samples_leaf': [1,2],\n",
    "    'max_leaf_nodes': [4,50,None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:59:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\", \"max_leaf_nodes\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score,best_random = get_best_estimator(classifier,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7326708822643783 XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              criterion='gini', early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=6,\n",
      "              max_leaf_nodes=4, max_leaves=0, min_child_weight=1,\n",
      "              min_samples_leaf=1, min_samples_split=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "              num_parallel_tree=1, ...)\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl_model(\"models/xgboost.pkl\",best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1fa63b9192d89ce9d1e4d6a7a4a001f8fee5f65329ca0df81cf26abef0c948c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
